{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 19 - Progress Log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have **290 food webs**, each with `Nodes`, `Edges`, and `Connectance`. To cluster them into **small, medium, and large** based on the number of **Edges (links)** (which makes sense computationally), here's a recommended academic approach:\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ **Step 1: Define Size Categories by Edges**\n",
    "\n",
    "A **quantile-based partitioning** gives a fair distribution and is statistically justified for heterogeneously sized datasets.\n",
    "\n",
    "### Option A: Use **Quantiles (tertiles)**\n",
    "\n",
    "```text\n",
    "Small:        bottom 33% (low edge count)\n",
    "Medium:       middle 33%\n",
    "Large:        top 33% (high edge count)\n",
    "```\n",
    "\n",
    "### Option B: Define **custom edge thresholds**\n",
    "\n",
    "Based on ecological logic or runtime performance:\n",
    "\n",
    "```text\n",
    "Small:        Edges ≤ 500\n",
    "Medium:       500 < Edges ≤ 3000\n",
    "Large:        Edges > 3000\n",
    "```\n",
    "\n",
    "I recommend starting with **Option A (tertiles)** to see how the data distributes naturally. Then we can refine.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of Foodwebs:\n",
      "290\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reload the uploaded CSV\n",
    "file_path = \"../../data/processed/foodweb_metrics.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate tertiles based on the 'Edges' column\n",
    "tertile_1 = df['Edges'].quantile(1/3)\n",
    "tertile_2 = df['Edges'].quantile(2/3)\n",
    "\n",
    "# Define categories\n",
    "def categorize_edges(edges):\n",
    "    if edges <= tertile_1:\n",
    "        return 'small'\n",
    "    elif edges <= tertile_2:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'large'\n",
    "\n",
    "# Apply categorization\n",
    "df['SizeCategory'] = df['Edges'].apply(categorize_edges)\n",
    "\n",
    "# Split into separate DataFrames\n",
    "df_small = df[df['SizeCategory'] == 'small']\n",
    "df_medium = df[df['SizeCategory'] == 'medium']\n",
    "df_large = df[df['SizeCategory'] == 'large']\n",
    "\n",
    "# Save to CSV files\n",
    "small_path = \"../../data/processed/small_tertile_foodwebs_16-120.csv\"\n",
    "medium_path = \"../../data/processed/medium_tertile_foodwebs_121-417.csv\"\n",
    "large_path = \"../../data/processed/large_tertile_foodwebs_418-16041.csv\"\n",
    "\n",
    "df_small.to_csv(small_path, index=False)\n",
    "df_medium.to_csv(medium_path, index=False)\n",
    "df_large.to_csv(large_path, index=False)\n",
    "\n",
    "print(\"Total amount of Foodwebs:\")\n",
    "print(df_small[\"Edges\"].count() + df_medium[\"Edges\"].count() + df_large[\"Edges\"].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has been successfully split into **tertiles** based on the number of edges (links), and stored in the following CSV files:\n",
    "\n",
    "* [small\\_webs.csv](sandbox:/mnt/data/small_webs.csv)\n",
    "* [medium\\_webs.csv](sandbox:/mnt/data/medium_webs.csv)\n",
    "* [large\\_webs.csv](sandbox:/mnt/data/large_webs.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Foodweb</th>\n",
       "      <th>Nodes</th>\n",
       "      <th>Edges</th>\n",
       "      <th>Connectance</th>\n",
       "      <th>SizeCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PGUBP3</td>\n",
       "      <td>21</td>\n",
       "      <td>68</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CGP1</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SF2M2</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twin Lake East</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>0.108974</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SF1I2</td>\n",
       "      <td>20</td>\n",
       "      <td>58</td>\n",
       "      <td>0.152632</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SF1I4</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PP1I1</td>\n",
       "      <td>27</td>\n",
       "      <td>119</td>\n",
       "      <td>0.169516</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CGP3</td>\n",
       "      <td>31</td>\n",
       "      <td>103</td>\n",
       "      <td>0.110753</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Lake</td>\n",
       "      <td>35</td>\n",
       "      <td>102</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Brook trout lake</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>0.090476</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MBP3</td>\n",
       "      <td>37</td>\n",
       "      <td>353</td>\n",
       "      <td>0.265015</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>L4P3</td>\n",
       "      <td>41</td>\n",
       "      <td>238</td>\n",
       "      <td>0.145122</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>L2P1</td>\n",
       "      <td>47</td>\n",
       "      <td>320</td>\n",
       "      <td>0.148011</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WP4</td>\n",
       "      <td>27</td>\n",
       "      <td>147</td>\n",
       "      <td>0.209402</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gearagh</td>\n",
       "      <td>117</td>\n",
       "      <td>383</td>\n",
       "      <td>0.028220</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MBP1</td>\n",
       "      <td>34</td>\n",
       "      <td>215</td>\n",
       "      <td>0.191622</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GJBP3</td>\n",
       "      <td>27</td>\n",
       "      <td>177</td>\n",
       "      <td>0.252137</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>German Creek</td>\n",
       "      <td>86</td>\n",
       "      <td>353</td>\n",
       "      <td>0.048290</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ythan Estuary</td>\n",
       "      <td>92</td>\n",
       "      <td>417</td>\n",
       "      <td>0.049809</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fawn lake</td>\n",
       "      <td>32</td>\n",
       "      <td>122</td>\n",
       "      <td>0.122984</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chilean Intertidal El Quisco</td>\n",
       "      <td>101</td>\n",
       "      <td>1347</td>\n",
       "      <td>0.133366</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SEW01</td>\n",
       "      <td>104</td>\n",
       "      <td>1245</td>\n",
       "      <td>0.116225</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>L3P3</td>\n",
       "      <td>54</td>\n",
       "      <td>464</td>\n",
       "      <td>0.162124</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AEW17</td>\n",
       "      <td>145</td>\n",
       "      <td>2864</td>\n",
       "      <td>0.137165</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Broad Stream</td>\n",
       "      <td>95</td>\n",
       "      <td>565</td>\n",
       "      <td>0.063270</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Dempsters Stream</td>\n",
       "      <td>110</td>\n",
       "      <td>966</td>\n",
       "      <td>0.080567</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chilean Intertidal Los Molles</td>\n",
       "      <td>105</td>\n",
       "      <td>1352</td>\n",
       "      <td>0.123810</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SEW03</td>\n",
       "      <td>122</td>\n",
       "      <td>2103</td>\n",
       "      <td>0.142460</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AEW03</td>\n",
       "      <td>122</td>\n",
       "      <td>1845</td>\n",
       "      <td>0.124983</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Grand Caricaie  marsh dominated by Cladietum m...</td>\n",
       "      <td>163</td>\n",
       "      <td>2120</td>\n",
       "      <td>0.080285</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Foodweb  Nodes  Edges  \\\n",
       "0                                              PGUBP3     21     68   \n",
       "1                                                CGP1     18     27   \n",
       "2                                               SF2M2     15     30   \n",
       "3                                      Twin Lake East     13     17   \n",
       "4                                               SF1I2     20     58   \n",
       "5                                               SF1I4     21     80   \n",
       "6                                               PP1I1     27    119   \n",
       "7                                                CGP3     31    103   \n",
       "8                                         Indian Lake     35    102   \n",
       "9                                    Brook trout lake     15     19   \n",
       "10                                               MBP3     37    353   \n",
       "11                                               L4P3     41    238   \n",
       "12                                               L2P1     47    320   \n",
       "13                                                WP4     27    147   \n",
       "14                                            Gearagh    117    383   \n",
       "15                                               MBP1     34    215   \n",
       "16                                              GJBP3     27    177   \n",
       "17                                       German Creek     86    353   \n",
       "18                                      Ythan Estuary     92    417   \n",
       "19                                          Fawn lake     32    122   \n",
       "20                       Chilean Intertidal El Quisco    101   1347   \n",
       "21                                              SEW01    104   1245   \n",
       "22                                               L3P3     54    464   \n",
       "23                                              AEW17    145   2864   \n",
       "24                                       Broad Stream     95    565   \n",
       "25                                   Dempsters Stream    110    966   \n",
       "26                      Chilean Intertidal Los Molles    105   1352   \n",
       "27                                              SEW03    122   2103   \n",
       "28                                              AEW03    122   1845   \n",
       "29  Grand Caricaie  marsh dominated by Cladietum m...    163   2120   \n",
       "\n",
       "    Connectance SizeCategory  \n",
       "0      0.161905        small  \n",
       "1      0.088235        small  \n",
       "2      0.142857        small  \n",
       "3      0.108974        small  \n",
       "4      0.152632        small  \n",
       "5      0.190476        small  \n",
       "6      0.169516        small  \n",
       "7      0.110753        small  \n",
       "8      0.085714        small  \n",
       "9      0.090476        small  \n",
       "10     0.265015       medium  \n",
       "11     0.145122       medium  \n",
       "12     0.148011       medium  \n",
       "13     0.209402       medium  \n",
       "14     0.028220       medium  \n",
       "15     0.191622       medium  \n",
       "16     0.252137       medium  \n",
       "17     0.048290       medium  \n",
       "18     0.049809       medium  \n",
       "19     0.122984       medium  \n",
       "20     0.133366        large  \n",
       "21     0.116225        large  \n",
       "22     0.162124        large  \n",
       "23     0.137165        large  \n",
       "24     0.063270        large  \n",
       "25     0.080567        large  \n",
       "26     0.123810        large  \n",
       "27     0.142460        large  \n",
       "28     0.124983        large  \n",
       "29     0.080285        large  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-import modules after code execution state reset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reload the dataset\n",
    "file_path = \"../../data/processed/foodweb_metrics.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Recompute tertiles\n",
    "tertile_1 = df['Edges'].quantile(1/3)\n",
    "tertile_2 = df['Edges'].quantile(2/3)\n",
    "\n",
    "# Re-categorize by edge count\n",
    "def categorize_edges(edges):\n",
    "    if edges <= tertile_1:\n",
    "        return 'small'\n",
    "    elif edges <= tertile_2:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'large'\n",
    "\n",
    "df['SizeCategory'] = df['Edges'].apply(categorize_edges)\n",
    "\n",
    "# Split categories\n",
    "df_small = df[df['SizeCategory'] == 'small']\n",
    "df_medium = df[df['SizeCategory'] == 'medium']\n",
    "df_large = df[df['SizeCategory'] == 'large']\n",
    "\n",
    "# Sample from each category\n",
    "np.random.seed(42)\n",
    "sampled_small = df_small.sample(n=min(10, len(df_small)), random_state=42)\n",
    "sampled_medium = df_medium.sample(n=min(10, len(df_medium)), random_state=42)\n",
    "sampled_large = df_large.sample(n=min(10, len(df_large)), random_state=42)\n",
    "\n",
    "# Combine and save\n",
    "sampled_combined = pd.concat([sampled_small, sampled_medium, sampled_large]).reset_index(drop=True)\n",
    "sampled_path = \"../../data/processed/stratified_random_sampled_foodwebs.csv\"\n",
    "sampled_combined.to_csv(sampled_path, index=False)\n",
    "\n",
    "sampled_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the final sample of food webs—10 from each size category (small, medium, large)—stored in one CSV:\n",
    "\n",
    "* [sampled\\_foodwebs.csv](sandbox:/mnt/data/sampled_foodwebs.csv)\n",
    "\n",
    "This subset is ideal for testing generalization without processing the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to generate .mat files from the sampled food webs with mass data in ascending order\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.io import savemat\n",
    "\n",
    "df = pd.read_csv(\"../../data/processed/stratified_random_sampled_foodwebs.csv\")\n",
    "foodweb_filenames = df['Foodweb'].unique()\n",
    "\n",
    "input_dir = \"../../data/processed/foodwebs_csv\"\n",
    "output_dir = \"../../data/processed/foodwebs_mat_by_ecosystem/MAT_mass\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "failed_files = []\n",
    "\n",
    "for filename in foodweb_filenames:\n",
    "    filename = filename.strip()\n",
    "    if not filename.endswith(\".csv\"):\n",
    "        filename += \".csv\"\n",
    "\n",
    "    csv_path = os.path.join(input_dir, filename)\n",
    "    mat_path = os.path.join(output_dir, filename.replace(\".csv\", \"_tax_mass.mat\"))\n",
    "\n",
    "    try:\n",
    "        df_web = pd.read_csv(csv_path)\n",
    "        df_web['res.taxonomy'] = df_web['res.taxonomy'].astype(str)\n",
    "        df_web['con.taxonomy'] = df_web['con.taxonomy'].astype(str)\n",
    "        prey = df_web['res.taxonomy']\n",
    "        predator = df_web['con.taxonomy']\n",
    "        species = sorted(set(prey).union(set(predator)))\n",
    "        species_index = {name: i for i, name in enumerate(species)}\n",
    "        N = len(species)\n",
    "\n",
    "        adj_matrix = np.zeros((N, N), dtype=int)\n",
    "        for res, con in zip(prey, predator):\n",
    "            i = species_index[res]\n",
    "            j = species_index[con]\n",
    "            adj_matrix[i, j] = 1\n",
    "        net_sparse = csc_matrix(adj_matrix)\n",
    "\n",
    "        res_masses = df_web[['res.taxonomy', 'res.mass.mean.g.']].dropna().rename(\n",
    "            columns={'res.taxonomy': 'species', 'res.mass.mean.g.': 'mass'})\n",
    "        con_masses = df_web[['con.taxonomy', 'con.mass.mean.g.']].dropna().rename(\n",
    "            columns={'con.taxonomy': 'species', 'con.mass.mean.g.': 'mass'})\n",
    "        all_masses = pd.concat([res_masses, con_masses])\n",
    "        species_mass = all_masses.groupby('species')['mass'].mean()\n",
    "\n",
    "        taxonomy_names = np.array(species, dtype=object)\n",
    "        mean_masses = np.array([species_mass.get(name, np.nan) for name in species])\n",
    "\n",
    "        savemat(mat_path, {\n",
    "            \"net\": net_sparse,\n",
    "            \"taxonomy\": taxonomy_names,\n",
    "            \"mass\": mean_masses\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        failed_files.append((filename, str(e)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review and understand the purpose of the `evaluate_on_all_unseen` input parameter from the `sample_neg()` function.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **DEFAULT BEHAVIOR: `evaluate_on_all_unseen = false`**\n",
    "\n",
    "#### Logic:\n",
    "\n",
    "* Combine all known links: `net = train + test`.\n",
    "* Find all non-links: `neg_net = (net == 0)`.\n",
    "* Randomly **sample `k*(train_size + test_size)` negative edges** from those non-links.\n",
    "\n",
    "  * First `k * train_size` → `train_neg`\n",
    "  * Remaining `k * test_size` → `test_neg`\n",
    "\n",
    "#### Summary:\n",
    "\n",
    "If:\n",
    "\n",
    "* `train_size = 8`, `test_size = 2`, and `k = 2`\n",
    "\n",
    "Then:\n",
    "\n",
    "* `train_neg = 16`\n",
    "* `test_neg = 4`\n",
    "\n",
    "Exactly what we expected.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **MODIFIED BEHAVIOR: `evaluate_on_all_unseen = true`**\n",
    "\n",
    "This mode **changes only how `test_neg` is constructed**, to enable evaluation on **all** possible test negative links.\n",
    "\n",
    "#### What happens:\n",
    "\n",
    "* `train_neg` is sampled just like before: `k * train_size`\n",
    "* `test_neg = all non-links` **minus** the links used for `train_neg`\n",
    "\n",
    "  * So the test set is evaluated **against all remaining unknown links** (i.e. a *denser* and *more realistic* test scenario)\n",
    "\n",
    "#### Implications:\n",
    "\n",
    "* We’re no longer controlling how many test negative examples we get. It will be:\n",
    "\n",
    "  ```\n",
    "  test_neg = total_possible_neg_links - train_neg\n",
    "  ```\n",
    "\n",
    "* So if my graph is sparse and `k` is small, we’ll get **a lot more test\\_neg** samples compared to the original test\\_pos.\n",
    "\n",
    "This mode is useful when:\n",
    "\n",
    "* You want to do **open-world** evaluation (i.e., predict whether any unseen link might be real).\n",
    "* You care about **ranking performance (e.g., AUC)** over the entire non-observed space.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Summary Table\n",
    "\n",
    "| Param                   | `evaluate_on_all_unseen = false` | `evaluate_on_all_unseen = true`  |\n",
    "| ----------------------- | -------------------------------- | -------------------------------- |\n",
    "| `train_neg` size        | `k * train_pos`                  | `k * train_pos`                  |\n",
    "| `test_neg` size         | `k * test_pos`                   | \\~all remaining non-links        |\n",
    "| Useful for...           | Controlled experiments           | Open-world, realistic evaluation |\n",
    "| Does negative sampling? | Yes (train & test)               | Yes (only train)                 |\n",
    "| AUC interpretation      | Controlled                       | More generalizable               |\n",
    "\n",
    "---\n",
    "\n",
    "#### Recommendation\n",
    "\n",
    "If we're testing **small/medium/large food webs** and care about generalization and ranking, the suggestion is:\n",
    "\n",
    "* `evaluate_on_all_unseen = true` **with AUC**\n",
    "* Use `evaluate_on_all_unseen = false` for more balanced per-instance metrics like precision, recall, or F1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FoodWebs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
