Processing dataset: Connera lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 170 / 268 (63.4%)
[DivideNet] Attempts made: 412 | Failed attempts: 242
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 248
    Train Negative: 496
    Test  Positive: 170
    Test  Negative: 340
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 744 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 510 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.1s
Progress: 100% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       81.25% |       0.6863 |          0.1000 |
|      10 |          50 |       00:00:00 |       99.22% |       0.0216 |          0.1000 |
|      20 |         100 |       00:00:00 |      100.00% |       0.0012 |          0.0900 |
|      30 |         150 |       00:00:00 |      100.00% |       0.0005 |          0.0810 |
|      40 |         200 |       00:00:00 |      100.00% |       0.0003 |          0.0729 |
|      50 |         250 |       00:00:00 |      100.00% |       0.0002 |          0.0656 |
|      60 |         300 |       00:00:00 |      100.00% |       0.0002 |          0.0590 |
|      70 |         350 |       00:00:00 |      100.00% |       0.0002 |          0.0531 |
|      80 |         400 |       00:00:00 |      100.00% |       0.0001 |          0.0478 |
|      90 |         450 |       00:00:00 |      100.00% |       0.0001 |          0.0430 |
|     100 |         500 |       00:00:00 |      100.00% |       0.0001 |          0.0387 |
|     110 |         550 |       00:00:00 |      100.00% |       0.0001 |          0.0349 |
|     120 |         600 |       00:00:00 |      100.00% |   9.4373e-05 |          0.0314 |
|     130 |         650 |       00:00:00 |      100.00% |   8.9335e-05 |          0.0282 |
|     140 |         700 |       00:00:00 |      100.00% |   8.5246e-05 |          0.0254 |
|     150 |         750 |       00:00:00 |      100.00% |   8.1770e-05 |          0.0229 |
|     160 |         800 |       00:00:00 |      100.00% |   7.8926e-05 |          0.0206 |
|     170 |         850 |       00:00:00 |      100.00% |   7.6509e-05 |          0.0185 |
|     180 |         900 |       00:00:01 |      100.00% |   7.4399e-05 |          0.0167 |
|     190 |         950 |       00:00:01 |      100.00% |   7.2631e-05 |          0.0150 |
|     200 |        1000 |       00:00:01 |      100.00% |   7.1239e-05 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9780, Recall: 0.5235, F1-Score: 0.6820
AUC: 0.9692
Processing dataset: Connera lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 170 / 248 (68.5%)
[DivideNet] Attempts made: 412 | Failed attempts: 242
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 248
    Train Negative: 496
    Test  Positive: 170
    Test  Negative: 340
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 744 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 510 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.1s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       60.16% |       0.6449 |          0.1000 |
|      10 |          50 |       00:00:00 |       99.22% |       0.0396 |          0.1000 |
|      20 |         100 |       00:00:00 |      100.00% |       0.0058 |          0.0900 |
|      30 |         150 |       00:00:00 |      100.00% |       0.0035 |          0.0810 |
|      40 |         200 |       00:00:00 |      100.00% |       0.0032 |          0.0729 |
|      50 |         250 |       00:00:00 |      100.00% |       0.0033 |          0.0656 |
|      60 |         300 |       00:00:00 |      100.00% |       0.0031 |          0.0590 |
|      70 |         350 |       00:00:00 |      100.00% |       0.0025 |          0.0531 |
|      80 |         400 |       00:00:00 |      100.00% |       0.0024 |          0.0478 |
|      90 |         450 |       00:00:00 |      100.00% |       0.0023 |          0.0430 |
|     100 |         500 |       00:00:00 |      100.00% |       0.0022 |          0.0387 |
|     110 |         550 |       00:00:00 |      100.00% |       0.0021 |          0.0349 |
|     120 |         600 |       00:00:00 |      100.00% |       0.0021 |          0.0314 |
|     130 |         650 |       00:00:00 |      100.00% |       0.0020 |          0.0282 |
|     140 |         700 |       00:00:00 |      100.00% |       0.0020 |          0.0254 |
|     150 |         750 |       00:00:00 |      100.00% |       0.0020 |          0.0229 |
|     160 |         800 |       00:00:00 |      100.00% |       0.0019 |          0.0206 |
|     170 |         850 |       00:00:01 |      100.00% |       0.0019 |          0.0185 |
|     180 |         900 |       00:00:01 |      100.00% |       0.0019 |          0.0167 |
|     190 |         950 |       00:00:01 |      100.00% |       0.0018 |          0.0150 |
|     200 |        1000 |       00:00:01 |      100.00% |       0.0018 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.4941, F1-Score: 0.6614
AUC: 0.9529
Processing dataset: Connera lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 171 / 227 (75.3%)
[DivideNet] Attempts made: 412 | Failed attempts: 241
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 247
    Train Negative: 494
    Test  Positive: 171
    Test  Negative: 342
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 741 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 513 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 99% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       88.28% |       0.5945 |          0.1000 |
|      10 |          50 |       00:00:00 |       99.22% |       0.0187 |          0.1000 |
|      20 |         100 |       00:00:00 |      100.00% |       0.0010 |          0.0900 |
|      30 |         150 |       00:00:00 |      100.00% |       0.0004 |          0.0810 |
|      40 |         200 |       00:00:00 |      100.00% |       0.0003 |          0.0729 |
|      50 |         250 |       00:00:00 |      100.00% |       0.0002 |          0.0656 |
|      60 |         300 |       00:00:00 |      100.00% |       0.0002 |          0.0590 |
|      70 |         350 |       00:00:00 |      100.00% |       0.0001 |          0.0531 |
|      80 |         400 |       00:00:00 |      100.00% |       0.0001 |          0.0478 |
|      90 |         450 |       00:00:00 |      100.00% |       0.0001 |          0.0430 |
|     100 |         500 |       00:00:00 |      100.00% |   9.9163e-05 |          0.0387 |
|     110 |         550 |       00:00:00 |      100.00% |   9.2025e-05 |          0.0349 |
|     120 |         600 |       00:00:00 |      100.00% |   8.6398e-05 |          0.0314 |
|     130 |         650 |       00:00:00 |      100.00% |   8.1858e-05 |          0.0282 |
|     140 |         700 |       00:00:00 |      100.00% |   7.8162e-05 |          0.0254 |
|     150 |         750 |       00:00:01 |      100.00% |   7.5041e-05 |          0.0229 |
|     160 |         800 |       00:00:01 |      100.00% |   7.2448e-05 |          0.0206 |
|     170 |         850 |       00:00:01 |      100.00% |   7.0287e-05 |          0.0185 |
|     180 |         900 |       00:00:01 |      100.00% |   6.8421e-05 |          0.0167 |
|     190 |         950 |       00:00:01 |      100.00% |   6.6818e-05 |          0.0150 |
|     200 |        1000 |       00:00:02 |      100.00% |   6.5440e-05 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9922, Recall: 0.7485, F1-Score: 0.8533
AUC: 0.9626
Processing dataset: Connera lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 170 / 206 (82.5%)
[DivideNet] Attempts made: 412 | Failed attempts: 242
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 248
    Train Negative: 496
    Test  Positive: 170
    Test  Negative: 340
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 744 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.2s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 510 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       23.44% |       0.7195 |          0.1000 |
|      10 |          50 |       00:00:00 |       99.22% |       0.0531 |          0.1000 |
|      20 |         100 |       00:00:00 |       99.22% |       0.0442 |          0.0900 |
|      30 |         150 |       00:00:00 |       99.22% |       0.0416 |          0.0810 |
|      40 |         200 |       00:00:00 |       99.22% |       0.0419 |          0.0729 |
|      50 |         250 |       00:00:00 |       99.22% |       0.0419 |          0.0656 |
|      60 |         300 |       00:00:00 |       99.22% |       0.0421 |          0.0590 |
|      70 |         350 |       00:00:00 |       99.22% |       0.0411 |          0.0531 |
|      80 |         400 |       00:00:00 |       99.22% |       0.0402 |          0.0478 |
|      90 |         450 |       00:00:00 |       99.22% |       0.0400 |          0.0430 |
|     100 |         500 |       00:00:00 |       99.22% |       0.0398 |          0.0387 |
|     110 |         550 |       00:00:00 |       99.22% |       0.0396 |          0.0349 |
|     120 |         600 |       00:00:01 |       99.22% |       0.0395 |          0.0314 |
|     130 |         650 |       00:00:01 |       99.22% |       0.0393 |          0.0282 |
|     140 |         700 |       00:00:01 |       99.22% |       0.0392 |          0.0254 |
|     150 |         750 |       00:00:01 |       99.22% |       0.0391 |          0.0229 |
|     160 |         800 |       00:00:01 |       99.22% |       0.0390 |          0.0206 |
|     170 |         850 |       00:00:01 |       99.22% |       0.0389 |          0.0185 |
|     180 |         900 |       00:00:01 |       99.22% |       0.0389 |          0.0167 |
|     190 |         950 |       00:00:01 |       99.22% |       0.0388 |          0.0150 |
|     200 |        1000 |       00:00:01 |       99.22% |       0.0387 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9840, Recall: 0.7235, F1-Score: 0.8339
AUC: 0.9446
Processing dataset: Connera lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 170 / 186 (91.4%)
[DivideNet] Attempts made: 412 | Failed attempts: 242
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 248
    Train Negative: 496
    Test  Positive: 170
    Test  Negative: 340
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 744 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.2s
Progress: 60% – Elapsed: 0.2s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.3s
Progress: 90% – Elapsed: 0.3s
Progress: 99% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 510 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.2s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.3s
Done. Total time: 0.3s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       39.06% |       0.6905 |          0.1000 |
|      10 |          50 |       00:00:00 |       99.22% |       0.0263 |          0.1000 |
|      20 |         100 |       00:00:00 |      100.00% |       0.0043 |          0.0900 |
|      30 |         150 |       00:00:00 |      100.00% |       0.0030 |          0.0810 |
|      40 |         200 |       00:00:00 |      100.00% |       0.0028 |          0.0729 |
|      50 |         250 |       00:00:00 |      100.00% |       0.0028 |          0.0656 |
|      60 |         300 |       00:00:00 |      100.00% |       0.0028 |          0.0590 |
|      70 |         350 |       00:00:00 |      100.00% |       0.0027 |          0.0531 |
|      80 |         400 |       00:00:00 |      100.00% |       0.0028 |          0.0478 |
|      90 |         450 |       00:00:00 |      100.00% |       0.0028 |          0.0430 |
|     100 |         500 |       00:00:00 |      100.00% |       0.0028 |          0.0387 |
|     110 |         550 |       00:00:01 |      100.00% |       0.0028 |          0.0349 |
|     120 |         600 |       00:00:01 |      100.00% |       0.0028 |          0.0314 |
|     130 |         650 |       00:00:01 |      100.00% |       0.0028 |          0.0282 |
|     140 |         700 |       00:00:01 |      100.00% |       0.0028 |          0.0254 |
|     150 |         750 |       00:00:01 |      100.00% |       0.0028 |          0.0229 |
|     160 |         800 |       00:00:01 |      100.00% |       0.0028 |          0.0206 |
|     170 |         850 |       00:00:01 |      100.00% |       0.0028 |          0.0185 |
|     180 |         900 |       00:00:01 |      100.00% |       0.0028 |          0.0167 |
|     190 |         950 |       00:00:01 |      100.00% |       0.0028 |          0.0150 |
|     200 |        1000 |       00:00:01 |      100.00% |       0.0028 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9806, Recall: 0.5941, F1-Score: 0.7399
AUC: 0.9717
Processing dataset: Connera lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 165 / 165 (100.0%)
[DivideNet] Attempts made: 384 | Failed attempts: 219
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 253
    Train Negative: 506
    Test  Positive: 165
    Test  Negative: 330
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 759 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.2s
Progress: 69% – Elapsed: 0.2s
Progress: 79% – Elapsed: 0.2s
Progress: 89% – Elapsed: 0.3s
Progress: 99% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 495 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.2s
Progress: 69% – Elapsed: 0.2s
Progress: 79% – Elapsed: 0.3s
Progress: 89% – Elapsed: 0.3s
Progress: 99% – Elapsed: 0.3s
Done. Total time: 0.3s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       64.06% |       0.7052 |          0.1000 |
|      10 |          50 |       00:00:00 |       92.19% |       0.1313 |          0.1000 |
|      20 |         100 |       00:00:00 |       99.22% |       0.0476 |          0.0900 |
|      30 |         150 |       00:00:00 |       99.22% |       0.0416 |          0.0810 |
|      40 |         200 |       00:00:00 |       99.22% |       0.0407 |          0.0729 |
|      50 |         250 |       00:00:00 |       99.22% |       0.0381 |          0.0656 |
|      60 |         300 |       00:00:00 |       99.22% |       0.0378 |          0.0590 |
|      70 |         350 |       00:00:00 |       99.22% |       0.0375 |          0.0531 |
|      80 |         400 |       00:00:00 |       99.22% |       0.0371 |          0.0478 |
|      90 |         450 |       00:00:01 |       99.22% |       0.0369 |          0.0430 |
|     100 |         500 |       00:00:01 |       99.22% |       0.0367 |          0.0387 |
|     110 |         550 |       00:00:01 |       99.22% |       0.0367 |          0.0349 |
|     120 |         600 |       00:00:01 |       99.22% |       0.0365 |          0.0314 |
|     130 |         650 |       00:00:01 |       99.22% |       0.0366 |          0.0282 |
|     140 |         700 |       00:00:01 |       99.22% |       0.0364 |          0.0254 |
|     150 |         750 |       00:00:01 |       99.22% |       0.0363 |          0.0229 |
|     160 |         800 |       00:00:01 |       99.22% |       0.0362 |          0.0206 |
|     170 |         850 |       00:00:01 |       99.22% |       0.0362 |          0.0185 |
|     180 |         900 |       00:00:01 |       99.22% |       0.0362 |          0.0167 |
|     190 |         950 |       00:00:01 |       99.22% |       0.0361 |          0.0150 |
|     200 |        1000 |       00:00:01 |       99.22% |       0.0362 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.15, Precision: 0.9744, Recall: 0.9212, F1-Score: 0.9470
AUC: 0.9960
Processing dataset: Connera lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 145 / 145 (100.0%)
[DivideNet] Attempts made: 330 | Failed attempts: 185
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 273
    Train Negative: 546
    Test  Positive: 145
    Test  Negative: 290
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 819 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.2s
Progress: 69% – Elapsed: 0.2s
Progress: 79% – Elapsed: 0.2s
Progress: 89% – Elapsed: 0.3s
Progress: 99% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 435 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 99% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       82.81% |       0.6743 |          0.1000 |
|       9 |          50 |       00:00:00 |       99.22% |       0.0335 |          0.1000 |
|      17 |         100 |       00:00:00 |      100.00% |       0.0068 |          0.0900 |
|      25 |         150 |       00:00:00 |      100.00% |       0.0038 |          0.0810 |
|      34 |         200 |       00:00:00 |      100.00% |       0.0037 |          0.0729 |
|      42 |         250 |       00:00:00 |      100.00% |       0.0032 |          0.0656 |
|      50 |         300 |       00:00:00 |      100.00% |       0.0036 |          0.0656 |
|      59 |         350 |       00:00:00 |      100.00% |       0.0031 |          0.0590 |
|      67 |         400 |       00:00:00 |      100.00% |       0.0028 |          0.0531 |
|      75 |         450 |       00:00:00 |      100.00% |       0.0033 |          0.0478 |
|      84 |         500 |       00:00:00 |      100.00% |       0.0029 |          0.0430 |
|      92 |         550 |       00:00:00 |      100.00% |       0.0028 |          0.0387 |
|     100 |         600 |       00:00:00 |      100.00% |       0.0032 |          0.0387 |
|     109 |         650 |       00:00:00 |      100.00% |       0.0028 |          0.0349 |
|     117 |         700 |       00:00:01 |      100.00% |       0.0028 |          0.0314 |
|     125 |         750 |       00:00:01 |      100.00% |       0.0030 |          0.0282 |
|     134 |         800 |       00:00:01 |      100.00% |       0.0027 |          0.0254 |
|     142 |         850 |       00:00:01 |      100.00% |       0.0028 |          0.0229 |
|     150 |         900 |       00:00:01 |      100.00% |       0.0029 |          0.0229 |
|     159 |         950 |       00:00:02 |      100.00% |       0.0027 |          0.0206 |
|     167 |        1000 |       00:00:02 |      100.00% |       0.0029 |          0.0185 |
|     175 |        1050 |       00:00:02 |      100.00% |       0.0029 |          0.0167 |
|     184 |        1100 |       00:00:02 |      100.00% |       0.0026 |          0.0150 |
|     192 |        1150 |       00:00:02 |      100.00% |       0.0029 |          0.0135 |
|     200 |        1200 |       00:00:02 |      100.00% |       0.0028 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9714, Recall: 0.9379, F1-Score: 0.9544
AUC: 0.9933
Processing dataset: Connera lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 124 / 124 (100.0%)
[DivideNet] Attempts made: 254 | Failed attempts: 130
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 294
    Train Negative: 588
    Test  Positive: 124
    Test  Negative: 248
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 882 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.2s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.3s
Progress: 100% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 372 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.1s
Progress: 99% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       92.19% |       0.5963 |          0.1000 |
|       9 |          50 |       00:00:00 |       93.75% |       0.1449 |          0.1000 |
|      17 |         100 |       00:00:00 |       99.22% |       0.0367 |          0.0900 |
|      25 |         150 |       00:00:00 |      100.00% |       0.0058 |          0.0810 |
|      34 |         200 |       00:00:00 |       99.22% |       0.0420 |          0.0729 |
|      42 |         250 |       00:00:00 |       99.22% |       0.0420 |          0.0656 |
|      50 |         300 |       00:00:00 |      100.00% |       0.0031 |          0.0656 |
|      59 |         350 |       00:00:00 |       99.22% |       0.0426 |          0.0590 |
|      67 |         400 |       00:00:00 |       99.22% |       0.0384 |          0.0531 |
|      75 |         450 |       00:00:01 |      100.00% |       0.0045 |          0.0478 |
|      84 |         500 |       00:00:01 |       99.22% |       0.0394 |          0.0430 |
|      92 |         550 |       00:00:01 |       99.22% |       0.0390 |          0.0387 |
|     100 |         600 |       00:00:01 |      100.00% |       0.0037 |          0.0387 |
|     109 |         650 |       00:00:01 |       99.22% |       0.0390 |          0.0349 |
|     117 |         700 |       00:00:01 |       99.22% |       0.0388 |          0.0314 |
|     125 |         750 |       00:00:01 |      100.00% |       0.0035 |          0.0282 |
|     134 |         800 |       00:00:01 |       99.22% |       0.0386 |          0.0254 |
|     142 |         850 |       00:00:01 |       99.22% |       0.0385 |          0.0229 |
|     150 |         900 |       00:00:02 |      100.00% |       0.0034 |          0.0229 |
|     159 |         950 |       00:00:02 |       99.22% |       0.0384 |          0.0206 |
|     167 |        1000 |       00:00:02 |       99.22% |       0.0383 |          0.0185 |
|     175 |        1050 |       00:00:02 |      100.00% |       0.0032 |          0.0167 |
|     184 |        1100 |       00:00:02 |       99.22% |       0.0381 |          0.0150 |
|     192 |        1150 |       00:00:02 |       99.22% |       0.0381 |          0.0135 |
|     200 |        1200 |       00:00:02 |      100.00% |       0.0032 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9744, Recall: 0.9194, F1-Score: 0.9461
AUC: 0.9931
Processing dataset: Connera lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 103 / 103 (100.0%)
[DivideNet] Attempts made: 219 | Failed attempts: 116
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 315
    Train Negative: 630
    Test  Positive: 103
    Test  Negative: 206
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 945 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.2s
Progress: 50% – Elapsed: 0.2s
Progress: 60% – Elapsed: 0.2s
Progress: 70% – Elapsed: 0.3s
Progress: 80% – Elapsed: 0.3s
Progress: 90% – Elapsed: 0.4s
Progress: 99% – Elapsed: 0.4s
Done. Total time: 0.4s
Encoding 309 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 58% – Elapsed: 0.1s
Progress: 68% – Elapsed: 0.1s
Progress: 78% – Elapsed: 0.1s
Progress: 87% – Elapsed: 0.1s
Progress: 97% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       66.41% |       0.6786 |          0.1000 |
|       8 |          50 |       00:00:00 |       99.22% |       0.0370 |          0.1000 |
|      15 |         100 |       00:00:00 |       98.44% |       0.0863 |          0.0900 |
|      22 |         150 |       00:00:00 |      100.00% |       0.0029 |          0.0810 |
|      29 |         200 |       00:00:00 |      100.00% |       0.0018 |          0.0810 |
|      36 |         250 |       00:00:00 |      100.00% |       0.0034 |          0.0729 |
|      43 |         300 |       00:00:00 |      100.00% |       0.0030 |          0.0656 |
|      50 |         350 |       00:00:00 |      100.00% |       0.0014 |          0.0656 |
|      58 |         400 |       00:00:00 |      100.00% |       0.0017 |          0.0590 |
|      65 |         450 |       00:00:01 |       98.44% |       0.0496 |          0.0531 |
|      72 |         500 |       00:00:01 |      100.00% |       0.0021 |          0.0478 |
|      79 |         550 |       00:00:01 |      100.00% |       0.0018 |          0.0478 |
|      86 |         600 |       00:00:01 |      100.00% |       0.0015 |          0.0430 |
|      93 |         650 |       00:00:01 |      100.00% |       0.0018 |          0.0387 |
|     100 |         700 |       00:00:01 |      100.00% |       0.0010 |          0.0387 |
|     108 |         750 |       00:00:02 |      100.00% |       0.0011 |          0.0349 |
|     115 |         800 |       00:00:02 |       99.22% |       0.0446 |          0.0314 |
|     122 |         850 |       00:00:02 |      100.00% |       0.0017 |          0.0282 |
|     129 |         900 |       00:00:02 |      100.00% |       0.0013 |          0.0282 |
|     136 |         950 |       00:00:02 |      100.00% |       0.0014 |          0.0254 |
|     143 |        1000 |       00:00:02 |      100.00% |       0.0014 |          0.0229 |
|     150 |        1050 |       00:00:03 |      100.00% |       0.0010 |          0.0229 |
|     158 |        1100 |       00:00:03 |      100.00% |       0.0011 |          0.0206 |
|     165 |        1150 |       00:00:03 |       99.22% |       0.0434 |          0.0185 |
|     172 |        1200 |       00:00:03 |      100.00% |       0.0015 |          0.0167 |
|     179 |        1250 |       00:00:04 |      100.00% |       0.0011 |          0.0167 |
|     186 |        1300 |       00:00:04 |      100.00% |       0.0013 |          0.0150 |
|     193 |        1350 |       00:00:04 |      100.00% |       0.0013 |          0.0135 |
|     200 |        1400 |       00:00:04 |      100.00% |       0.0010 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9900, Recall: 0.9612, F1-Score: 0.9754
AUC: 0.9989
Processing dataset: Connera lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 83 / 83 (100.0%)
[DivideNet] Attempts made: 195 | Failed attempts: 112
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 335
    Train Negative: 670
    Test  Positive: 83
    Test  Negative: 166
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 1005 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.2s
Progress: 60% – Elapsed: 0.2s
Progress: 70% – Elapsed: 0.3s
Progress: 80% – Elapsed: 0.3s
Progress: 90% – Elapsed: 0.4s
Progress: 100% – Elapsed: 0.5s
Done. Total time: 0.5s
Encoding 249 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.1s
Progress: 48% – Elapsed: 0.1s
Progress: 58% – Elapsed: 0.1s
Progress: 67% – Elapsed: 0.1s
Progress: 77% – Elapsed: 0.1s
Progress: 87% – Elapsed: 0.1s
Progress: 96% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       66.41% |       0.6916 |          0.1000 |
|       8 |          50 |       00:00:00 |      100.00% |       0.0049 |          0.1000 |
|      15 |         100 |       00:00:00 |      100.00% |       0.0017 |          0.0900 |
|      22 |         150 |       00:00:00 |      100.00% |       0.0020 |          0.0810 |
|      29 |         200 |       00:00:00 |      100.00% |       0.0017 |          0.0810 |
|      36 |         250 |       00:00:00 |      100.00% |       0.0012 |          0.0729 |
|      43 |         300 |       00:00:00 |       99.22% |       0.0437 |          0.0656 |
|      50 |         350 |       00:00:00 |      100.00% |       0.0012 |          0.0656 |
|      58 |         400 |       00:00:00 |      100.00% |       0.0016 |          0.0590 |
|      65 |         450 |       00:00:00 |      100.00% |       0.0013 |          0.0531 |
|      72 |         500 |       00:00:00 |      100.00% |       0.0013 |          0.0478 |
|      79 |         550 |       00:00:00 |      100.00% |       0.0015 |          0.0478 |
|      86 |         600 |       00:00:00 |      100.00% |       0.0011 |          0.0430 |
|      93 |         650 |       00:00:00 |       99.22% |       0.0429 |          0.0387 |
|     100 |         700 |       00:00:01 |      100.00% |       0.0011 |          0.0387 |
|     108 |         750 |       00:00:01 |      100.00% |       0.0014 |          0.0349 |
|     115 |         800 |       00:00:01 |      100.00% |       0.0013 |          0.0314 |
|     122 |         850 |       00:00:01 |      100.00% |       0.0012 |          0.0282 |
|     129 |         900 |       00:00:01 |      100.00% |       0.0014 |          0.0282 |
|     136 |         950 |       00:00:01 |      100.00% |       0.0010 |          0.0254 |
|     143 |        1000 |       00:00:01 |       99.22% |       0.0426 |          0.0229 |
|     150 |        1050 |       00:00:01 |      100.00% |       0.0011 |          0.0229 |
|     158 |        1100 |       00:00:01 |      100.00% |       0.0014 |          0.0206 |
|     165 |        1150 |       00:00:01 |      100.00% |       0.0013 |          0.0185 |
|     172 |        1200 |       00:00:01 |      100.00% |       0.0012 |          0.0167 |
|     179 |        1250 |       00:00:01 |      100.00% |       0.0014 |          0.0167 |
|     186 |        1300 |       00:00:01 |      100.00% |       0.0010 |          0.0150 |
|     193 |        1350 |       00:00:01 |       99.22% |       0.0424 |          0.0135 |
|     200 |        1400 |       00:00:02 |      100.00% |       0.0011 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9881, Recall: 1.0000, F1-Score: 0.9940
AUC: 0.9995
Processing dataset: Connera lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 62 / 62 (100.0%)
[DivideNet] Attempts made: 144 | Failed attempts: 82
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 356
    Train Negative: 712
    Test  Positive: 62
    Test  Negative: 124
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 1068 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.2s
Progress: 69% – Elapsed: 0.2s
Progress: 79% – Elapsed: 0.2s
Progress: 89% – Elapsed: 0.3s
Progress: 99% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 186 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 77% – Elapsed: 0.0s
Progress: 87% – Elapsed: 0.0s
Progress: 97% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       66.41% |       0.6758 |          0.1000 |
|       7 |          50 |       00:00:00 |       96.88% |       0.0742 |          0.1000 |
|      13 |         100 |       00:00:00 |       99.22% |       0.0206 |          0.0900 |
|      19 |         150 |       00:00:00 |      100.00% |       0.0064 |          0.0900 |
|      25 |         200 |       00:00:00 |       99.22% |       0.0390 |          0.0810 |
|      32 |         250 |       00:00:00 |      100.00% |       0.0043 |          0.0729 |
|      38 |         300 |       00:00:00 |      100.00% |       0.0045 |          0.0729 |
|      44 |         350 |       00:00:00 |      100.00% |       0.0018 |          0.0656 |
|      50 |         400 |       00:00:00 |       99.22% |       0.0398 |          0.0656 |
|      57 |         450 |       00:00:00 |      100.00% |       0.0029 |          0.0590 |
|      63 |         500 |       00:00:01 |      100.00% |       0.0023 |          0.0531 |
|      69 |         550 |       00:00:01 |      100.00% |       0.0019 |          0.0531 |
|      75 |         600 |       00:00:01 |       99.22% |       0.0387 |          0.0478 |
|      82 |         650 |       00:00:01 |      100.00% |       0.0022 |          0.0430 |
|      88 |         700 |       00:00:01 |      100.00% |       0.0021 |          0.0430 |
|      94 |         750 |       00:00:01 |      100.00% |       0.0020 |          0.0387 |
|     100 |         800 |       00:00:01 |       99.22% |       0.0379 |          0.0387 |
|     107 |         850 |       00:00:01 |      100.00% |       0.0023 |          0.0349 |
|     113 |         900 |       00:00:01 |      100.00% |       0.0019 |          0.0314 |
|     119 |         950 |       00:00:01 |      100.00% |       0.0019 |          0.0314 |
|     125 |        1000 |       00:00:01 |       99.22% |       0.0389 |          0.0282 |
|     132 |        1050 |       00:00:01 |      100.00% |       0.0023 |          0.0254 |
|     138 |        1100 |       00:00:01 |      100.00% |       0.0018 |          0.0254 |
|     144 |        1150 |       00:00:01 |      100.00% |       0.0020 |          0.0229 |
|     150 |        1200 |       00:00:01 |       99.22% |       0.0385 |          0.0229 |
|     157 |        1250 |       00:00:02 |      100.00% |       0.0021 |          0.0206 |
|     163 |        1300 |       00:00:02 |      100.00% |       0.0018 |          0.0185 |
|     169 |        1350 |       00:00:02 |      100.00% |       0.0019 |          0.0185 |
|     175 |        1400 |       00:00:02 |       99.22% |       0.0381 |          0.0167 |
|     182 |        1450 |       00:00:03 |      100.00% |       0.0021 |          0.0150 |
|     188 |        1500 |       00:00:03 |      100.00% |       0.0016 |          0.0150 |
|     194 |        1550 |       00:00:03 |      100.00% |       0.0019 |          0.0135 |
|     200 |        1600 |       00:00:03 |       99.22% |       0.0383 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.9839, F1-Score: 0.9919
AUC: 1.0000
Processing dataset: Connera lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 42 / 42 (100.0%)
[DivideNet] Attempts made: 94 | Failed attempts: 52
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 376
    Train Negative: 752
    Test  Positive: 42
    Test  Negative: 84
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 1128 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.2s
Progress: 50% – Elapsed: 0.2s
Progress: 60% – Elapsed: 0.2s
Progress: 70% – Elapsed: 0.3s
Progress: 79% – Elapsed: 0.3s
Progress: 89% – Elapsed: 0.4s
Progress: 99% – Elapsed: 0.4s
Done. Total time: 0.4s
Encoding 126 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 76% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.0s
Progress: 95% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       65.62% |       0.6670 |          0.1000 |
|       7 |          50 |       00:00:00 |       98.44% |       0.0579 |          0.1000 |
|      13 |         100 |       00:00:00 |      100.00% |       0.0025 |          0.0900 |
|      19 |         150 |       00:00:00 |      100.00% |       0.0029 |          0.0900 |
|      25 |         200 |       00:00:00 |      100.00% |       0.0023 |          0.0810 |
|      32 |         250 |       00:00:00 |      100.00% |       0.0029 |          0.0729 |
|      38 |         300 |       00:00:00 |      100.00% |       0.0023 |          0.0729 |
|      44 |         350 |       00:00:00 |      100.00% |       0.0023 |          0.0656 |
|      50 |         400 |       00:00:00 |      100.00% |       0.0022 |          0.0656 |
|      57 |         450 |       00:00:00 |      100.00% |       0.0027 |          0.0590 |
|      63 |         500 |       00:00:00 |      100.00% |       0.0023 |          0.0531 |
|      69 |         550 |       00:00:00 |      100.00% |       0.0021 |          0.0531 |
|      75 |         600 |       00:00:00 |      100.00% |       0.0021 |          0.0478 |
|      82 |         650 |       00:00:01 |      100.00% |       0.0027 |          0.0430 |
|      88 |         700 |       00:00:01 |      100.00% |       0.0023 |          0.0430 |
|      94 |         750 |       00:00:01 |      100.00% |       0.0020 |          0.0387 |
|     100 |         800 |       00:00:01 |      100.00% |       0.0021 |          0.0387 |
|     107 |         850 |       00:00:01 |      100.00% |       0.0027 |          0.0349 |
|     113 |         900 |       00:00:01 |      100.00% |       0.0023 |          0.0314 |
|     119 |         950 |       00:00:01 |      100.00% |       0.0020 |          0.0314 |
|     125 |        1000 |       00:00:01 |      100.00% |       0.0021 |          0.0282 |
|     132 |        1050 |       00:00:01 |      100.00% |       0.0026 |          0.0254 |
|     138 |        1100 |       00:00:01 |      100.00% |       0.0023 |          0.0254 |
|     144 |        1150 |       00:00:01 |      100.00% |       0.0020 |          0.0229 |
|     150 |        1200 |       00:00:02 |      100.00% |       0.0021 |          0.0229 |
|     157 |        1250 |       00:00:02 |      100.00% |       0.0026 |          0.0206 |
|     163 |        1300 |       00:00:02 |      100.00% |       0.0024 |          0.0185 |
|     169 |        1350 |       00:00:02 |      100.00% |       0.0019 |          0.0185 |
|     175 |        1400 |       00:00:02 |      100.00% |       0.0021 |          0.0167 |
|     182 |        1450 |       00:00:02 |      100.00% |       0.0026 |          0.0150 |
|     188 |        1500 |       00:00:02 |      100.00% |       0.0024 |          0.0150 |
|     194 |        1550 |       00:00:02 |      100.00% |       0.0019 |          0.0135 |
|     200 |        1600 |       00:00:02 |      100.00% |       0.0021 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000
AUC: 1.0000
Processing dataset: Connera lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 169 / 371 (45.6%)
[DivideNet] Attempts made: 412 | Failed attempts: 243
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 249
    Train Negative: 498
    Test  Positive: 169
    Test  Negative: 338
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 747 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.2s
Progress: 79% – Elapsed: 0.2s
Progress: 89% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 507 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       36.72% |       0.8125 |          0.1000 |
|      10 |          50 |       00:00:00 |       99.22% |       0.0378 |          0.1000 |
|      20 |         100 |       00:00:00 |      100.00% |       0.0040 |          0.0900 |
|      30 |         150 |       00:00:00 |      100.00% |       0.0012 |          0.0810 |
|      40 |         200 |       00:00:00 |      100.00% |       0.0005 |          0.0729 |
|      50 |         250 |       00:00:00 |      100.00% |       0.0004 |          0.0656 |
|      60 |         300 |       00:00:00 |      100.00% |       0.0003 |          0.0590 |
|      70 |         350 |       00:00:00 |      100.00% |       0.0002 |          0.0531 |
|      80 |         400 |       00:00:00 |      100.00% |       0.0002 |          0.0478 |
|      90 |         450 |       00:00:00 |      100.00% |       0.0002 |          0.0430 |
|     100 |         500 |       00:00:00 |      100.00% |       0.0002 |          0.0387 |
|     110 |         550 |       00:00:00 |      100.00% |       0.0002 |          0.0349 |
|     120 |         600 |       00:00:00 |      100.00% |       0.0002 |          0.0314 |
|     130 |         650 |       00:00:00 |      100.00% |       0.0001 |          0.0282 |
|     140 |         700 |       00:00:00 |      100.00% |       0.0001 |          0.0254 |
|     150 |         750 |       00:00:00 |      100.00% |       0.0001 |          0.0229 |
|     160 |         800 |       00:00:00 |      100.00% |       0.0001 |          0.0206 |
|     170 |         850 |       00:00:01 |      100.00% |       0.0001 |          0.0185 |
|     180 |         900 |       00:00:01 |      100.00% |       0.0001 |          0.0167 |
|     190 |         950 |       00:00:01 |      100.00% |       0.0001 |          0.0150 |
|     200 |        1000 |       00:00:01 |      100.00% |       0.0001 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9659, Recall: 0.5030, F1-Score: 0.6615
AUC: 0.9604
Processing dataset: Connera lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 170 / 351 (48.4%)
[DivideNet] Attempts made: 412 | Failed attempts: 242
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 248
    Train Negative: 496
    Test  Positive: 170
    Test  Negative: 340
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 744 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 510 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       65.62% |       0.7413 |          0.1000 |
|      10 |          50 |       00:00:00 |      100.00% |       0.0261 |          0.1000 |
|      20 |         100 |       00:00:00 |      100.00% |       0.0065 |          0.0900 |
|      30 |         150 |       00:00:00 |      100.00% |       0.0056 |          0.0810 |
|      40 |         200 |       00:00:00 |      100.00% |       0.0055 |          0.0729 |
|      50 |         250 |       00:00:00 |      100.00% |       0.0052 |          0.0656 |
|      60 |         300 |       00:00:00 |      100.00% |       0.0051 |          0.0590 |
|      70 |         350 |       00:00:00 |      100.00% |       0.0049 |          0.0531 |
|      80 |         400 |       00:00:00 |      100.00% |       0.0048 |          0.0478 |
|      90 |         450 |       00:00:00 |      100.00% |       0.0047 |          0.0430 |
|     100 |         500 |       00:00:00 |      100.00% |       0.0047 |          0.0387 |
|     110 |         550 |       00:00:00 |      100.00% |       0.0046 |          0.0349 |
|     120 |         600 |       00:00:00 |      100.00% |       0.0045 |          0.0314 |
|     130 |         650 |       00:00:00 |      100.00% |       0.0044 |          0.0282 |
|     140 |         700 |       00:00:00 |      100.00% |       0.0044 |          0.0254 |
|     150 |         750 |       00:00:01 |      100.00% |       0.0044 |          0.0229 |
|     160 |         800 |       00:00:01 |      100.00% |       0.0043 |          0.0206 |
|     170 |         850 |       00:00:01 |      100.00% |       0.0042 |          0.0185 |
|     180 |         900 |       00:00:01 |      100.00% |       0.0043 |          0.0167 |
|     190 |         950 |       00:00:01 |      100.00% |       0.0043 |          0.0150 |
|     200 |        1000 |       00:00:01 |      100.00% |       0.0042 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9829, Recall: 0.6765, F1-Score: 0.8014
AUC: 0.9816
Processing dataset: Connera lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 170 / 330 (51.5%)
[DivideNet] Attempts made: 412 | Failed attempts: 242
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 248
    Train Negative: 496
    Test  Positive: 170
    Test  Negative: 340
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 744 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.2s
Progress: 60% – Elapsed: 0.2s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.3s
Progress: 90% – Elapsed: 0.3s
Progress: 99% – Elapsed: 0.4s
Done. Total time: 0.4s
Encoding 510 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.2s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.3s
Done. Total time: 0.3s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       66.41% |       0.7243 |          0.1000 |
|      10 |          50 |       00:00:00 |       98.44% |       0.0649 |          0.1000 |
|      20 |         100 |       00:00:00 |       99.22% |       0.0553 |          0.0900 |
|      30 |         150 |       00:00:00 |       99.22% |       0.0509 |          0.0810 |
|      40 |         200 |       00:00:00 |       99.22% |       0.0447 |          0.0729 |
|      50 |         250 |       00:00:00 |       99.22% |       0.0479 |          0.0656 |
|      60 |         300 |       00:00:00 |       99.22% |       0.0475 |          0.0590 |
|      70 |         350 |       00:00:00 |       99.22% |       0.0480 |          0.0531 |
|      80 |         400 |       00:00:00 |       99.22% |       0.0472 |          0.0478 |
|      90 |         450 |       00:00:00 |       99.22% |       0.0467 |          0.0430 |
|     100 |         500 |       00:00:00 |       99.22% |       0.0463 |          0.0387 |
|     110 |         550 |       00:00:00 |       99.22% |       0.0458 |          0.0349 |
|     120 |         600 |       00:00:01 |       99.22% |       0.0454 |          0.0314 |
|     130 |         650 |       00:00:01 |       99.22% |       0.0451 |          0.0282 |
|     140 |         700 |       00:00:01 |       99.22% |       0.0448 |          0.0254 |
|     150 |         750 |       00:00:01 |       99.22% |       0.0446 |          0.0229 |
|     160 |         800 |       00:00:01 |       99.22% |       0.0445 |          0.0206 |
|     170 |         850 |       00:00:01 |       99.22% |       0.0443 |          0.0185 |
|     180 |         900 |       00:00:01 |       99.22% |       0.0441 |          0.0167 |
|     190 |         950 |       00:00:01 |       99.22% |       0.0439 |          0.0150 |
|     200 |        1000 |       00:00:01 |       99.22% |       0.0438 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9483, Recall: 0.6471, F1-Score: 0.7692
AUC: 0.9639
Processing dataset: Connera lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 171 / 309 (55.3%)
[DivideNet] Attempts made: 412 | Failed attempts: 241
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 247
    Train Negative: 494
    Test  Positive: 171
    Test  Negative: 342
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 741 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 513 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       35.94% |       0.7382 |          0.1000 |
|      10 |          50 |       00:00:00 |       98.44% |       0.0517 |          0.1000 |
|      20 |         100 |       00:00:00 |      100.00% |       0.0070 |          0.0900 |
|      30 |         150 |       00:00:00 |      100.00% |       0.0038 |          0.0810 |
|      40 |         200 |       00:00:00 |      100.00% |       0.0023 |          0.0729 |
|      50 |         250 |       00:00:00 |       99.22% |       0.0291 |          0.0656 |
|      60 |         300 |       00:00:00 |      100.00% |       0.0017 |          0.0590 |
|      70 |         350 |       00:00:00 |      100.00% |       0.0026 |          0.0531 |
|      80 |         400 |       00:00:00 |      100.00% |       0.0023 |          0.0478 |
|      90 |         450 |       00:00:00 |      100.00% |       0.0022 |          0.0430 |
|     100 |         500 |       00:00:00 |      100.00% |       0.0021 |          0.0387 |
|     110 |         550 |       00:00:00 |      100.00% |       0.0020 |          0.0349 |
|     120 |         600 |       00:00:00 |      100.00% |       0.0020 |          0.0314 |
|     130 |         650 |       00:00:00 |      100.00% |       0.0019 |          0.0282 |
|     140 |         700 |       00:00:00 |      100.00% |       0.0019 |          0.0254 |
|     150 |         750 |       00:00:00 |      100.00% |       0.0018 |          0.0229 |
|     160 |         800 |       00:00:00 |      100.00% |       0.0018 |          0.0206 |
|     170 |         850 |       00:00:00 |      100.00% |       0.0018 |          0.0185 |
|     180 |         900 |       00:00:01 |      100.00% |       0.0018 |          0.0167 |
|     190 |         950 |       00:00:01 |      100.00% |       0.0017 |          0.0150 |
|     200 |        1000 |       00:00:01 |      100.00% |       0.0017 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9919, Recall: 0.7135, F1-Score: 0.8299
AUC: 0.9857
Processing dataset: Connera lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 170 / 289 (58.8%)
[DivideNet] Attempts made: 412 | Failed attempts: 242
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 248
    Train Negative: 496
    Test  Positive: 170
    Test  Negative: 340
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 744 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 510 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |        7.81% |       0.7280 |          0.1000 |
|      10 |          50 |       00:00:00 |       96.88% |       0.0539 |          0.1000 |
|      20 |         100 |       00:00:00 |      100.00% |       0.0068 |          0.0900 |
|      30 |         150 |       00:00:00 |      100.00% |       0.0062 |          0.0810 |
|      40 |         200 |       00:00:00 |      100.00% |       0.0060 |          0.0729 |
|      50 |         250 |       00:00:00 |      100.00% |       0.0057 |          0.0656 |
|      60 |         300 |       00:00:00 |      100.00% |       0.0054 |          0.0590 |
|      70 |         350 |       00:00:00 |      100.00% |       0.0051 |          0.0531 |
|      80 |         400 |       00:00:00 |      100.00% |       0.0050 |          0.0478 |
|      90 |         450 |       00:00:00 |      100.00% |       0.0048 |          0.0430 |
|     100 |         500 |       00:00:00 |      100.00% |       0.0047 |          0.0387 |
|     110 |         550 |       00:00:00 |      100.00% |       0.0045 |          0.0349 |
|     120 |         600 |       00:00:00 |      100.00% |       0.0043 |          0.0314 |
|     130 |         650 |       00:00:00 |      100.00% |       0.0042 |          0.0282 |
|     140 |         700 |       00:00:00 |      100.00% |       0.0041 |          0.0254 |
|     150 |         750 |       00:00:00 |      100.00% |       0.0041 |          0.0229 |
|     160 |         800 |       00:00:00 |      100.00% |       0.0040 |          0.0206 |
|     170 |         850 |       00:00:01 |      100.00% |       0.0039 |          0.0185 |
|     180 |         900 |       00:00:01 |      100.00% |       0.0039 |          0.0167 |
|     190 |         950 |       00:00:01 |      100.00% |       0.0038 |          0.0150 |
|     200 |        1000 |       00:00:01 |      100.00% |       0.0038 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9841, Recall: 0.7294, F1-Score: 0.8378
AUC: 0.9874
