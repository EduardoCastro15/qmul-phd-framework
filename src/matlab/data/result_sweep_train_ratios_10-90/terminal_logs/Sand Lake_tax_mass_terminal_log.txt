Processing dataset: Sand Lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Skipping connectivity check (adaptive mode, n = 29).
[DivideNet] Using directed logic. Connectivity check: 0
[DivideNet] Test links accepted: 52 / 52 (100.0%)
[DivideNet] Attempts made: 52 | Failed attempts: 0
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 30
    Train Negative: 60
    Test  Positive: 52
    Test  Negative: 104
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 90 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.0s
Progress: 90% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
Encoding 156 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 77% – Elapsed: 0.0s
Progress: 87% – Elapsed: 0.0s
Progress: 96% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       33.33% |       0.6981 |          0.1000 |
|      50 |          50 |       00:00:00 |       95.56% |       0.0809 |          0.0656 |
|     100 |         100 |       00:00:00 |       95.56% |       0.0756 |          0.0387 |
|     150 |         150 |       00:00:00 |       95.56% |       0.0754 |          0.0229 |
|     200 |         200 |       00:00:00 |       95.56% |       0.0754 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.45, Precision: 1.0000, Recall: 0.7885, F1-Score: 0.8817
AUC: 0.9103
Processing dataset: Sand Lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Skipping connectivity check (adaptive mode, n = 29).
[DivideNet] Using directed logic. Connectivity check: 0
[DivideNet] Test links accepted: 48 / 48 (100.0%)
[DivideNet] Attempts made: 48 | Failed attempts: 0
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 34
    Train Negative: 68
    Test  Positive: 48
    Test  Negative: 96
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 102 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 59% – Elapsed: 0.0s
Progress: 69% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 88% – Elapsed: 0.0s
Progress: 98% – Elapsed: 0.0s
Done. Total time: 0.0s
Encoding 144 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 88% – Elapsed: 0.0s
Progress: 97% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       66.67% |       0.7076 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0099 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0014 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0010 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0008 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.85, Precision: 1.0000, Recall: 0.6875, F1-Score: 0.8148
AUC: 0.9287
Processing dataset: Sand Lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Skipping connectivity check (adaptive mode, n = 29).
[DivideNet] Using directed logic. Connectivity check: 0
[DivideNet] Test links accepted: 44 / 44 (100.0%)
[DivideNet] Attempts made: 44 | Failed attempts: 0
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 38
    Train Negative: 76
    Test  Positive: 44
    Test  Negative: 88
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 114 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 77% – Elapsed: 0.0s
Progress: 87% – Elapsed: 0.0s
Progress: 96% – Elapsed: 0.0s
Done. Total time: 0.0s
Encoding 132 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 59% – Elapsed: 0.0s
Progress: 69% – Elapsed: 0.0s
Progress: 79% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 98% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       63.16% |       0.6959 |          0.1000 |
|      50 |          50 |       00:00:00 |       96.49% |       0.1081 |          0.0656 |
|     100 |         100 |       00:00:00 |       97.37% |       0.0774 |          0.0387 |
|     150 |         150 |       00:00:00 |       97.37% |       0.0760 |          0.0229 |
|     200 |         200 |       00:00:00 |       97.37% |       0.0756 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.25, Precision: 1.0000, Recall: 0.7500, F1-Score: 0.8571
AUC: 0.8660
Processing dataset: Sand Lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Skipping connectivity check (adaptive mode, n = 29).
[DivideNet] Using directed logic. Connectivity check: 0
[DivideNet] Test links accepted: 40 / 40 (100.0%)
[DivideNet] Attempts made: 40 | Failed attempts: 0
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 42
    Train Negative: 84
    Test  Positive: 40
    Test  Negative: 80
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 126 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 76% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.0s
Progress: 95% – Elapsed: 0.0s
Done. Total time: 0.0s
Encoding 120 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.0s
Progress: 90% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       33.33% |       0.7073 |          0.1000 |
|      50 |          50 |       00:00:00 |       98.41% |       0.0417 |          0.0656 |
|     100 |         100 |       00:00:00 |       98.41% |       0.0317 |          0.0387 |
|     150 |         150 |       00:00:00 |       98.41% |       0.0313 |          0.0229 |
|     200 |         200 |       00:00:00 |       98.41% |       0.0312 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.35, Precision: 1.0000, Recall: 0.8750, F1-Score: 0.9333
AUC: 0.9672
Processing dataset: Sand Lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Skipping connectivity check (adaptive mode, n = 29).
[DivideNet] Using directed logic. Connectivity check: 0
[DivideNet] Test links accepted: 36 / 36 (100.0%)
[DivideNet] Attempts made: 36 | Failed attempts: 0
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 46
    Train Negative: 92
    Test  Positive: 36
    Test  Negative: 72
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 138 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 47% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 66% – Elapsed: 0.0s
Progress: 75% – Elapsed: 0.0s
Progress: 85% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Done. Total time: 0.0s
Encoding 108 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 37% – Elapsed: 0.0s
Progress: 46% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 65% – Elapsed: 0.0s
Progress: 74% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 93% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       66.41% |       0.6743 |          0.1000 |
|      50 |          50 |       00:00:00 |       98.44% |       0.0475 |          0.0656 |
|     100 |         100 |       00:00:00 |       98.44% |       0.0463 |          0.0387 |
|     150 |         150 |       00:00:00 |       98.44% |       0.0463 |          0.0229 |
|     200 |         200 |       00:00:00 |       98.44% |       0.0462 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.15, Precision: 1.0000, Recall: 0.7500, F1-Score: 0.8571
AUC: 0.9333
Processing dataset: Sand Lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Skipping connectivity check (adaptive mode, n = 29).
[DivideNet] Using directed logic. Connectivity check: 0
[DivideNet] Test links accepted: 32 / 32 (100.0%)
[DivideNet] Attempts made: 32 | Failed attempts: 0
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 50
    Train Negative: 100
    Test  Positive: 32
    Test  Negative: 64
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 150 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.0s
Progress: 90% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
Encoding 96 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 47% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 66% – Elapsed: 0.0s
Progress: 75% – Elapsed: 0.0s
Progress: 84% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       67.97% |       0.6694 |          0.1000 |
|      50 |          50 |       00:00:00 |       99.22% |       0.0188 |          0.0656 |
|     100 |         100 |       00:00:00 |       99.22% |       0.0114 |          0.0387 |
|     150 |         150 |       00:00:00 |       99.22% |       0.0112 |          0.0229 |
|     200 |         200 |       00:00:00 |       99.22% |       0.0111 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.7500, F1-Score: 0.8571
AUC: 0.9395
Processing dataset: Sand Lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Skipping connectivity check (adaptive mode, n = 29).
[DivideNet] Using directed logic. Connectivity check: 0
[DivideNet] Test links accepted: 28 / 28 (100.0%)
[DivideNet] Attempts made: 28 | Failed attempts: 0
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 54
    Train Negative: 108
    Test  Positive: 28
    Test  Negative: 56
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 162 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 59% – Elapsed: 0.0s
Progress: 69% – Elapsed: 0.0s
Progress: 79% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 99% – Elapsed: 0.0s
Done. Total time: 0.0s
Encoding 84 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 76% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.0s
Progress: 95% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       67.97% |       0.6669 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0078 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0012 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0008 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0007 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9286, Recall: 0.9286, F1-Score: 0.9286
AUC: 0.9694
Processing dataset: Sand Lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Skipping connectivity check (adaptive mode, n = 29).
[DivideNet] Using directed logic. Connectivity check: 0
[DivideNet] Test links accepted: 24 / 24 (100.0%)
[DivideNet] Attempts made: 24 | Failed attempts: 0
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 58
    Train Negative: 116
    Test  Positive: 24
    Test  Negative: 48
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 174 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 59% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 72 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 88% – Elapsed: 0.0s
Progress: 97% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       34.38% |       0.7558 |          0.1000 |
|      50 |          50 |       00:00:00 |       99.22% |       0.0286 |          0.0656 |
|     100 |         100 |       00:00:00 |       99.22% |       0.0165 |          0.0387 |
|     150 |         150 |       00:00:00 |       99.22% |       0.0159 |          0.0229 |
|     200 |         200 |       00:00:00 |       99.22% |       0.0158 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9545, Recall: 0.8750, F1-Score: 0.9130
AUC: 0.9666
Processing dataset: Sand Lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Skipping connectivity check (adaptive mode, n = 29).
[DivideNet] Using directed logic. Connectivity check: 0
[DivideNet] Test links accepted: 20 / 20 (100.0%)
[DivideNet] Attempts made: 20 | Failed attempts: 0
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 62
    Train Negative: 124
    Test  Positive: 20
    Test  Negative: 40
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 186 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 77% – Elapsed: 0.0s
Progress: 87% – Elapsed: 0.1s
Progress: 97% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 60 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.0s
Progress: 90% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       60.94% |       0.7110 |          0.1000 |
|      50 |          50 |       00:00:00 |       99.22% |       0.0242 |          0.0656 |
|     100 |         100 |       00:00:00 |       99.22% |       0.0161 |          0.0387 |
|     150 |         150 |       00:00:00 |       99.22% |       0.0157 |          0.0229 |
|     200 |         200 |       00:00:00 |       99.22% |       0.0156 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.70, Precision: 0.9500, Recall: 0.9500, F1-Score: 0.9500
AUC: 0.9812
Processing dataset: Sand Lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Skipping connectivity check (adaptive mode, n = 29).
[DivideNet] Using directed logic. Connectivity check: 0
[DivideNet] Test links accepted: 16 / 16 (100.0%)
[DivideNet] Attempts made: 16 | Failed attempts: 0
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 66
    Train Negative: 132
    Test  Positive: 16
    Test  Negative: 32
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 198 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.1s
Progress: 67% – Elapsed: 0.1s
Progress: 77% – Elapsed: 0.1s
Progress: 86% – Elapsed: 0.1s
Progress: 96% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 25% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 42% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 75% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 92% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       59.38% |       0.7015 |          0.1000 |
|      50 |          50 |       00:00:00 |       98.44% |       0.0418 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0117 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0069 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0052 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.25, Precision: 1.0000, Recall: 0.8750, F1-Score: 0.9333
AUC: 0.9893
Processing dataset: Sand Lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Skipping connectivity check (adaptive mode, n = 29).
[DivideNet] Using directed logic. Connectivity check: 0
[DivideNet] Test links accepted: 12 / 12 (100.0%)
[DivideNet] Attempts made: 12 | Failed attempts: 0
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 70
    Train Negative: 140
    Test  Positive: 12
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 210 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.1s
Progress: 100% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 36 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 25% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 42% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 75% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 92% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       31.25% |       0.7186 |          0.1000 |
|      50 |          50 |       00:00:00 |       99.22% |       0.0371 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0107 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0032 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0022 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.85, Precision: 0.9000, Recall: 0.7500, F1-Score: 0.8182
AUC: 0.8906
Processing dataset: Sand Lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Skipping connectivity check (adaptive mode, n = 29).
[DivideNet] Using directed logic. Connectivity check: 0
[DivideNet] Test links accepted: 8 / 8 (100.0%)
[DivideNet] Attempts made: 8 | Failed attempts: 0
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 74
    Train Negative: 148
    Test  Positive: 8
    Test  Negative: 16
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 222 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 59% – Elapsed: 0.0s
Progress: 69% – Elapsed: 0.0s
Progress: 79% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.1s
Progress: 99% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 24 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 25% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 42% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 75% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 92% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       67.97% |       0.6854 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0028 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0005 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0004 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0003 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.5000, F1-Score: 0.6667
AUC: 0.9375
Processing dataset: Sand Lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Skipping connectivity check (adaptive mode, n = 29).
[DivideNet] Using directed logic. Connectivity check: 0
[DivideNet] Test links accepted: 72 / 72 (100.0%)
[DivideNet] Attempts made: 72 | Failed attempts: 0
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 10
    Train Negative: 20
    Test  Positive: 72
    Test  Negative: 144
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 30 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.0s
Progress: 90% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
Encoding 216 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 88% – Elapsed: 0.0s
Progress: 97% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       60.00% |       0.6936 |          0.1000 |
|      50 |          50 |       00:00:00 |       66.67% |       0.6242 |          0.0656 |
|     100 |         100 |       00:00:00 |       70.00% |       0.5987 |          0.0387 |
|     150 |         150 |       00:00:00 |       70.00% |       0.5900 |          0.0229 |
|     200 |         200 |       00:00:00 |       70.00% |       0.5882 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.35, Precision: 0.7000, Recall: 0.6806, F1-Score: 0.6901
AUC: 0.7544
Processing dataset: Sand Lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Skipping connectivity check (adaptive mode, n = 29).
[DivideNet] Using directed logic. Connectivity check: 0
[DivideNet] Test links accepted: 68 / 68 (100.0%)
[DivideNet] Attempts made: 68 | Failed attempts: 0
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 14
    Train Negative: 28
    Test  Positive: 68
    Test  Negative: 136
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 42 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 76% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.0s
Progress: 95% – Elapsed: 0.0s
Done. Total time: 0.0s
Encoding 204 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 78% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       66.67% |       0.6958 |          0.1000 |
|      50 |          50 |       00:00:00 |       76.19% |       0.5427 |          0.0656 |
|     100 |         100 |       00:00:00 |       78.57% |       0.4885 |          0.0387 |
|     150 |         150 |       00:00:00 |       78.57% |       0.4774 |          0.0229 |
|     200 |         200 |       00:00:00 |       78.57% |       0.4751 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.25, Precision: 0.6087, Recall: 0.8235, F1-Score: 0.7000
AUC: 0.8135
Processing dataset: Sand Lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Skipping connectivity check (adaptive mode, n = 29).
[DivideNet] Using directed logic. Connectivity check: 0
[DivideNet] Test links accepted: 64 / 64 (100.0%)
[DivideNet] Attempts made: 64 | Failed attempts: 0
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 18
    Train Negative: 36
    Test  Positive: 64
    Test  Negative: 128
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 54 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 37% – Elapsed: 0.0s
Progress: 46% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 65% – Elapsed: 0.0s
Progress: 74% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 93% – Elapsed: 0.0s
Done. Total time: 0.0s
Encoding 192 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 59% – Elapsed: 0.0s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 99% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       70.37% |       0.6846 |          0.1000 |
|      50 |          50 |       00:00:00 |       94.44% |       0.1552 |          0.0656 |
|     100 |         100 |       00:00:00 |       94.44% |       0.1539 |          0.0387 |
|     150 |         150 |       00:00:00 |       94.44% |       0.1538 |          0.0229 |
|     200 |         200 |       00:00:00 |       94.44% |       0.1537 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.50, Precision: 0.7576, Recall: 0.3906, F1-Score: 0.5155
AUC: 0.7073
Processing dataset: Sand Lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Skipping connectivity check (adaptive mode, n = 29).
[DivideNet] Using directed logic. Connectivity check: 0
[DivideNet] Test links accepted: 60 / 60 (100.0%)
[DivideNet] Attempts made: 60 | Failed attempts: 0
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 22
    Train Negative: 44
    Test  Positive: 60
    Test  Negative: 120
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 66 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Progress: 18% – Elapsed: 0.0s
Progress: 27% – Elapsed: 0.0s
Progress: 36% – Elapsed: 0.0s
Progress: 45% – Elapsed: 0.0s
Progress: 55% – Elapsed: 0.0s
Progress: 64% – Elapsed: 0.0s
Progress: 73% – Elapsed: 0.0s
Progress: 82% – Elapsed: 0.0s
Progress: 91% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
Encoding 180 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.0s
Progress: 90% – Elapsed: 0.1s
Progress: 100% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       31.82% |       0.7101 |          0.1000 |
|      50 |          50 |       00:00:00 |       93.94% |       0.1320 |          0.0656 |
|     100 |         100 |       00:00:00 |       93.94% |       0.1277 |          0.0387 |
|     150 |         150 |       00:00:00 |       93.94% |       0.1275 |          0.0229 |
|     200 |         200 |       00:00:00 |       93.94% |       0.1274 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.30, Precision: 1.0000, Recall: 0.5500, F1-Score: 0.7097
AUC: 0.8185
Processing dataset: Sand Lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Skipping connectivity check (adaptive mode, n = 29).
[DivideNet] Using directed logic. Connectivity check: 0
[DivideNet] Test links accepted: 56 / 56 (100.0%)
[DivideNet] Attempts made: 56 | Failed attempts: 0
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 26
    Train Negative: 52
    Test  Positive: 56
    Test  Negative: 112
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 78 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Progress: 18% – Elapsed: 0.0s
Progress: 27% – Elapsed: 0.0s
Progress: 36% – Elapsed: 0.0s
Progress: 45% – Elapsed: 0.0s
Progress: 54% – Elapsed: 0.0s
Progress: 63% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 81% – Elapsed: 0.0s
Progress: 90% – Elapsed: 0.0s
Progress: 99% – Elapsed: 0.0s
Done. Total time: 0.0s
Encoding 168 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 76% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.0s
Progress: 95% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       42.31% |       0.6809 |          0.1000 |
|      50 |          50 |       00:00:00 |       96.15% |       0.1481 |          0.0656 |
|     100 |         100 |       00:00:00 |       96.15% |       0.1449 |          0.0387 |
|     150 |         150 |       00:00:00 |       96.15% |       0.1437 |          0.0229 |
|     200 |         200 |       00:00:00 |       96.15% |       0.1431 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.7500, F1-Score: 0.8571
AUC: 0.8811
