Processing dataset: Dutch Microfauna food web PlotA_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 445 / 549 (81.1%)
[DivideNet] Attempts made: 844 | Failed attempts: 399
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 399
    Train Negative: 399
    Test  Positive: 445
    Test  Negative: 445
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 798 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.2s
Progress: 89% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 890 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.2s
Progress: 50% – Elapsed: 0.2s
Progress: 60% – Elapsed: 0.2s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.3s
Progress: 100% – Elapsed: 0.3s
Done. Total time: 0.3s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       67.97% |       0.7049 |          0.1000 |
|       9 |          50 |       00:00:00 |       91.41% |       0.2335 |          0.1000 |
|      17 |         100 |       00:00:00 |       90.62% |       0.2725 |          0.0900 |
|      25 |         150 |       00:00:00 |       90.62% |       0.2610 |          0.0810 |
|      34 |         200 |       00:00:00 |       92.19% |       0.2249 |          0.0729 |
|      42 |         250 |       00:00:00 |       91.41% |       0.2513 |          0.0656 |
|      50 |         300 |       00:00:00 |       90.62% |       0.2565 |          0.0656 |
|      59 |         350 |       00:00:00 |       92.19% |       0.2214 |          0.0590 |
|      67 |         400 |       00:00:00 |       91.41% |       0.2482 |          0.0531 |
|      75 |         450 |       00:00:00 |       90.62% |       0.2556 |          0.0478 |
|      84 |         500 |       00:00:00 |       92.19% |       0.2193 |          0.0430 |
|      92 |         550 |       00:00:00 |       91.41% |       0.2476 |          0.0387 |
|     100 |         600 |       00:00:00 |       90.62% |       0.2554 |          0.0387 |
|     109 |         650 |       00:00:00 |       92.19% |       0.2183 |          0.0349 |
|     117 |         700 |       00:00:00 |       91.41% |       0.2475 |          0.0314 |
|     125 |         750 |       00:00:01 |       90.62% |       0.2553 |          0.0282 |
|     134 |         800 |       00:00:01 |       92.19% |       0.2175 |          0.0254 |
|     142 |         850 |       00:00:01 |       91.41% |       0.2473 |          0.0229 |
|     150 |         900 |       00:00:01 |       90.62% |       0.2552 |          0.0229 |
|     159 |         950 |       00:00:01 |       92.19% |       0.2173 |          0.0206 |
|     167 |        1000 |       00:00:01 |       91.41% |       0.2473 |          0.0185 |
|     175 |        1050 |       00:00:01 |       90.62% |       0.2551 |          0.0167 |
|     184 |        1100 |       00:00:01 |       92.19% |       0.2170 |          0.0150 |
|     192 |        1150 |       00:00:01 |       91.41% |       0.2472 |          0.0135 |
|     200 |        1200 |       00:00:01 |       90.62% |       0.2551 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.7500, Recall: 0.6000, F1-Score: 0.6667
AUC: 0.8175
Processing dataset: Dutch Microfauna food web PlotA_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 445 / 507 (87.8%)
[DivideNet] Attempts made: 844 | Failed attempts: 399
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 399
    Train Negative: 399
    Test  Positive: 445
    Test  Negative: 445
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 798 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.2s
Progress: 89% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 890 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       71.88% |       0.6609 |          0.1000 |
|       9 |          50 |       00:00:00 |       87.50% |       0.3284 |          0.1000 |
|      17 |         100 |       00:00:00 |       94.53% |       0.2129 |          0.0900 |
|      25 |         150 |       00:00:00 |       90.62% |       0.2704 |          0.0810 |
|      34 |         200 |       00:00:00 |       88.28% |       0.3090 |          0.0729 |
|      42 |         250 |       00:00:00 |       94.53% |       0.2015 |          0.0656 |
|      50 |         300 |       00:00:00 |       90.62% |       0.2622 |          0.0656 |
|      59 |         350 |       00:00:00 |       88.28% |       0.3027 |          0.0590 |
|      67 |         400 |       00:00:00 |       94.53% |       0.2003 |          0.0531 |
|      75 |         450 |       00:00:00 |       90.62% |       0.2613 |          0.0478 |
|      84 |         500 |       00:00:00 |       88.28% |       0.3010 |          0.0430 |
|      92 |         550 |       00:00:00 |       94.53% |       0.1996 |          0.0387 |
|     100 |         600 |       00:00:00 |       90.62% |       0.2610 |          0.0387 |
|     109 |         650 |       00:00:00 |       88.28% |       0.3009 |          0.0349 |
|     117 |         700 |       00:00:00 |       94.53% |       0.1993 |          0.0314 |
|     125 |         750 |       00:00:00 |       90.62% |       0.2608 |          0.0282 |
|     134 |         800 |       00:00:00 |       88.28% |       0.3008 |          0.0254 |
|     142 |         850 |       00:00:01 |       94.53% |       0.1977 |          0.0229 |
|     150 |         900 |       00:00:01 |       90.62% |       0.2608 |          0.0229 |
|     159 |         950 |       00:00:01 |       88.28% |       0.3008 |          0.0206 |
|     167 |        1000 |       00:00:01 |       94.53% |       0.1989 |          0.0185 |
|     175 |        1050 |       00:00:01 |       90.62% |       0.2607 |          0.0167 |
|     184 |        1100 |       00:00:01 |       88.28% |       0.3008 |          0.0150 |
|     192 |        1150 |       00:00:01 |       94.53% |       0.1985 |          0.0135 |
|     200 |        1200 |       00:00:01 |       90.62% |       0.2607 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.25, Precision: 0.8018, Recall: 0.7910, F1-Score: 0.7964
AUC: 0.9091
Processing dataset: Dutch Microfauna food web PlotA_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 445 / 465 (95.7%)
[DivideNet] Attempts made: 844 | Failed attempts: 399
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 399
    Train Negative: 399
    Test  Positive: 445
    Test  Negative: 445
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 798 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.2s
Progress: 89% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 890 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       39.06% |       0.7057 |          0.1000 |
|       9 |          50 |       00:00:00 |       91.41% |       0.2495 |          0.1000 |
|      17 |         100 |       00:00:00 |       85.94% |       0.3470 |          0.0900 |
|      25 |         150 |       00:00:00 |       91.41% |       0.2320 |          0.0810 |
|      34 |         200 |       00:00:00 |       93.75% |       0.2206 |          0.0729 |
|      42 |         250 |       00:00:00 |       85.94% |       0.3354 |          0.0656 |
|      50 |         300 |       00:00:00 |       90.62% |       0.2365 |          0.0656 |
|      59 |         350 |       00:00:00 |       93.75% |       0.2162 |          0.0590 |
|      67 |         400 |       00:00:00 |       85.94% |       0.3340 |          0.0531 |
|      75 |         450 |       00:00:00 |       90.62% |       0.2365 |          0.0478 |
|      84 |         500 |       00:00:00 |       93.75% |       0.2157 |          0.0430 |
|      92 |         550 |       00:00:00 |       85.94% |       0.3331 |          0.0387 |
|     100 |         600 |       00:00:00 |       90.62% |       0.2363 |          0.0387 |
|     109 |         650 |       00:00:00 |       93.75% |       0.2158 |          0.0349 |
|     117 |         700 |       00:00:00 |       85.94% |       0.3328 |          0.0314 |
|     125 |         750 |       00:00:00 |       90.62% |       0.2362 |          0.0282 |
|     134 |         800 |       00:00:01 |       93.75% |       0.2154 |          0.0254 |
|     142 |         850 |       00:00:01 |       85.94% |       0.3325 |          0.0229 |
|     150 |         900 |       00:00:01 |       90.62% |       0.2361 |          0.0229 |
|     159 |         950 |       00:00:01 |       93.75% |       0.2152 |          0.0206 |
|     167 |        1000 |       00:00:01 |       85.94% |       0.3323 |          0.0185 |
|     175 |        1050 |       00:00:01 |       90.62% |       0.2355 |          0.0167 |
|     184 |        1100 |       00:00:01 |       93.75% |       0.2152 |          0.0150 |
|     192 |        1150 |       00:00:01 |       85.94% |       0.3322 |          0.0135 |
|     200 |        1200 |       00:00:01 |       90.62% |       0.2360 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.85, Precision: 1.0000, Recall: 0.7079, F1-Score: 0.8289
AUC: 0.9238
Processing dataset: Dutch Microfauna food web PlotA_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 422 / 422 (100.0%)
[DivideNet] Attempts made: 783 | Failed attempts: 361
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 422
    Train Negative: 422
    Test  Positive: 422
    Test  Negative: 422
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 844 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 844 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       46.88% |       0.6978 |          0.1000 |
|       9 |          50 |       00:00:00 |       92.19% |       0.2512 |          0.1000 |
|      17 |         100 |       00:00:00 |       90.62% |       0.2576 |          0.0900 |
|      25 |         150 |       00:00:00 |       92.19% |       0.2268 |          0.0810 |
|      34 |         200 |       00:00:00 |       92.19% |       0.2297 |          0.0729 |
|      42 |         250 |       00:00:00 |       90.62% |       0.2367 |          0.0656 |
|      50 |         300 |       00:00:00 |       92.19% |       0.2239 |          0.0656 |
|      59 |         350 |       00:00:00 |       92.19% |       0.2290 |          0.0590 |
|      67 |         400 |       00:00:00 |       92.19% |       0.2148 |          0.0531 |
|      75 |         450 |       00:00:00 |       92.19% |       0.2235 |          0.0478 |
|      84 |         500 |       00:00:00 |       92.19% |       0.2280 |          0.0430 |
|      92 |         550 |       00:00:00 |       92.19% |       0.2123 |          0.0387 |
|     100 |         600 |       00:00:00 |       92.19% |       0.2233 |          0.0387 |
|     109 |         650 |       00:00:00 |       92.19% |       0.2277 |          0.0349 |
|     117 |         700 |       00:00:00 |       92.19% |       0.2117 |          0.0314 |
|     125 |         750 |       00:00:00 |       92.19% |       0.2233 |          0.0282 |
|     134 |         800 |       00:00:00 |       92.19% |       0.2276 |          0.0254 |
|     142 |         850 |       00:00:01 |       92.19% |       0.2112 |          0.0229 |
|     150 |         900 |       00:00:01 |       92.19% |       0.2232 |          0.0229 |
|     159 |         950 |       00:00:01 |       92.19% |       0.2274 |          0.0206 |
|     167 |        1000 |       00:00:01 |       92.19% |       0.2111 |          0.0185 |
|     175 |        1050 |       00:00:01 |       92.19% |       0.2232 |          0.0167 |
|     184 |        1100 |       00:00:01 |       92.19% |       0.2273 |          0.0150 |
|     192 |        1150 |       00:00:01 |       92.19% |       0.2108 |          0.0135 |
|     200 |        1200 |       00:00:01 |       92.19% |       0.2232 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.8951, Recall: 0.9502, F1-Score: 0.9218
AUC: 0.9754
Processing dataset: Dutch Microfauna food web PlotA_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 380 / 380 (100.0%)
[DivideNet] Attempts made: 708 | Failed attempts: 328
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 464
    Train Negative: 464
    Test  Positive: 380
    Test  Negative: 380
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 928 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.2s
Progress: 69% – Elapsed: 0.2s
Progress: 79% – Elapsed: 0.2s
Progress: 89% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 760 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       30.47% |       0.7114 |          0.1000 |
|       8 |          50 |       00:00:00 |       86.72% |       0.3069 |          0.1000 |
|      15 |         100 |       00:00:00 |       89.06% |       0.3177 |          0.0900 |
|      22 |         150 |       00:00:00 |       92.19% |       0.2179 |          0.0810 |
|      29 |         200 |       00:00:00 |       92.97% |       0.1926 |          0.0810 |
|      36 |         250 |       00:00:00 |       97.66% |       0.1337 |          0.0729 |
|      43 |         300 |       00:00:00 |       96.88% |       0.1305 |          0.0656 |
|      50 |         350 |       00:00:00 |       88.28% |       0.3043 |          0.0656 |
|      58 |         400 |       00:00:00 |       92.97% |       0.2181 |          0.0590 |
|      65 |         450 |       00:00:01 |       89.84% |       0.2712 |          0.0531 |
|      72 |         500 |       00:00:01 |       92.19% |       0.2130 |          0.0478 |
|      79 |         550 |       00:00:01 |       93.75% |       0.1829 |          0.0478 |
|      86 |         600 |       00:00:01 |       97.66% |       0.1194 |          0.0430 |
|      93 |         650 |       00:00:01 |       96.88% |       0.1279 |          0.0387 |
|     100 |         700 |       00:00:01 |       89.06% |       0.2942 |          0.0387 |
|     108 |         750 |       00:00:01 |       92.97% |       0.2120 |          0.0349 |
|     115 |         800 |       00:00:01 |       89.84% |       0.2711 |          0.0314 |
|     122 |         850 |       00:00:01 |       92.19% |       0.2124 |          0.0282 |
|     129 |         900 |       00:00:01 |       93.75% |       0.1793 |          0.0282 |
|     136 |         950 |       00:00:01 |       97.66% |       0.1168 |          0.0254 |
|     143 |        1000 |       00:00:01 |       96.88% |       0.1271 |          0.0229 |
|     150 |        1050 |       00:00:01 |       89.06% |       0.2903 |          0.0229 |
|     158 |        1100 |       00:00:02 |       92.97% |       0.2101 |          0.0206 |
|     165 |        1150 |       00:00:02 |       89.84% |       0.2709 |          0.0185 |
|     172 |        1200 |       00:00:02 |       92.19% |       0.2120 |          0.0167 |
|     179 |        1250 |       00:00:02 |       93.75% |       0.1785 |          0.0167 |
|     186 |        1300 |       00:00:02 |       97.66% |       0.1165 |          0.0150 |
|     193 |        1350 |       00:00:02 |       96.88% |       0.1269 |          0.0135 |
|     200 |        1400 |       00:00:02 |       89.06% |       0.2887 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.35, Precision: 0.9044, Recall: 0.9211, F1-Score: 0.9126
AUC: 0.9389
Processing dataset: Dutch Microfauna food web PlotA_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 338 / 338 (100.0%)
[DivideNet] Attempts made: 623 | Failed attempts: 285
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 506
    Train Negative: 506
    Test  Positive: 338
    Test  Negative: 338
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 1012 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.2s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.3s
Progress: 100% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 676 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.2s
Progress: 89% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       54.69% |       0.7179 |          0.1000 |
|       8 |          50 |       00:00:00 |       91.41% |       0.2029 |          0.1000 |
|      15 |         100 |       00:00:00 |       95.31% |       0.1466 |          0.0900 |
|      22 |         150 |       00:00:00 |       91.41% |       0.2155 |          0.0810 |
|      29 |         200 |       00:00:00 |       92.97% |       0.1904 |          0.0810 |
|      36 |         250 |       00:00:00 |       96.09% |       0.1485 |          0.0729 |
|      43 |         300 |       00:00:00 |       96.09% |       0.1415 |          0.0656 |
|      50 |         350 |       00:00:00 |       93.75% |       0.1689 |          0.0656 |
|      58 |         400 |       00:00:00 |       97.66% |       0.0940 |          0.0590 |
|      65 |         450 |       00:00:00 |       96.88% |       0.1121 |          0.0531 |
|      72 |         500 |       00:00:00 |       95.31% |       0.1426 |          0.0478 |
|      79 |         550 |       00:00:00 |       93.75% |       0.1692 |          0.0478 |
|      86 |         600 |       00:00:00 |       95.31% |       0.1493 |          0.0430 |
|      93 |         650 |       00:00:01 |       96.09% |       0.1407 |          0.0387 |
|     100 |         700 |       00:00:01 |       93.75% |       0.1645 |          0.0387 |
|     108 |         750 |       00:00:01 |       97.66% |       0.0909 |          0.0349 |
|     115 |         800 |       00:00:01 |       96.88% |       0.1221 |          0.0314 |
|     122 |         850 |       00:00:01 |       96.09% |       0.1479 |          0.0282 |
|     129 |         900 |       00:00:01 |       94.53% |       0.1678 |          0.0282 |
|     136 |         950 |       00:00:01 |       95.31% |       0.1486 |          0.0254 |
|     143 |        1000 |       00:00:01 |       96.09% |       0.1397 |          0.0229 |
|     150 |        1050 |       00:00:01 |       93.75% |       0.1643 |          0.0229 |
|     158 |        1100 |       00:00:01 |       97.66% |       0.0906 |          0.0206 |
|     165 |        1150 |       00:00:01 |       96.88% |       0.1074 |          0.0185 |
|     172 |        1200 |       00:00:01 |       96.09% |       0.1409 |          0.0167 |
|     179 |        1250 |       00:00:01 |       94.53% |       0.1627 |          0.0167 |
|     186 |        1300 |       00:00:01 |       95.31% |       0.1490 |          0.0150 |
|     193 |        1350 |       00:00:01 |       96.09% |       0.1396 |          0.0135 |
|     200 |        1400 |       00:00:02 |       93.75% |       0.1638 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.8682, Recall: 0.9941, F1-Score: 0.9269
AUC: 0.9758
Processing dataset: Dutch Microfauna food web PlotA_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 296 / 296 (100.0%)
[DivideNet] Attempts made: 538 | Failed attempts: 242
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 548
    Train Negative: 548
    Test  Positive: 296
    Test  Negative: 296
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 1096 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.2s
Progress: 60% – Elapsed: 0.2s
Progress: 70% – Elapsed: 0.3s
Progress: 80% – Elapsed: 0.3s
Progress: 90% – Elapsed: 0.3s
Progress: 99% – Elapsed: 0.4s
Done. Total time: 0.4s
Encoding 592 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       50.00% |       0.8238 |          0.1000 |
|       7 |          50 |       00:00:00 |       92.19% |       0.2215 |          0.1000 |
|      13 |         100 |       00:00:00 |       90.62% |       0.2466 |          0.0900 |
|      19 |         150 |       00:00:00 |       94.53% |       0.1615 |          0.0900 |
|      25 |         200 |       00:00:00 |       95.31% |       0.1485 |          0.0810 |
|      32 |         250 |       00:00:00 |       96.88% |       0.1132 |          0.0729 |
|      38 |         300 |       00:00:00 |       94.53% |       0.1846 |          0.0729 |
|      44 |         350 |       00:00:00 |       96.09% |       0.1346 |          0.0656 |
|      50 |         400 |       00:00:00 |       96.88% |       0.1186 |          0.0656 |
|      57 |         450 |       00:00:00 |       96.88% |       0.1079 |          0.0590 |
|      63 |         500 |       00:00:00 |       94.53% |       0.1621 |          0.0531 |
|      69 |         550 |       00:00:00 |       96.09% |       0.1271 |          0.0531 |
|      75 |         600 |       00:00:01 |       97.66% |       0.1075 |          0.0478 |
|      82 |         650 |       00:00:01 |       96.88% |       0.1066 |          0.0430 |
|      88 |         700 |       00:00:01 |       95.31% |       0.1483 |          0.0430 |
|      94 |         750 |       00:00:01 |       96.88% |       0.1179 |          0.0387 |
|     100 |         800 |       00:00:01 |       97.66% |       0.1029 |          0.0387 |
|     107 |         850 |       00:00:01 |       96.88% |       0.1031 |          0.0349 |
|     113 |         900 |       00:00:01 |       95.31% |       0.1429 |          0.0314 |
|     119 |         950 |       00:00:01 |       96.88% |       0.1168 |          0.0314 |
|     125 |        1000 |       00:00:01 |       97.66% |       0.1019 |          0.0282 |
|     132 |        1050 |       00:00:01 |       96.88% |       0.1026 |          0.0254 |
|     138 |        1100 |       00:00:01 |       95.31% |       0.1413 |          0.0254 |
|     144 |        1150 |       00:00:01 |       96.88% |       0.1169 |          0.0229 |
|     150 |        1200 |       00:00:01 |       97.66% |       0.1015 |          0.0229 |
|     157 |        1250 |       00:00:02 |       96.88% |       0.1023 |          0.0206 |
|     163 |        1300 |       00:00:02 |       95.31% |       0.1398 |          0.0185 |
|     169 |        1350 |       00:00:02 |       96.88% |       0.1163 |          0.0185 |
|     175 |        1400 |       00:00:02 |       97.66% |       0.1008 |          0.0167 |
|     182 |        1450 |       00:00:02 |       96.88% |       0.1025 |          0.0150 |
|     188 |        1500 |       00:00:02 |       95.31% |       0.1396 |          0.0150 |
|     194 |        1550 |       00:00:02 |       96.88% |       0.1162 |          0.0135 |
|     200 |        1600 |       00:00:02 |       97.66% |       0.1005 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.40, Precision: 0.9433, Recall: 0.9561, F1-Score: 0.9497
AUC: 0.9842
Processing dataset: Dutch Microfauna food web PlotA_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 254 / 254 (100.0%)
[DivideNet] Attempts made: 454 | Failed attempts: 200
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 590
    Train Negative: 590
    Test  Positive: 254
    Test  Negative: 254
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 1180 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.1s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.2s
Progress: 50% – Elapsed: 0.2s
Progress: 60% – Elapsed: 0.3s
Progress: 70% – Elapsed: 0.3s
Progress: 80% – Elapsed: 0.4s
Progress: 90% – Elapsed: 0.4s
Progress: 100% – Elapsed: 0.5s
Done. Total time: 0.5s
Encoding 508 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.2s
Progress: 89% – Elapsed: 0.2s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       67.19% |       0.6627 |          0.1000 |
|       6 |          50 |       00:00:00 |       91.41% |       0.2827 |          0.1000 |
|      12 |         100 |       00:00:00 |       95.31% |       0.1225 |          0.0900 |
|      17 |         150 |       00:00:00 |       96.88% |       0.1157 |          0.0900 |
|      23 |         200 |       00:00:00 |       93.75% |       0.1951 |          0.0810 |
|      28 |         250 |       00:00:00 |       97.66% |       0.0967 |          0.0810 |
|      34 |         300 |       00:00:00 |       94.53% |       0.1352 |          0.0729 |
|      39 |         350 |       00:00:00 |       96.88% |       0.1129 |          0.0729 |
|      45 |         400 |       00:00:00 |       96.88% |       0.1005 |          0.0656 |
|      50 |         450 |       00:00:00 |       92.97% |       0.1982 |          0.0656 |
|      56 |         500 |       00:00:00 |       94.53% |       0.1713 |          0.0590 |
|      62 |         550 |       00:00:00 |       96.88% |       0.1059 |          0.0531 |
|      67 |         600 |       00:00:00 |       96.88% |       0.1056 |          0.0531 |
|      73 |         650 |       00:00:01 |       96.09% |       0.1401 |          0.0478 |
|      78 |         700 |       00:00:01 |       99.22% |       0.0575 |          0.0478 |
|      84 |         750 |       00:00:01 |       95.31% |       0.1301 |          0.0430 |
|      89 |         800 |       00:00:01 |       96.88% |       0.1112 |          0.0430 |
|      95 |         850 |       00:00:01 |       96.88% |       0.0958 |          0.0387 |
|     100 |         900 |       00:00:01 |       92.97% |       0.1922 |          0.0387 |
|     106 |         950 |       00:00:01 |       94.53% |       0.1642 |          0.0349 |
|     112 |        1000 |       00:00:01 |       96.88% |       0.1033 |          0.0314 |
|     117 |        1050 |       00:00:01 |       96.88% |       0.1031 |          0.0314 |
|     123 |        1100 |       00:00:01 |       96.09% |       0.1394 |          0.0282 |
|     128 |        1150 |       00:00:01 |       99.22% |       0.0558 |          0.0282 |
|     134 |        1200 |       00:00:01 |       95.31% |       0.1291 |          0.0254 |
|     139 |        1250 |       00:00:01 |       96.88% |       0.1114 |          0.0254 |
|     145 |        1300 |       00:00:01 |       96.88% |       0.0962 |          0.0229 |
|     150 |        1350 |       00:00:02 |       92.97% |       0.1924 |          0.0229 |
|     156 |        1400 |       00:00:02 |       94.53% |       0.1626 |          0.0206 |
|     162 |        1450 |       00:00:02 |       96.88% |       0.1026 |          0.0185 |
|     167 |        1500 |       00:00:02 |       96.88% |       0.1019 |          0.0185 |
|     173 |        1550 |       00:00:02 |       96.09% |       0.1394 |          0.0167 |
|     178 |        1600 |       00:00:02 |       99.22% |       0.0548 |          0.0167 |
|     184 |        1650 |       00:00:02 |       95.31% |       0.1288 |          0.0150 |
|     189 |        1700 |       00:00:02 |       96.88% |       0.1118 |          0.0150 |
|     195 |        1750 |       00:00:02 |       96.88% |       0.0951 |          0.0135 |
|     200 |        1800 |       00:00:02 |       92.97% |       0.1928 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.20, Precision: 0.9333, Recall: 0.9921, F1-Score: 0.9618
AUC: 0.9899
Processing dataset: Dutch Microfauna food web PlotA_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 211 / 211 (100.0%)
[DivideNet] Attempts made: 374 | Failed attempts: 163
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 633
    Train Negative: 633
    Test  Positive: 211
    Test  Negative: 211
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 1266 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.1s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.2s
Progress: 40% – Elapsed: 0.2s
Progress: 50% – Elapsed: 0.3s
Progress: 60% – Elapsed: 0.3s
Progress: 70% – Elapsed: 0.4s
Progress: 80% – Elapsed: 0.4s
Progress: 90% – Elapsed: 0.5s
Progress: 100% – Elapsed: 0.6s
Done. Total time: 0.6s
Encoding 422 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       31.25% |       0.6981 |          0.1000 |
|       6 |          50 |       00:00:00 |       92.19% |       0.1421 |          0.1000 |
|      12 |         100 |       00:00:00 |       94.53% |       0.1741 |          0.0900 |
|      17 |         150 |       00:00:00 |       96.88% |       0.1039 |          0.0900 |
|      23 |         200 |       00:00:00 |       96.88% |       0.1046 |          0.0810 |
|      28 |         250 |       00:00:00 |       99.22% |       0.0632 |          0.0810 |
|      34 |         300 |       00:00:00 |       95.31% |       0.1510 |          0.0729 |
|      39 |         350 |       00:00:00 |       99.22% |       0.0415 |          0.0729 |
|      45 |         400 |       00:00:00 |       98.44% |       0.0679 |          0.0656 |
|      50 |         450 |       00:00:00 |       98.44% |       0.0731 |          0.0656 |
|      56 |         500 |       00:00:00 |       98.44% |       0.0682 |          0.0590 |
|      62 |         550 |       00:00:01 |       96.09% |       0.1296 |          0.0531 |
|      67 |         600 |       00:00:01 |       97.66% |       0.0862 |          0.0531 |
|      73 |         650 |       00:00:01 |       97.66% |       0.0942 |          0.0478 |
|      78 |         700 |       00:00:01 |       99.22% |       0.0509 |          0.0478 |
|      84 |         750 |       00:00:01 |       95.31% |       0.1486 |          0.0430 |
|      89 |         800 |       00:00:01 |       99.22% |       0.0421 |          0.0430 |
|      95 |         850 |       00:00:01 |       98.44% |       0.0672 |          0.0387 |
|     100 |         900 |       00:00:01 |       98.44% |       0.0708 |          0.0387 |
|     106 |         950 |       00:00:01 |       98.44% |       0.0684 |          0.0349 |
|     112 |        1000 |       00:00:01 |       96.09% |       0.1270 |          0.0314 |
|     117 |        1050 |       00:00:01 |       97.66% |       0.0853 |          0.0314 |
|     123 |        1100 |       00:00:02 |       97.66% |       0.0936 |          0.0282 |
|     128 |        1150 |       00:00:02 |       99.22% |       0.0505 |          0.0282 |
|     134 |        1200 |       00:00:02 |       95.31% |       0.1454 |          0.0254 |
|     139 |        1250 |       00:00:02 |       99.22% |       0.0418 |          0.0254 |
|     145 |        1300 |       00:00:02 |       98.44% |       0.0671 |          0.0229 |
|     150 |        1350 |       00:00:02 |       98.44% |       0.0709 |          0.0229 |
|     156 |        1400 |       00:00:02 |       98.44% |       0.0683 |          0.0206 |
|     162 |        1450 |       00:00:02 |       96.09% |       0.1268 |          0.0185 |
|     167 |        1500 |       00:00:02 |       97.66% |       0.0852 |          0.0185 |
|     173 |        1550 |       00:00:02 |       97.66% |       0.0936 |          0.0167 |
|     178 |        1600 |       00:00:02 |       99.22% |       0.0500 |          0.0167 |
|     184 |        1650 |       00:00:02 |       95.31% |       0.1449 |          0.0150 |
|     189 |        1700 |       00:00:03 |       99.22% |       0.0416 |          0.0150 |
|     195 |        1750 |       00:00:03 |       98.44% |       0.0671 |          0.0135 |
|     200 |        1800 |       00:00:03 |       98.44% |       0.0706 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.15, Precision: 0.9724, Recall: 1.0000, F1-Score: 0.9860
AUC: 0.9963
Processing dataset: Dutch Microfauna food web PlotA_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 169 / 169 (100.0%)
[DivideNet] Attempts made: 291 | Failed attempts: 122
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 675
    Train Negative: 675
    Test  Positive: 169
    Test  Negative: 169
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 1350 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.1s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.2s
Progress: 50% – Elapsed: 0.2s
Progress: 60% – Elapsed: 0.3s
Progress: 70% – Elapsed: 0.3s
Progress: 80% – Elapsed: 0.4s
Progress: 90% – Elapsed: 0.4s
Progress: 100% – Elapsed: 0.5s
Done. Total time: 0.5s
Encoding 338 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 68% – Elapsed: 0.1s
Progress: 78% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       60.94% |       0.6884 |          0.1000 |
|       5 |          50 |       00:00:00 |       95.31% |       0.1499 |          0.1000 |
|      10 |         100 |       00:00:00 |       94.53% |       0.1454 |          0.1000 |
|      15 |         150 |       00:00:00 |       96.09% |       0.1225 |          0.0900 |
|      20 |         200 |       00:00:00 |       96.09% |       0.1167 |          0.0900 |
|      25 |         250 |       00:00:00 |       96.09% |       0.1109 |          0.0810 |
|      30 |         300 |       00:00:00 |       96.88% |       0.1064 |          0.0810 |
|      35 |         350 |       00:00:00 |       96.88% |       0.1045 |          0.0729 |
|      40 |         400 |       00:00:00 |       96.88% |       0.1034 |          0.0729 |
|      45 |         450 |       00:00:00 |       96.88% |       0.1019 |          0.0656 |
|      50 |         500 |       00:00:00 |       96.88% |       0.1015 |          0.0656 |
|      55 |         550 |       00:00:00 |       96.88% |       0.1016 |          0.0590 |
|      60 |         600 |       00:00:00 |       96.88% |       0.1013 |          0.0590 |
|      65 |         650 |       00:00:00 |       96.88% |       0.1011 |          0.0531 |
|      70 |         700 |       00:00:00 |       96.88% |       0.1007 |          0.0531 |
|      75 |         750 |       00:00:01 |       96.88% |       0.1011 |          0.0478 |
|      80 |         800 |       00:00:01 |       96.88% |       0.1008 |          0.0478 |
|      85 |         850 |       00:00:01 |       96.88% |       0.1010 |          0.0430 |
|      90 |         900 |       00:00:01 |       96.88% |       0.1005 |          0.0430 |
|      95 |         950 |       00:00:01 |       96.88% |       0.1007 |          0.0387 |
|     100 |        1000 |       00:00:01 |       96.88% |       0.1005 |          0.0387 |
|     105 |        1050 |       00:00:01 |       96.88% |       0.1008 |          0.0349 |
|     110 |        1100 |       00:00:01 |       96.88% |       0.1005 |          0.0349 |
|     115 |        1150 |       00:00:01 |       96.88% |       0.1006 |          0.0314 |
|     120 |        1200 |       00:00:01 |       96.88% |       0.1010 |          0.0314 |
|     125 |        1250 |       00:00:01 |       96.88% |       0.1005 |          0.0282 |
|     130 |        1300 |       00:00:01 |       96.88% |       0.1007 |          0.0282 |
|     135 |        1350 |       00:00:01 |       96.88% |       0.1006 |          0.0254 |
|     140 |        1400 |       00:00:01 |       96.88% |       0.1006 |          0.0254 |
|     145 |        1450 |       00:00:01 |       96.88% |       0.1010 |          0.0229 |
|     150 |        1500 |       00:00:02 |       96.88% |       0.1005 |          0.0229 |
|     155 |        1550 |       00:00:02 |       96.88% |       0.1005 |          0.0206 |
|     160 |        1600 |       00:00:02 |       96.88% |       0.1007 |          0.0206 |
|     165 |        1650 |       00:00:02 |       96.88% |       0.1005 |          0.0185 |
|     170 |        1700 |       00:00:02 |       96.88% |       0.1005 |          0.0185 |
|     175 |        1750 |       00:00:02 |       96.88% |       0.1005 |          0.0167 |
|     180 |        1800 |       00:00:02 |       96.88% |       0.1004 |          0.0167 |
|     185 |        1850 |       00:00:02 |       96.88% |       0.1004 |          0.0150 |
|     190 |        1900 |       00:00:02 |       96.88% |       0.1003 |          0.0150 |
|     195 |        1950 |       00:00:02 |       96.88% |       0.1004 |          0.0135 |
|     200 |        2000 |       00:00:02 |       96.88% |       0.1003 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9602, Recall: 1.0000, F1-Score: 0.9797
AUC: 0.9956
Processing dataset: Dutch Microfauna food web PlotA_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 127 / 127 (100.0%)
[DivideNet] Attempts made: 223 | Failed attempts: 96
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 717
    Train Negative: 717
    Test  Positive: 127
    Test  Negative: 127
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 1434 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.2s
Progress: 60% – Elapsed: 0.2s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.3s
Progress: 90% – Elapsed: 0.3s
Progress: 100% – Elapsed: 0.4s
Done. Total time: 0.4s
Encoding 254 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 59% – Elapsed: 0.0s
Progress: 69% – Elapsed: 0.0s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       46.88% |       0.6980 |          0.1000 |
|       5 |          50 |       00:00:00 |       97.66% |       0.0865 |          0.1000 |
|      10 |         100 |       00:00:00 |       96.09% |       0.1205 |          0.1000 |
|      14 |         150 |       00:00:00 |       97.66% |       0.0684 |          0.0900 |
|      19 |         200 |       00:00:00 |       93.75% |       0.1467 |          0.0900 |
|      23 |         250 |       00:00:00 |       96.09% |       0.1050 |          0.0810 |
|      28 |         300 |       00:00:00 |       97.66% |       0.0925 |          0.0810 |
|      32 |         350 |       00:00:00 |       96.88% |       0.1098 |          0.0729 |
|      37 |         400 |       00:00:00 |       97.66% |       0.0818 |          0.0729 |
|      41 |         450 |       00:00:00 |       99.22% |       0.0421 |          0.0656 |
|      46 |         500 |       00:00:00 |       98.44% |       0.0712 |          0.0656 |
|      50 |         550 |       00:00:00 |       96.09% |       0.1227 |          0.0656 |
|      55 |         600 |       00:00:00 |       98.44% |       0.0531 |          0.0590 |
|      60 |         650 |       00:00:00 |       96.88% |       0.0929 |          0.0590 |
|      64 |         700 |       00:00:00 |       97.66% |       0.0694 |          0.0531 |
|      69 |         750 |       00:00:00 |       98.44% |       0.0742 |          0.0531 |
|      73 |         800 |       00:00:00 |       96.09% |       0.1099 |          0.0478 |
|      78 |         850 |       00:00:01 |       97.66% |       0.0817 |          0.0478 |
|      82 |         900 |       00:00:01 |       96.88% |       0.1113 |          0.0430 |
|      87 |         950 |       00:00:01 |       97.66% |       0.0807 |          0.0430 |
|      91 |        1000 |       00:00:01 |       99.22% |       0.0424 |          0.0387 |
|      96 |        1050 |       00:00:01 |       98.44% |       0.0700 |          0.0387 |
|     100 |        1100 |       00:00:01 |       96.09% |       0.1165 |          0.0387 |
|     105 |        1150 |       00:00:01 |       98.44% |       0.0536 |          0.0349 |
|     110 |        1200 |       00:00:01 |       96.88% |       0.0917 |          0.0349 |
|     114 |        1250 |       00:00:01 |       97.66% |       0.0693 |          0.0314 |
|     119 |        1300 |       00:00:01 |       98.44% |       0.0743 |          0.0314 |
|     123 |        1350 |       00:00:01 |       96.09% |       0.1083 |          0.0282 |
|     128 |        1400 |       00:00:01 |       97.66% |       0.0819 |          0.0282 |
|     132 |        1450 |       00:00:01 |       96.88% |       0.1102 |          0.0254 |
|     137 |        1500 |       00:00:01 |       97.66% |       0.0805 |          0.0254 |
|     141 |        1550 |       00:00:01 |       99.22% |       0.0420 |          0.0229 |
|     146 |        1600 |       00:00:02 |       98.44% |       0.0695 |          0.0229 |
|     150 |        1650 |       00:00:02 |       96.09% |       0.1158 |          0.0229 |
|     155 |        1700 |       00:00:02 |       98.44% |       0.0535 |          0.0206 |
|     160 |        1750 |       00:00:02 |       96.88% |       0.0913 |          0.0206 |
|     164 |        1800 |       00:00:02 |       97.66% |       0.0694 |          0.0185 |
|     169 |        1850 |       00:00:02 |       98.44% |       0.0744 |          0.0185 |
|     173 |        1900 |       00:00:02 |       96.09% |       0.1077 |          0.0167 |
|     178 |        1950 |       00:00:02 |       97.66% |       0.0811 |          0.0167 |
|     182 |        2000 |       00:00:02 |       96.88% |       0.1100 |          0.0150 |
|     187 |        2050 |       00:00:02 |       97.66% |       0.0804 |          0.0150 |
|     191 |        2100 |       00:00:02 |       99.22% |       0.0418 |          0.0135 |
|     196 |        2150 |       00:00:02 |       98.44% |       0.0693 |          0.0135 |
|     200 |        2200 |       00:00:02 |       96.09% |       0.1155 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.30, Precision: 0.9692, Recall: 0.9921, F1-Score: 0.9805
AUC: 0.9967
Processing dataset: Dutch Microfauna food web PlotA_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 85 / 85 (100.0%)
[DivideNet] Attempts made: 158 | Failed attempts: 73
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 759
    Train Negative: 759
    Test  Positive: 85
    Test  Negative: 85
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 1518 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.2s
Progress: 50% – Elapsed: 0.2s
Progress: 60% – Elapsed: 0.3s
Progress: 70% – Elapsed: 0.3s
Progress: 80% – Elapsed: 0.4s
Progress: 90% – Elapsed: 0.4s
Progress: 99% – Elapsed: 0.6s
Done. Total time: 0.6s
Encoding 170 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.1s
Progress: 100% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       47.66% |       0.7689 |          0.1000 |
|       5 |          50 |       00:00:00 |       92.97% |       0.2006 |          0.1000 |
|      10 |         100 |       00:00:00 |       93.75% |       0.0981 |          0.1000 |
|      14 |         150 |       00:00:00 |       96.09% |       0.1021 |          0.0900 |
|      19 |         200 |       00:00:00 |       98.44% |       0.0573 |          0.0900 |
|      23 |         250 |       00:00:00 |       98.44% |       0.0683 |          0.0810 |
|      28 |         300 |       00:00:00 |       96.88% |       0.0759 |          0.0810 |
|      32 |         350 |       00:00:00 |       98.44% |       0.0767 |          0.0729 |
|      37 |         400 |       00:00:00 |       98.44% |       0.0361 |          0.0729 |
|      41 |         450 |       00:00:00 |       96.88% |       0.0900 |          0.0656 |
|      46 |         500 |       00:00:01 |       96.09% |       0.1410 |          0.0656 |
|      50 |         550 |       00:00:01 |       96.09% |       0.1356 |          0.0656 |
|      55 |         600 |       00:00:01 |       92.97% |       0.1964 |          0.0590 |
|      60 |         650 |       00:00:01 |       99.22% |       0.0626 |          0.0590 |
|      64 |         700 |       00:00:01 |       96.88% |       0.0808 |          0.0531 |
|      69 |         750 |       00:00:01 |       98.44% |       0.0520 |          0.0531 |
|      73 |         800 |       00:00:01 |       98.44% |       0.0621 |          0.0478 |
|      78 |         850 |       00:00:01 |       96.88% |       0.0733 |          0.0478 |
|      82 |         900 |       00:00:01 |       99.22% |       0.0312 |          0.0430 |
|      87 |         950 |       00:00:01 |       99.22% |       0.0286 |          0.0430 |
|      91 |        1000 |       00:00:01 |       96.88% |       0.0864 |          0.0387 |
|      96 |        1050 |       00:00:01 |       96.09% |       0.1348 |          0.0387 |
|     100 |        1100 |       00:00:02 |       96.09% |       0.1288 |          0.0387 |
|     105 |        1150 |       00:00:02 |       92.97% |       0.1847 |          0.0349 |
|     110 |        1200 |       00:00:02 |       99.22% |       0.0608 |          0.0349 |
|     114 |        1250 |       00:00:02 |       96.88% |       0.0810 |          0.0314 |
|     119 |        1300 |       00:00:02 |       98.44% |       0.0514 |          0.0314 |
|     123 |        1350 |       00:00:02 |       98.44% |       0.0599 |          0.0282 |
|     128 |        1400 |       00:00:02 |       96.88% |       0.0736 |          0.0282 |
|     132 |        1450 |       00:00:02 |       99.22% |       0.0293 |          0.0254 |
|     137 |        1500 |       00:00:02 |       99.22% |       0.0282 |          0.0254 |
|     141 |        1550 |       00:00:02 |       96.88% |       0.0857 |          0.0229 |
|     146 |        1600 |       00:00:02 |       96.09% |       0.1322 |          0.0229 |
|     150 |        1650 |       00:00:02 |       96.09% |       0.1281 |          0.0229 |
|     155 |        1700 |       00:00:02 |       92.97% |       0.1827 |          0.0206 |
|     160 |        1750 |       00:00:02 |       99.22% |       0.0598 |          0.0206 |
|     164 |        1800 |       00:00:03 |       96.88% |       0.0821 |          0.0185 |
|     169 |        1850 |       00:00:03 |       98.44% |       0.0512 |          0.0185 |
|     173 |        1900 |       00:00:03 |       98.44% |       0.0595 |          0.0167 |
|     178 |        1950 |       00:00:03 |       96.88% |       0.0734 |          0.0167 |
|     182 |        2000 |       00:00:03 |       99.22% |       0.0286 |          0.0150 |
|     187 |        2050 |       00:00:03 |       99.22% |       0.0281 |          0.0150 |
|     191 |        2100 |       00:00:03 |       96.88% |       0.0855 |          0.0135 |
|     196 |        2150 |       00:00:03 |       96.09% |       0.1310 |          0.0135 |
|     200 |        2200 |       00:00:03 |       96.09% |       0.1276 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9444, Recall: 1.0000, F1-Score: 0.9714
AUC: 0.9954
Processing dataset: Dutch Microfauna food web PlotA_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 444 / 760 (58.4%)
[DivideNet] Attempts made: 844 | Failed attempts: 400
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 400
    Train Negative: 400
    Test  Positive: 444
    Test  Negative: 444
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 800 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 888 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.2s
Progress: 79% – Elapsed: 0.2s
Progress: 89% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.2s
Done. Total time: 0.3s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       59.38% |       0.6952 |          0.1000 |
|       9 |          50 |       00:00:00 |       94.53% |       0.2232 |          0.1000 |
|      17 |         100 |       00:00:00 |       89.06% |       0.2921 |          0.0900 |
|      25 |         150 |       00:00:00 |       90.62% |       0.2600 |          0.0810 |
|      34 |         200 |       00:00:00 |       94.53% |       0.2089 |          0.0729 |
|      42 |         250 |       00:00:00 |       89.84% |       0.2722 |          0.0656 |
|      50 |         300 |       00:00:00 |       91.41% |       0.2470 |          0.0656 |
|      59 |         350 |       00:00:00 |       95.31% |       0.1983 |          0.0590 |
|      67 |         400 |       00:00:00 |       89.84% |       0.2651 |          0.0531 |
|      75 |         450 |       00:00:00 |       91.41% |       0.2433 |          0.0478 |
|      84 |         500 |       00:00:00 |       95.31% |       0.1936 |          0.0430 |
|      92 |         550 |       00:00:00 |       89.84% |       0.2622 |          0.0387 |
|     100 |         600 |       00:00:00 |       91.41% |       0.2423 |          0.0387 |
|     109 |         650 |       00:00:00 |       95.31% |       0.1917 |          0.0349 |
|     117 |         700 |       00:00:01 |       89.84% |       0.2613 |          0.0314 |
|     125 |         750 |       00:00:01 |       91.41% |       0.2422 |          0.0282 |
|     134 |         800 |       00:00:01 |       95.31% |       0.1868 |          0.0254 |
|     142 |         850 |       00:00:01 |       89.84% |       0.2610 |          0.0229 |
|     150 |         900 |       00:00:01 |       91.41% |       0.2421 |          0.0229 |
|     159 |         950 |       00:00:01 |       95.31% |       0.1902 |          0.0206 |
|     167 |        1000 |       00:00:01 |       89.84% |       0.2608 |          0.0185 |
|     175 |        1050 |       00:00:01 |       91.41% |       0.2421 |          0.0167 |
|     184 |        1100 |       00:00:01 |       95.31% |       0.1884 |          0.0150 |
|     192 |        1150 |       00:00:01 |       89.84% |       0.2605 |          0.0135 |
|     200 |        1200 |       00:00:01 |       91.41% |       0.2420 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.85, Precision: 0.9973, Recall: 0.8446, F1-Score: 0.9146
AUC: 0.9724
Processing dataset: Dutch Microfauna food web PlotA_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 446 / 718 (62.1%)
[DivideNet] Attempts made: 844 | Failed attempts: 398
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 398
    Train Negative: 398
    Test  Positive: 446
    Test  Negative: 446
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 796 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.2s
Progress: 69% – Elapsed: 0.2s
Progress: 79% – Elapsed: 0.3s
Progress: 89% – Elapsed: 0.3s
Progress: 99% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 892 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.2s
Progress: 50% – Elapsed: 0.2s
Progress: 60% – Elapsed: 0.2s
Progress: 70% – Elapsed: 0.3s
Progress: 80% – Elapsed: 0.3s
Progress: 90% – Elapsed: 0.4s
Progress: 100% – Elapsed: 0.4s
Done. Total time: 0.4s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       39.06% |       0.6931 |          0.1000 |
|       9 |          50 |       00:00:00 |       85.94% |       0.3373 |          0.1000 |
|      17 |         100 |       00:00:00 |       93.75% |       0.2044 |          0.0900 |
|      25 |         150 |       00:00:00 |       90.62% |       0.2634 |          0.0810 |
|      34 |         200 |       00:00:00 |       89.06% |       0.2822 |          0.0729 |
|      42 |         250 |       00:00:00 |       96.09% |       0.1776 |          0.0656 |
|      50 |         300 |       00:00:00 |       90.62% |       0.2566 |          0.0656 |
|      59 |         350 |       00:00:00 |       89.06% |       0.2727 |          0.0590 |
|      67 |         400 |       00:00:00 |       96.09% |       0.1795 |          0.0531 |
|      75 |         450 |       00:00:00 |       90.62% |       0.2551 |          0.0478 |
|      84 |         500 |       00:00:00 |       89.06% |       0.2707 |          0.0430 |
|      92 |         550 |       00:00:01 |       96.09% |       0.1687 |          0.0387 |
|     100 |         600 |       00:00:01 |       90.62% |       0.2544 |          0.0387 |
|     109 |         650 |       00:00:01 |       89.06% |       0.2703 |          0.0349 |
|     117 |         700 |       00:00:01 |       96.09% |       0.1677 |          0.0314 |
|     125 |         750 |       00:00:01 |       90.62% |       0.2540 |          0.0282 |
|     134 |         800 |       00:00:01 |       89.06% |       0.2701 |          0.0254 |
|     142 |         850 |       00:00:01 |       96.09% |       0.1666 |          0.0229 |
|     150 |         900 |       00:00:01 |       90.62% |       0.2536 |          0.0229 |
|     159 |         950 |       00:00:01 |       89.06% |       0.2699 |          0.0206 |
|     167 |        1000 |       00:00:01 |       96.09% |       0.1691 |          0.0185 |
|     175 |        1050 |       00:00:01 |       90.62% |       0.2536 |          0.0167 |
|     184 |        1100 |       00:00:02 |       89.06% |       0.2697 |          0.0150 |
|     192 |        1150 |       00:00:02 |       96.09% |       0.1678 |          0.0135 |
|     200 |        1200 |       00:00:02 |       90.62% |       0.2538 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.85, Precision: 1.0000, Recall: 0.8161, F1-Score: 0.8988
AUC: 0.9478
Processing dataset: Dutch Microfauna food web PlotA_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 445 / 676 (65.8%)
[DivideNet] Attempts made: 844 | Failed attempts: 399
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 399
    Train Negative: 399
    Test  Positive: 445
    Test  Negative: 445
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 798 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.2s
Progress: 30% – Elapsed: 0.2s
Progress: 40% – Elapsed: 0.3s
Progress: 49% – Elapsed: 0.3s
Progress: 59% – Elapsed: 0.3s
Progress: 69% – Elapsed: 0.3s
Progress: 79% – Elapsed: 0.4s
Progress: 89% – Elapsed: 0.4s
Progress: 99% – Elapsed: 0.5s
Done. Total time: 0.5s
Encoding 890 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.2s
Progress: 60% – Elapsed: 0.2s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.3s
Progress: 90% – Elapsed: 0.3s
Progress: 100% – Elapsed: 0.3s
Done. Total time: 0.3s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       51.56% |       0.6946 |          0.1000 |
|       9 |          50 |       00:00:00 |       91.41% |       0.2606 |          0.1000 |
|      17 |         100 |       00:00:00 |       87.50% |       0.3224 |          0.0900 |
|      25 |         150 |       00:00:00 |       92.19% |       0.2359 |          0.0810 |
|      34 |         200 |       00:00:00 |       91.41% |       0.2431 |          0.0729 |
|      42 |         250 |       00:00:00 |       87.50% |       0.3194 |          0.0656 |
|      50 |         300 |       00:00:00 |       92.19% |       0.2353 |          0.0656 |
|      59 |         350 |       00:00:00 |       91.41% |       0.2407 |          0.0590 |
|      67 |         400 |       00:00:00 |       87.50% |       0.3171 |          0.0531 |
|      75 |         450 |       00:00:01 |       92.19% |       0.2348 |          0.0478 |
|      84 |         500 |       00:00:01 |       91.41% |       0.2390 |          0.0430 |
|      92 |         550 |       00:00:01 |       87.50% |       0.3154 |          0.0387 |
|     100 |         600 |       00:00:01 |       92.19% |       0.2347 |          0.0387 |
|     109 |         650 |       00:00:01 |       91.41% |       0.2376 |          0.0349 |
|     117 |         700 |       00:00:02 |       87.50% |       0.3149 |          0.0314 |
|     125 |         750 |       00:00:02 |       92.19% |       0.2347 |          0.0282 |
|     134 |         800 |       00:00:02 |       91.41% |       0.2368 |          0.0254 |
|     142 |         850 |       00:00:02 |       87.50% |       0.3145 |          0.0229 |
|     150 |         900 |       00:00:02 |       92.19% |       0.2349 |          0.0229 |
|     159 |         950 |       00:00:02 |       91.41% |       0.2363 |          0.0206 |
|     167 |        1000 |       00:00:02 |       87.50% |       0.3147 |          0.0185 |
|     175 |        1050 |       00:00:03 |       92.19% |       0.2348 |          0.0167 |
|     184 |        1100 |       00:00:03 |       91.41% |       0.2362 |          0.0150 |
|     192 |        1150 |       00:00:03 |       87.50% |       0.3140 |          0.0135 |
|     200 |        1200 |       00:00:03 |       92.19% |       0.2348 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.7976, Recall: 0.7618, F1-Score: 0.7793
AUC: 0.8557
Processing dataset: Dutch Microfauna food web PlotA_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 444 / 633 (70.1%)
[DivideNet] Attempts made: 844 | Failed attempts: 400
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 400
    Train Negative: 400
    Test  Positive: 444
    Test  Negative: 444
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 800 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 888 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.2s
Progress: 69% – Elapsed: 0.2s
Progress: 79% – Elapsed: 0.2s
Progress: 89% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.3s
Done. Total time: 0.3s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       45.31% |       0.6501 |          0.1000 |
|       9 |          50 |       00:00:00 |       88.28% |       0.3156 |          0.1000 |
|      17 |         100 |       00:00:00 |       89.84% |       0.2908 |          0.0900 |
|      25 |         150 |       00:00:00 |       89.06% |       0.3022 |          0.0810 |
|      34 |         200 |       00:00:00 |       89.06% |       0.2900 |          0.0729 |
|      42 |         250 |       00:00:00 |       90.62% |       0.2428 |          0.0656 |
|      50 |         300 |       00:00:00 |       89.06% |       0.2799 |          0.0656 |
|      59 |         350 |       00:00:00 |       89.06% |       0.2882 |          0.0590 |
|      67 |         400 |       00:00:00 |       90.62% |       0.2399 |          0.0531 |
|      75 |         450 |       00:00:00 |       89.06% |       0.2689 |          0.0478 |
|      84 |         500 |       00:00:00 |       89.06% |       0.2896 |          0.0430 |
|      92 |         550 |       00:00:00 |       90.62% |       0.2425 |          0.0387 |
|     100 |         600 |       00:00:00 |       89.06% |       0.2735 |          0.0387 |
|     109 |         650 |       00:00:00 |       89.06% |       0.2889 |          0.0349 |
|     117 |         700 |       00:00:00 |       90.62% |       0.2386 |          0.0314 |
|     125 |         750 |       00:00:00 |       89.06% |       0.2710 |          0.0282 |
|     134 |         800 |       00:00:00 |       89.06% |       0.2885 |          0.0254 |
|     142 |         850 |       00:00:01 |       90.62% |       0.2379 |          0.0229 |
|     150 |         900 |       00:00:01 |       89.06% |       0.2703 |          0.0229 |
|     159 |         950 |       00:00:01 |       89.06% |       0.2881 |          0.0206 |
|     167 |        1000 |       00:00:01 |       90.62% |       0.2376 |          0.0185 |
|     175 |        1050 |       00:00:01 |       89.06% |       0.2701 |          0.0167 |
|     184 |        1100 |       00:00:01 |       89.06% |       0.2877 |          0.0150 |
|     192 |        1150 |       00:00:01 |       90.62% |       0.2374 |          0.0135 |
|     200 |        1200 |       00:00:01 |       89.06% |       0.2698 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.85, Precision: 1.0000, Recall: 0.7027, F1-Score: 0.8254
AUC: 0.9260
Processing dataset: Dutch Microfauna food web PlotA_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 446 / 591 (75.5%)
[DivideNet] Attempts made: 844 | Failed attempts: 398
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 398
    Train Negative: 398
    Test  Positive: 446
    Test  Negative: 446
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 796 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.2s
Progress: 69% – Elapsed: 0.2s
Progress: 79% – Elapsed: 0.2s
Progress: 89% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 892 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.2s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.3s
Done. Total time: 0.3s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       39.06% |       0.6895 |          0.1000 |
|       9 |          50 |       00:00:00 |       89.06% |       0.2719 |          0.1000 |
|      17 |         100 |       00:00:00 |       92.19% |       0.2256 |          0.0900 |
|      25 |         150 |       00:00:00 |       94.53% |       0.1953 |          0.0810 |
|      34 |         200 |       00:00:00 |       92.19% |       0.2314 |          0.0729 |
|      42 |         250 |       00:00:00 |       92.19% |       0.2146 |          0.0656 |
|      50 |         300 |       00:00:00 |       94.53% |       0.1956 |          0.0656 |
|      59 |         350 |       00:00:00 |       92.19% |       0.2286 |          0.0590 |
|      67 |         400 |       00:00:00 |       92.19% |       0.2138 |          0.0531 |
|      75 |         450 |       00:00:00 |       94.53% |       0.1941 |          0.0478 |
|      84 |         500 |       00:00:00 |       92.19% |       0.2281 |          0.0430 |
|      92 |         550 |       00:00:00 |       92.19% |       0.2133 |          0.0387 |
|     100 |         600 |       00:00:00 |       94.53% |       0.1921 |          0.0387 |
|     109 |         650 |       00:00:00 |       92.19% |       0.2278 |          0.0349 |
|     117 |         700 |       00:00:00 |       92.19% |       0.2132 |          0.0314 |
|     125 |         750 |       00:00:00 |       94.53% |       0.1919 |          0.0282 |
|     134 |         800 |       00:00:01 |       92.19% |       0.2278 |          0.0254 |
|     142 |         850 |       00:00:01 |       92.19% |       0.2131 |          0.0229 |
|     150 |         900 |       00:00:01 |       94.53% |       0.1912 |          0.0229 |
|     159 |         950 |       00:00:01 |       92.19% |       0.2277 |          0.0206 |
|     167 |        1000 |       00:00:01 |       92.19% |       0.2131 |          0.0185 |
|     175 |        1050 |       00:00:01 |       94.53% |       0.1909 |          0.0167 |
|     184 |        1100 |       00:00:01 |       92.19% |       0.2278 |          0.0150 |
|     192 |        1150 |       00:00:01 |       92.19% |       0.2131 |          0.0135 |
|     200 |        1200 |       00:00:01 |       94.53% |       0.1912 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.7947, Recall: 0.7466, F1-Score: 0.7699
AUC: 0.8504
