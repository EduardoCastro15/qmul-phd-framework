Processing dataset: F1P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 57 / 165 (34.5%)
[DivideNet] Attempts made: 253 | Failed attempts: 196
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 200
    Train Negative: 400
    Test  Positive: 57
    Test  Negative: 114
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 600 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.1s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 171 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 99% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       60.16% |       0.7215 |          0.1000 |
|      13 |          50 |       00:00:00 |       83.59% |       0.3303 |          0.0900 |
|      25 |         100 |       00:00:00 |       87.50% |       0.2670 |          0.0810 |
|      38 |         150 |       00:00:00 |       86.72% |       0.2623 |          0.0729 |
|      50 |         200 |       00:00:00 |       87.50% |       0.2658 |          0.0656 |
|      63 |         250 |       00:00:00 |       86.72% |       0.2552 |          0.0531 |
|      75 |         300 |       00:00:00 |       87.50% |       0.2654 |          0.0478 |
|      88 |         350 |       00:00:00 |       86.72% |       0.2541 |          0.0430 |
|     100 |         400 |       00:00:00 |       87.50% |       0.2651 |          0.0387 |
|     113 |         450 |       00:00:00 |       86.72% |       0.2536 |          0.0314 |
|     125 |         500 |       00:00:00 |       87.50% |       0.2651 |          0.0282 |
|     138 |         550 |       00:00:00 |       86.72% |       0.2530 |          0.0254 |
|     150 |         600 |       00:00:00 |       87.50% |       0.2651 |          0.0229 |
|     163 |         650 |       00:00:00 |       86.72% |       0.2529 |          0.0185 |
|     175 |         700 |       00:00:00 |       87.50% |       0.2649 |          0.0167 |
|     188 |         750 |       00:00:00 |       86.72% |       0.2527 |          0.0150 |
|     200 |         800 |       00:00:01 |       87.50% |       0.2650 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.70, Precision: 1.0000, Recall: 0.8596, F1-Score: 0.9245
AUC: 0.9746
Processing dataset: F1P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 57 / 152 (37.5%)
[DivideNet] Attempts made: 253 | Failed attempts: 196
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 200
    Train Negative: 400
    Test  Positive: 57
    Test  Negative: 114
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 600 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.1s
Progress: 100% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 171 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 99% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       67.97% |       0.6666 |          0.1000 |
|      13 |          50 |       00:00:00 |       85.94% |       0.3117 |          0.0900 |
|      25 |         100 |       00:00:00 |       91.41% |       0.2356 |          0.0810 |
|      38 |         150 |       00:00:00 |       85.94% |       0.2828 |          0.0729 |
|      50 |         200 |       00:00:00 |       91.41% |       0.2204 |          0.0656 |
|      63 |         250 |       00:00:00 |       85.94% |       0.2720 |          0.0531 |
|      75 |         300 |       00:00:00 |       91.41% |       0.2165 |          0.0478 |
|      88 |         350 |       00:00:00 |       85.94% |       0.2705 |          0.0430 |
|     100 |         400 |       00:00:00 |       91.41% |       0.2157 |          0.0387 |
|     113 |         450 |       00:00:00 |       85.94% |       0.2682 |          0.0314 |
|     125 |         500 |       00:00:00 |       91.41% |       0.2159 |          0.0282 |
|     138 |         550 |       00:00:00 |       85.94% |       0.2678 |          0.0254 |
|     150 |         600 |       00:00:00 |       91.41% |       0.2145 |          0.0229 |
|     163 |         650 |       00:00:00 |       85.94% |       0.2670 |          0.0185 |
|     175 |         700 |       00:00:00 |       91.41% |       0.2142 |          0.0167 |
|     188 |         750 |       00:00:00 |       85.94% |       0.2669 |          0.0150 |
|     200 |         800 |       00:00:00 |       91.41% |       0.2140 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.45, Precision: 0.7246, Recall: 0.8772, F1-Score: 0.7937
AUC: 0.8816
Processing dataset: F1P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 57 / 140 (40.7%)
[DivideNet] Attempts made: 253 | Failed attempts: 196
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 200
    Train Negative: 400
    Test  Positive: 57
    Test  Negative: 114
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 600 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.1s
Progress: 20% – Elapsed: 0.2s
Progress: 30% – Elapsed: 0.2s
Progress: 40% – Elapsed: 0.2s
Progress: 50% – Elapsed: 0.2s
Progress: 60% – Elapsed: 0.2s
Progress: 70% – Elapsed: 0.3s
Progress: 80% – Elapsed: 0.3s
Progress: 90% – Elapsed: 0.3s
Progress: 100% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 171 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 99% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       71.88% |       0.6053 |          0.1000 |
|      13 |          50 |       00:00:00 |       87.50% |       0.3212 |          0.0900 |
|      25 |         100 |       00:00:00 |       85.94% |       0.2904 |          0.0810 |
|      38 |         150 |       00:00:00 |       89.06% |       0.2624 |          0.0729 |
|      50 |         200 |       00:00:00 |       86.72% |       0.2734 |          0.0656 |
|      63 |         250 |       00:00:01 |       89.06% |       0.2602 |          0.0531 |
|      75 |         300 |       00:00:01 |       86.72% |       0.2700 |          0.0478 |
|      88 |         350 |       00:00:01 |       89.06% |       0.2594 |          0.0430 |
|     100 |         400 |       00:00:01 |       86.72% |       0.2693 |          0.0387 |
|     113 |         450 |       00:00:01 |       89.06% |       0.2587 |          0.0314 |
|     125 |         500 |       00:00:01 |       86.72% |       0.2688 |          0.0282 |
|     138 |         550 |       00:00:01 |       89.06% |       0.2583 |          0.0254 |
|     150 |         600 |       00:00:01 |       86.72% |       0.2685 |          0.0229 |
|     163 |         650 |       00:00:01 |       89.06% |       0.2579 |          0.0185 |
|     175 |         700 |       00:00:01 |       86.72% |       0.2683 |          0.0167 |
|     188 |         750 |       00:00:01 |       89.06% |       0.2579 |          0.0150 |
|     200 |         800 |       00:00:01 |       86.72% |       0.2681 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.6329, Recall: 0.8772, F1-Score: 0.7353
AUC: 0.8948
Processing dataset: F1P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 57 / 127 (44.9%)
[DivideNet] Attempts made: 253 | Failed attempts: 196
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 200
    Train Negative: 400
    Test  Positive: 57
    Test  Negative: 114
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 600 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 171 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 99% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       68.75% |       0.6385 |          0.1000 |
|      13 |          50 |       00:00:00 |       82.03% |       0.3778 |          0.0900 |
|      25 |         100 |       00:00:00 |       85.94% |       0.3104 |          0.0810 |
|      38 |         150 |       00:00:00 |       83.59% |       0.3176 |          0.0729 |
|      50 |         200 |       00:00:00 |       85.94% |       0.3107 |          0.0656 |
|      63 |         250 |       00:00:00 |       83.59% |       0.3100 |          0.0531 |
|      75 |         300 |       00:00:00 |       85.94% |       0.3063 |          0.0478 |
|      88 |         350 |       00:00:00 |       83.59% |       0.3071 |          0.0430 |
|     100 |         400 |       00:00:00 |       85.94% |       0.3046 |          0.0387 |
|     113 |         450 |       00:00:00 |       83.59% |       0.3047 |          0.0314 |
|     125 |         500 |       00:00:00 |       85.94% |       0.3029 |          0.0282 |
|     138 |         550 |       00:00:00 |       83.59% |       0.3032 |          0.0254 |
|     150 |         600 |       00:00:00 |       85.94% |       0.3027 |          0.0229 |
|     163 |         650 |       00:00:00 |       83.59% |       0.3020 |          0.0185 |
|     175 |         700 |       00:00:00 |       85.94% |       0.3026 |          0.0167 |
|     188 |         750 |       00:00:01 |       83.59% |       0.3016 |          0.0150 |
|     200 |         800 |       00:00:01 |       85.94% |       0.3021 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.7353, Recall: 0.8772, F1-Score: 0.8000
AUC: 0.8389
Processing dataset: F1P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 57 / 114 (50.0%)
[DivideNet] Attempts made: 253 | Failed attempts: 196
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 200
    Train Negative: 400
    Test  Positive: 57
    Test  Negative: 114
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 600 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 171 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 99% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       46.88% |       0.6898 |          0.1000 |
|      13 |          50 |       00:00:00 |       89.06% |       0.2857 |          0.0900 |
|      25 |         100 |       00:00:00 |       89.06% |       0.2660 |          0.0810 |
|      38 |         150 |       00:00:00 |       90.62% |       0.2185 |          0.0729 |
|      50 |         200 |       00:00:00 |       89.06% |       0.2669 |          0.0656 |
|      63 |         250 |       00:00:00 |       90.62% |       0.2146 |          0.0531 |
|      75 |         300 |       00:00:00 |       89.06% |       0.2623 |          0.0478 |
|      88 |         350 |       00:00:00 |       90.62% |       0.2137 |          0.0430 |
|     100 |         400 |       00:00:00 |       89.06% |       0.2622 |          0.0387 |
|     113 |         450 |       00:00:00 |       90.62% |       0.2129 |          0.0314 |
|     125 |         500 |       00:00:00 |       89.06% |       0.2619 |          0.0282 |
|     138 |         550 |       00:00:00 |       90.62% |       0.2126 |          0.0254 |
|     150 |         600 |       00:00:00 |       89.06% |       0.2624 |          0.0229 |
|     163 |         650 |       00:00:00 |       90.62% |       0.2124 |          0.0185 |
|     175 |         700 |       00:00:00 |       89.06% |       0.2618 |          0.0167 |
|     188 |         750 |       00:00:01 |       90.62% |       0.2123 |          0.0150 |
|     200 |         800 |       00:00:01 |       89.06% |       0.2617 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.6944, Recall: 0.8772, F1-Score: 0.7752
AUC: 0.9743
Processing dataset: F1P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 57 / 102 (55.9%)
[DivideNet] Attempts made: 253 | Failed attempts: 196
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 200
    Train Negative: 400
    Test  Positive: 57
    Test  Negative: 114
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 600 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.1s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 171 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 99% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       35.16% |       0.8698 |          0.1000 |
|      13 |          50 |       00:00:00 |       89.06% |       0.2857 |          0.0900 |
|      25 |         100 |       00:00:00 |       83.59% |       0.3483 |          0.0810 |
|      38 |         150 |       00:00:00 |       89.84% |       0.2361 |          0.0729 |
|      50 |         200 |       00:00:00 |       85.16% |       0.2909 |          0.0656 |
|      63 |         250 |       00:00:00 |       89.84% |       0.2421 |          0.0531 |
|      75 |         300 |       00:00:00 |       85.16% |       0.2834 |          0.0478 |
|      88 |         350 |       00:00:00 |       89.84% |       0.2377 |          0.0430 |
|     100 |         400 |       00:00:00 |       85.16% |       0.2825 |          0.0387 |
|     113 |         450 |       00:00:00 |       89.84% |       0.2382 |          0.0314 |
|     125 |         500 |       00:00:00 |       85.16% |       0.2807 |          0.0282 |
|     138 |         550 |       00:00:00 |       89.84% |       0.2360 |          0.0254 |
|     150 |         600 |       00:00:00 |       85.16% |       0.2800 |          0.0229 |
|     163 |         650 |       00:00:00 |       89.84% |       0.2348 |          0.0185 |
|     175 |         700 |       00:00:00 |       85.16% |       0.2796 |          0.0167 |
|     188 |         750 |       00:00:00 |       89.84% |       0.2347 |          0.0150 |
|     200 |         800 |       00:00:01 |       85.16% |       0.2793 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.8028, Recall: 1.0000, F1-Score: 0.8906
AUC: 0.9472
Processing dataset: F1P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 57 / 89 (64.0%)
[DivideNet] Attempts made: 253 | Failed attempts: 196
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 200
    Train Negative: 400
    Test  Positive: 57
    Test  Negative: 114
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 600 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 171 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 99% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       59.38% |       0.6729 |          0.1000 |
|      13 |          50 |       00:00:00 |       86.72% |       0.3058 |          0.0900 |
|      25 |         100 |       00:00:00 |       92.19% |       0.2197 |          0.0810 |
|      38 |         150 |       00:00:00 |       87.50% |       0.2678 |          0.0729 |
|      50 |         200 |       00:00:00 |       92.19% |       0.1901 |          0.0656 |
|      63 |         250 |       00:00:00 |       87.50% |       0.2649 |          0.0531 |
|      75 |         300 |       00:00:00 |       92.19% |       0.1880 |          0.0478 |
|      88 |         350 |       00:00:00 |       87.50% |       0.2641 |          0.0430 |
|     100 |         400 |       00:00:00 |       92.19% |       0.1870 |          0.0387 |
|     113 |         450 |       00:00:00 |       87.50% |       0.2637 |          0.0314 |
|     125 |         500 |       00:00:00 |       92.19% |       0.1867 |          0.0282 |
|     138 |         550 |       00:00:01 |       87.50% |       0.2634 |          0.0254 |
|     150 |         600 |       00:00:01 |       92.19% |       0.1858 |          0.0229 |
|     163 |         650 |       00:00:01 |       87.50% |       0.2633 |          0.0185 |
|     175 |         700 |       00:00:01 |       92.19% |       0.1855 |          0.0167 |
|     188 |         750 |       00:00:01 |       87.50% |       0.2632 |          0.0150 |
|     200 |         800 |       00:00:01 |       92.19% |       0.1854 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.7576, Recall: 0.8772, F1-Score: 0.8130
AUC: 0.9332
Processing dataset: F1P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 57 / 76 (75.0%)
[DivideNet] Attempts made: 253 | Failed attempts: 196
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 200
    Train Negative: 400
    Test  Positive: 57
    Test  Negative: 114
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 600 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.1s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 171 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 99% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       68.75% |       0.6918 |          0.1000 |
|      13 |          50 |       00:00:00 |       84.38% |       0.3307 |          0.0900 |
|      25 |         100 |       00:00:00 |       88.28% |       0.2597 |          0.0810 |
|      38 |         150 |       00:00:00 |       86.72% |       0.2631 |          0.0729 |
|      50 |         200 |       00:00:00 |       89.06% |       0.2510 |          0.0656 |
|      63 |         250 |       00:00:00 |       86.72% |       0.2593 |          0.0531 |
|      75 |         300 |       00:00:00 |       89.06% |       0.2445 |          0.0478 |
|      88 |         350 |       00:00:00 |       86.72% |       0.2586 |          0.0430 |
|     100 |         400 |       00:00:00 |       89.06% |       0.2439 |          0.0387 |
|     113 |         450 |       00:00:00 |       86.72% |       0.2580 |          0.0314 |
|     125 |         500 |       00:00:00 |       89.06% |       0.2434 |          0.0282 |
|     138 |         550 |       00:00:00 |       86.72% |       0.2577 |          0.0254 |
|     150 |         600 |       00:00:00 |       89.06% |       0.2433 |          0.0229 |
|     163 |         650 |       00:00:00 |       86.72% |       0.2574 |          0.0185 |
|     175 |         700 |       00:00:00 |       89.06% |       0.2431 |          0.0167 |
|     188 |         750 |       00:00:00 |       86.72% |       0.2572 |          0.0150 |
|     200 |         800 |       00:00:00 |       89.06% |       0.2430 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.6111, Recall: 0.5789, F1-Score: 0.5946
AUC: 0.8105
Processing dataset: F1P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 57 / 64 (89.1%)
[DivideNet] Attempts made: 253 | Failed attempts: 196
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 200
    Train Negative: 400
    Test  Positive: 57
    Test  Negative: 114
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 600 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 171 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 99% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       39.84% |       0.6866 |          0.1000 |
|      13 |          50 |       00:00:00 |       85.94% |       0.2794 |          0.0900 |
|      25 |         100 |       00:00:00 |       89.06% |       0.2456 |          0.0810 |
|      38 |         150 |       00:00:00 |       89.06% |       0.2310 |          0.0729 |
|      50 |         200 |       00:00:00 |       89.84% |       0.2297 |          0.0656 |
|      63 |         250 |       00:00:00 |       89.06% |       0.2254 |          0.0531 |
|      75 |         300 |       00:00:00 |       89.84% |       0.2291 |          0.0478 |
|      88 |         350 |       00:00:00 |       89.06% |       0.2239 |          0.0430 |
|     100 |         400 |       00:00:00 |       89.84% |       0.2289 |          0.0387 |
|     113 |         450 |       00:00:00 |       89.06% |       0.2230 |          0.0314 |
|     125 |         500 |       00:00:00 |       89.84% |       0.2288 |          0.0282 |
|     138 |         550 |       00:00:00 |       89.06% |       0.2227 |          0.0254 |
|     150 |         600 |       00:00:00 |       89.84% |       0.2288 |          0.0229 |
|     163 |         650 |       00:00:01 |       89.06% |       0.2224 |          0.0185 |
|     175 |         700 |       00:00:01 |       89.84% |       0.2287 |          0.0167 |
|     188 |         750 |       00:00:01 |       89.06% |       0.2223 |          0.0150 |
|     200 |         800 |       00:00:01 |       89.84% |       0.2287 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.7042, Recall: 0.8772, F1-Score: 0.7812
AUC: 0.8133
Processing dataset: F1P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 51 / 51 (100.0%)
[DivideNet] Attempts made: 222 | Failed attempts: 171
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 206
    Train Negative: 412
    Test  Positive: 51
    Test  Negative: 102
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 618 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 99% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 153 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 59% – Elapsed: 0.0s
Progress: 69% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 88% – Elapsed: 0.0s
Progress: 98% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       32.81% |       0.7329 |          0.1000 |
|      13 |          50 |       00:00:00 |       85.94% |       0.3168 |          0.0900 |
|      25 |         100 |       00:00:00 |       87.50% |       0.2962 |          0.0810 |
|      38 |         150 |       00:00:00 |       86.72% |       0.3113 |          0.0729 |
|      50 |         200 |       00:00:00 |       86.72% |       0.2734 |          0.0656 |
|      63 |         250 |       00:00:00 |       86.72% |       0.2810 |          0.0531 |
|      75 |         300 |       00:00:00 |       87.50% |       0.2683 |          0.0478 |
|      88 |         350 |       00:00:00 |       86.72% |       0.2798 |          0.0430 |
|     100 |         400 |       00:00:00 |       87.50% |       0.2672 |          0.0387 |
|     113 |         450 |       00:00:00 |       86.72% |       0.2790 |          0.0314 |
|     125 |         500 |       00:00:00 |       87.50% |       0.2665 |          0.0282 |
|     138 |         550 |       00:00:00 |       86.72% |       0.2784 |          0.0254 |
|     150 |         600 |       00:00:00 |       87.50% |       0.2660 |          0.0229 |
|     163 |         650 |       00:00:01 |       86.72% |       0.2780 |          0.0185 |
|     175 |         700 |       00:00:01 |       87.50% |       0.2656 |          0.0167 |
|     188 |         750 |       00:00:01 |       86.72% |       0.2776 |          0.0150 |
|     200 |         800 |       00:00:01 |       87.50% |       0.2654 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.80, Precision: 1.0000, Recall: 0.8824, F1-Score: 0.9375
AUC: 0.9841
Processing dataset: F1P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 38 / 38 (100.0%)
[DivideNet] Attempts made: 181 | Failed attempts: 143
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 219
    Train Negative: 438
    Test  Positive: 38
    Test  Negative: 76
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 657 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.2s
Progress: 79% – Elapsed: 0.2s
Progress: 89% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 114 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 77% – Elapsed: 0.0s
Progress: 87% – Elapsed: 0.0s
Progress: 96% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       47.66% |       0.6951 |          0.1000 |
|      10 |          50 |       00:00:00 |       89.84% |       0.2600 |          0.1000 |
|      20 |         100 |       00:00:00 |       93.75% |       0.1649 |          0.0900 |
|      30 |         150 |       00:00:00 |       93.75% |       0.1586 |          0.0810 |
|      40 |         200 |       00:00:00 |       93.75% |       0.1578 |          0.0729 |
|      50 |         250 |       00:00:00 |       93.75% |       0.1579 |          0.0656 |
|      60 |         300 |       00:00:00 |       93.75% |       0.1574 |          0.0590 |
|      70 |         350 |       00:00:00 |       93.75% |       0.1574 |          0.0531 |
|      80 |         400 |       00:00:00 |       93.75% |       0.1573 |          0.0478 |
|      90 |         450 |       00:00:00 |       93.75% |       0.1570 |          0.0430 |
|     100 |         500 |       00:00:00 |       93.75% |       0.1572 |          0.0387 |
|     110 |         550 |       00:00:00 |       93.75% |       0.1572 |          0.0349 |
|     120 |         600 |       00:00:00 |       93.75% |       0.1574 |          0.0314 |
|     130 |         650 |       00:00:00 |       93.75% |       0.1572 |          0.0282 |
|     140 |         700 |       00:00:01 |       93.75% |       0.1572 |          0.0254 |
|     150 |         750 |       00:00:01 |       93.75% |       0.1571 |          0.0229 |
|     160 |         800 |       00:00:01 |       93.75% |       0.1571 |          0.0206 |
|     170 |         850 |       00:00:01 |       93.75% |       0.1573 |          0.0185 |
|     180 |         900 |       00:00:01 |       93.75% |       0.1571 |          0.0167 |
|     190 |         950 |       00:00:01 |       93.75% |       0.1571 |          0.0150 |
|     200 |        1000 |       00:00:01 |       93.75% |       0.1571 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.80, Precision: 1.0000, Recall: 0.9211, F1-Score: 0.9589
AUC: 0.9624
Processing dataset: F1P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 26 / 26 (100.0%)
[DivideNet] Attempts made: 108 | Failed attempts: 82
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 231
    Train Negative: 462
    Test  Positive: 26
    Test  Negative: 52
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 693 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 78 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Progress: 18% – Elapsed: 0.0s
Progress: 27% – Elapsed: 0.0s
Progress: 36% – Elapsed: 0.0s
Progress: 45% – Elapsed: 0.0s
Progress: 54% – Elapsed: 0.0s
Progress: 63% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 81% – Elapsed: 0.0s
Progress: 90% – Elapsed: 0.0s
Progress: 99% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       76.56% |       0.6285 |          0.1000 |
|      10 |          50 |       00:00:00 |       85.16% |       0.3021 |          0.1000 |
|      20 |         100 |       00:00:00 |       87.50% |       0.2667 |          0.0900 |
|      30 |         150 |       00:00:00 |       87.50% |       0.2582 |          0.0810 |
|      40 |         200 |       00:00:00 |       87.50% |       0.2531 |          0.0729 |
|      50 |         250 |       00:00:00 |       87.50% |       0.2532 |          0.0656 |
|      60 |         300 |       00:00:00 |       87.50% |       0.2510 |          0.0590 |
|      70 |         350 |       00:00:00 |       87.50% |       0.2507 |          0.0531 |
|      80 |         400 |       00:00:00 |       87.50% |       0.2496 |          0.0478 |
|      90 |         450 |       00:00:00 |       87.50% |       0.2495 |          0.0430 |
|     100 |         500 |       00:00:00 |       87.50% |       0.2489 |          0.0387 |
|     110 |         550 |       00:00:00 |       87.50% |       0.2490 |          0.0349 |
|     120 |         600 |       00:00:01 |       87.50% |       0.2479 |          0.0314 |
|     130 |         650 |       00:00:01 |       87.50% |       0.2480 |          0.0282 |
|     140 |         700 |       00:00:01 |       87.50% |       0.2479 |          0.0254 |
|     150 |         750 |       00:00:01 |       87.50% |       0.2476 |          0.0229 |
|     160 |         800 |       00:00:01 |       87.50% |       0.2476 |          0.0206 |
|     170 |         850 |       00:00:01 |       87.50% |       0.2471 |          0.0185 |
|     180 |         900 |       00:00:01 |       87.50% |       0.2470 |          0.0167 |
|     190 |         950 |       00:00:01 |       87.50% |       0.2472 |          0.0150 |
|     200 |        1000 |       00:00:01 |       87.50% |       0.2474 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.15, Precision: 0.7667, Recall: 0.8846, F1-Score: 0.8214
AUC: 0.8835
Processing dataset: F1P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 57 / 228 (25.0%)
[DivideNet] Attempts made: 253 | Failed attempts: 196
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 200
    Train Negative: 400
    Test  Positive: 57
    Test  Negative: 114
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 600 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.1s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 171 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.1s
Progress: 99% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       50.78% |       0.7119 |          0.1000 |
|      13 |          50 |       00:00:00 |       81.25% |       0.4166 |          0.0900 |
|      25 |         100 |       00:00:00 |       88.28% |       0.2471 |          0.0810 |
|      38 |         150 |       00:00:00 |       82.81% |       0.3291 |          0.0729 |
|      50 |         200 |       00:00:00 |       88.28% |       0.2303 |          0.0656 |
|      63 |         250 |       00:00:00 |       82.81% |       0.3271 |          0.0531 |
|      75 |         300 |       00:00:00 |       88.28% |       0.2295 |          0.0478 |
|      88 |         350 |       00:00:00 |       82.81% |       0.3258 |          0.0430 |
|     100 |         400 |       00:00:00 |       88.28% |       0.2293 |          0.0387 |
|     113 |         450 |       00:00:00 |       82.81% |       0.3241 |          0.0314 |
|     125 |         500 |       00:00:00 |       88.28% |       0.2292 |          0.0282 |
|     138 |         550 |       00:00:00 |       82.81% |       0.3236 |          0.0254 |
|     150 |         600 |       00:00:00 |       88.28% |       0.2292 |          0.0229 |
|     163 |         650 |       00:00:00 |       82.81% |       0.3230 |          0.0185 |
|     175 |         700 |       00:00:01 |       88.28% |       0.2291 |          0.0167 |
|     188 |         750 |       00:00:01 |       82.81% |       0.3226 |          0.0150 |
|     200 |         800 |       00:00:01 |       88.28% |       0.2290 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.4615, Recall: 0.3158, F1-Score: 0.3750
AUC: 0.8206
Processing dataset: F1P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 57 / 216 (26.4%)
[DivideNet] Attempts made: 253 | Failed attempts: 196
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 200
    Train Negative: 400
    Test  Positive: 57
    Test  Negative: 114
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 600 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.2s
Progress: 60% – Elapsed: 0.2s
Progress: 70% – Elapsed: 0.3s
Progress: 80% – Elapsed: 0.3s
Progress: 90% – Elapsed: 0.4s
Progress: 100% – Elapsed: 0.4s
Done. Total time: 0.4s
Encoding 171 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 99% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       35.16% |       0.7834 |          0.1000 |
|      13 |          50 |       00:00:00 |       87.50% |       0.2955 |          0.0900 |
|      25 |         100 |       00:00:00 |       85.94% |       0.3109 |          0.0810 |
|      38 |         150 |       00:00:00 |       91.41% |       0.2426 |          0.0729 |
|      50 |         200 |       00:00:00 |       85.94% |       0.2800 |          0.0656 |
|      63 |         250 |       00:00:00 |       91.41% |       0.2273 |          0.0531 |
|      75 |         300 |       00:00:00 |       85.94% |       0.2767 |          0.0478 |
|      88 |         350 |       00:00:00 |       91.41% |       0.2233 |          0.0430 |
|     100 |         400 |       00:00:00 |       85.94% |       0.2786 |          0.0387 |
|     113 |         450 |       00:00:00 |       91.41% |       0.2216 |          0.0314 |
|     125 |         500 |       00:00:00 |       85.94% |       0.2751 |          0.0282 |
|     138 |         550 |       00:00:01 |       91.41% |       0.2216 |          0.0254 |
|     150 |         600 |       00:00:01 |       85.94% |       0.2746 |          0.0229 |
|     163 |         650 |       00:00:02 |       91.41% |       0.2198 |          0.0185 |
|     175 |         700 |       00:00:02 |       85.94% |       0.2743 |          0.0167 |
|     188 |         750 |       00:00:02 |       91.41% |       0.2198 |          0.0150 |
|     200 |         800 |       00:00:02 |       85.94% |       0.2742 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.6182, Recall: 0.5965, F1-Score: 0.6071
AUC: 0.8129
Processing dataset: F1P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 57 / 203 (28.1%)
[DivideNet] Attempts made: 253 | Failed attempts: 196
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 200
    Train Negative: 400
    Test  Positive: 57
    Test  Negative: 114
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 600 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 171 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 99% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       32.03% |       0.7089 |          0.1000 |
|      13 |          50 |       00:00:00 |       88.28% |       0.3053 |          0.0900 |
|      25 |         100 |       00:00:00 |       87.50% |       0.2795 |          0.0810 |
|      38 |         150 |       00:00:00 |       89.84% |       0.2567 |          0.0729 |
|      50 |         200 |       00:00:00 |       87.50% |       0.2561 |          0.0656 |
|      63 |         250 |       00:00:00 |       89.84% |       0.2431 |          0.0531 |
|      75 |         300 |       00:00:00 |       87.50% |       0.2520 |          0.0478 |
|      88 |         350 |       00:00:00 |       89.84% |       0.2409 |          0.0430 |
|     100 |         400 |       00:00:00 |       87.50% |       0.2495 |          0.0387 |
|     113 |         450 |       00:00:00 |       89.84% |       0.2394 |          0.0314 |
|     125 |         500 |       00:00:00 |       87.50% |       0.2485 |          0.0282 |
|     138 |         550 |       00:00:00 |       89.84% |       0.2389 |          0.0254 |
|     150 |         600 |       00:00:00 |       87.50% |       0.2480 |          0.0229 |
|     163 |         650 |       00:00:01 |       89.84% |       0.2381 |          0.0185 |
|     175 |         700 |       00:00:01 |       87.50% |       0.2476 |          0.0167 |
|     188 |         750 |       00:00:01 |       89.84% |       0.2379 |          0.0150 |
|     200 |         800 |       00:00:01 |       87.50% |       0.2475 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.7692, Recall: 0.8772, F1-Score: 0.8197
AUC: 0.9378
Processing dataset: F1P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 57 / 190 (30.0%)
[DivideNet] Attempts made: 253 | Failed attempts: 196
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 200
    Train Negative: 400
    Test  Positive: 57
    Test  Negative: 114
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 600 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 171 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 99% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       83.59% |       0.6549 |          0.1000 |
|      13 |          50 |       00:00:00 |       84.38% |       0.3410 |          0.0900 |
|      25 |         100 |       00:00:00 |       86.72% |       0.2970 |          0.0810 |
|      38 |         150 |       00:00:00 |       87.50% |       0.2676 |          0.0729 |
|      50 |         200 |       00:00:00 |       87.50% |       0.2560 |          0.0656 |
|      63 |         250 |       00:00:00 |       87.50% |       0.2549 |          0.0531 |
|      75 |         300 |       00:00:00 |       87.50% |       0.2546 |          0.0478 |
|      88 |         350 |       00:00:00 |       87.50% |       0.2534 |          0.0430 |
|     100 |         400 |       00:00:00 |       87.50% |       0.2541 |          0.0387 |
|     113 |         450 |       00:00:00 |       87.50% |       0.2528 |          0.0314 |
|     125 |         500 |       00:00:00 |       87.50% |       0.2540 |          0.0282 |
|     138 |         550 |       00:00:00 |       87.50% |       0.2525 |          0.0254 |
|     150 |         600 |       00:00:00 |       87.50% |       0.2540 |          0.0229 |
|     163 |         650 |       00:00:00 |       87.50% |       0.2523 |          0.0185 |
|     175 |         700 |       00:00:00 |       87.50% |       0.2539 |          0.0167 |
|     188 |         750 |       00:00:01 |       87.50% |       0.2522 |          0.0150 |
|     200 |         800 |       00:00:01 |       87.50% |       0.2539 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.7692, Recall: 0.8772, F1-Score: 0.8197
AUC: 0.9444
Processing dataset: F1P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 57 / 178 (32.0%)
[DivideNet] Attempts made: 253 | Failed attempts: 196
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 200
    Train Negative: 400
    Test  Positive: 57
    Test  Negative: 114
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 600 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.1s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 171 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 99% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       35.16% |       0.7006 |          0.1000 |
|      13 |          50 |       00:00:00 |       85.94% |       0.3162 |          0.0900 |
|      25 |         100 |       00:00:00 |       89.84% |       0.2440 |          0.0810 |
|      38 |         150 |       00:00:00 |       89.06% |       0.2482 |          0.0729 |
|      50 |         200 |       00:00:00 |       89.84% |       0.2320 |          0.0656 |
|      63 |         250 |       00:00:00 |       89.06% |       0.2452 |          0.0531 |
|      75 |         300 |       00:00:00 |       89.84% |       0.2308 |          0.0478 |
|      88 |         350 |       00:00:00 |       89.06% |       0.2440 |          0.0430 |
|     100 |         400 |       00:00:00 |       89.84% |       0.2295 |          0.0387 |
|     113 |         450 |       00:00:00 |       89.06% |       0.2434 |          0.0314 |
|     125 |         500 |       00:00:00 |       89.84% |       0.2291 |          0.0282 |
|     138 |         550 |       00:00:00 |       89.06% |       0.2432 |          0.0254 |
|     150 |         600 |       00:00:00 |       89.84% |       0.2288 |          0.0229 |
|     163 |         650 |       00:00:00 |       89.06% |       0.2431 |          0.0185 |
|     175 |         700 |       00:00:00 |       89.84% |       0.2285 |          0.0167 |
|     188 |         750 |       00:00:00 |       89.06% |       0.2429 |          0.0150 |
|     200 |         800 |       00:00:00 |       89.84% |       0.2284 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.7812, Recall: 0.8772, F1-Score: 0.8264
AUC: 0.8783
