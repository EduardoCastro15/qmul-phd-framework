Processing dataset: Chub lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 28 / 52 (53.8%)
[DivideNet] Attempts made: 80 | Failed attempts: 52
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 55
    Train Negative: 110
    Test  Positive: 28
    Test  Negative: 56
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 165 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 87% – Elapsed: 0.0s
Progress: 97% – Elapsed: 0.0s
Done. Total time: 0.0s
Encoding 84 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 76% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.0s
Progress: 95% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       81.25% |       0.6518 |          0.1000 |
|      50 |          50 |       00:00:00 |       98.44% |       0.0539 |          0.0656 |
|     100 |         100 |       00:00:00 |       98.44% |       0.0497 |          0.0387 |
|     150 |         150 |       00:00:00 |       98.44% |       0.0495 |          0.0229 |
|     200 |         200 |       00:00:00 |       98.44% |       0.0495 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.3214, F1-Score: 0.4865
AUC: 0.8074
Processing dataset: Chub lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 28 / 49 (57.1%)
[DivideNet] Attempts made: 80 | Failed attempts: 52
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 55
    Train Negative: 110
    Test  Positive: 28
    Test  Negative: 56
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 165 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 87% – Elapsed: 0.0s
Progress: 97% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 84 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 76% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.0s
Progress: 95% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       31.25% |       0.6898 |          0.1000 |
|      50 |          50 |       00:00:00 |       97.66% |       0.0817 |          0.0656 |
|     100 |         100 |       00:00:00 |       97.66% |       0.0619 |          0.0387 |
|     150 |         150 |       00:00:00 |       97.66% |       0.0613 |          0.0229 |
|     200 |         200 |       00:00:00 |       97.66% |       0.0612 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.8889, Recall: 0.2857, F1-Score: 0.4324
AUC: 0.8233
Processing dataset: Chub lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 28 / 44 (63.6%)
[DivideNet] Attempts made: 80 | Failed attempts: 52
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 55
    Train Negative: 110
    Test  Positive: 28
    Test  Negative: 56
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 165 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 87% – Elapsed: 0.0s
Progress: 97% – Elapsed: 0.0s
Done. Total time: 0.0s
Encoding 84 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 76% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.0s
Progress: 95% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       30.47% |       0.7505 |          0.1000 |
|      50 |          50 |       00:00:00 |       96.88% |       0.1059 |          0.0656 |
|     100 |         100 |       00:00:00 |       97.66% |       0.0694 |          0.0387 |
|     150 |         150 |       00:00:00 |       97.66% |       0.0685 |          0.0229 |
|     200 |         200 |       00:00:00 |       97.66% |       0.0683 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.90, Precision: 0.9000, Recall: 0.3214, F1-Score: 0.4737
AUC: 0.8744
Processing dataset: Chub lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 28 / 40 (70.0%)
[DivideNet] Attempts made: 80 | Failed attempts: 52
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 55
    Train Negative: 110
    Test  Positive: 28
    Test  Negative: 56
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 165 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.1s
Progress: 48% – Elapsed: 0.1s
Progress: 58% – Elapsed: 0.1s
Progress: 68% – Elapsed: 0.2s
Progress: 78% – Elapsed: 0.2s
Progress: 87% – Elapsed: 0.2s
Progress: 97% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 84 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.1s
Progress: 48% – Elapsed: 0.1s
Progress: 57% – Elapsed: 0.1s
Progress: 67% – Elapsed: 0.1s
Progress: 76% – Elapsed: 0.1s
Progress: 86% – Elapsed: 0.1s
Progress: 95% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       75.00% |       0.6693 |          0.1000 |
|      50 |          50 |       00:00:00 |       96.09% |       0.0966 |          0.0656 |
|     100 |         100 |       00:00:00 |       98.44% |       0.0630 |          0.0387 |
|     150 |         150 |       00:00:00 |       98.44% |       0.0519 |          0.0229 |
|     200 |         200 |       00:00:00 |       98.44% |       0.0500 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.90, Precision: 1.0000, Recall: 0.2500, F1-Score: 0.4000
AUC: 0.7902
Processing dataset: Chub lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 28 / 36 (77.8%)
[DivideNet] Attempts made: 80 | Failed attempts: 52
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 55
    Train Negative: 110
    Test  Positive: 28
    Test  Negative: 56
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 165 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 87% – Elapsed: 0.0s
Progress: 97% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 84 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 76% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.0s
Progress: 95% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       24.22% |       0.7057 |          0.1000 |
|      50 |          50 |       00:00:00 |       98.44% |       0.0654 |          0.0656 |
|     100 |         100 |       00:00:00 |       98.44% |       0.0559 |          0.0387 |
|     150 |         150 |       00:00:00 |       98.44% |       0.0557 |          0.0229 |
|     200 |         200 |       00:00:00 |       98.44% |       0.0556 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.6667, Recall: 0.1429, F1-Score: 0.2353
AUC: 0.8444
Processing dataset: Chub lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 28 / 32 (87.5%)
[DivideNet] Attempts made: 80 | Failed attempts: 52
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 55
    Train Negative: 110
    Test  Positive: 28
    Test  Negative: 56
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 165 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 87% – Elapsed: 0.0s
Progress: 97% – Elapsed: 0.0s
Done. Total time: 0.0s
Encoding 84 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 76% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.0s
Progress: 95% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       88.28% |       0.6677 |          0.1000 |
|      50 |          50 |       00:00:00 |       98.44% |       0.0581 |          0.0656 |
|     100 |         100 |       00:00:00 |       98.44% |       0.0518 |          0.0387 |
|     150 |         150 |       00:00:00 |       98.44% |       0.0515 |          0.0229 |
|     200 |         200 |       00:00:00 |       98.44% |       0.0514 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.8889, Recall: 0.2857, F1-Score: 0.4324
AUC: 0.7213
Processing dataset: Chub lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 28 / 28 (100.0%)
[DivideNet] Attempts made: 80 | Failed attempts: 52
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 55
    Train Negative: 110
    Test  Positive: 28
    Test  Negative: 56
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 165 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 87% – Elapsed: 0.0s
Progress: 97% – Elapsed: 0.0s
Done. Total time: 0.0s
Encoding 84 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 76% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.0s
Progress: 95% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       10.94% |       0.7423 |          0.1000 |
|      50 |          50 |       00:00:00 |       99.22% |       0.0467 |          0.0656 |
|     100 |         100 |       00:00:00 |       99.22% |       0.0338 |          0.0387 |
|     150 |         150 |       00:00:00 |       99.22% |       0.0335 |          0.0229 |
|     200 |         200 |       00:00:00 |       99.22% |       0.0334 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.3214, F1-Score: 0.4865
AUC: 0.7889
Processing dataset: Chub lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 25 / 25 (100.0%)
[DivideNet] Attempts made: 65 | Failed attempts: 40
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 58
    Train Negative: 116
    Test  Positive: 25
    Test  Negative: 50
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 174 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 59% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.1s
Progress: 78% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 75 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 37% – Elapsed: 0.0s
Progress: 47% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 65% – Elapsed: 0.0s
Progress: 75% – Elapsed: 0.0s
Progress: 84% – Elapsed: 0.0s
Progress: 93% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       67.97% |       0.6987 |          0.1000 |
|      50 |          50 |       00:00:00 |       96.09% |       0.0954 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0045 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0014 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0010 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9500, Recall: 0.7600, F1-Score: 0.8444
AUC: 0.9608
Processing dataset: Chub lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 20 / 20 (100.0%)
[DivideNet] Attempts made: 43 | Failed attempts: 23
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 63
    Train Negative: 126
    Test  Positive: 20
    Test  Negative: 40
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 189 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.1s
Progress: 67% – Elapsed: 0.1s
Progress: 76% – Elapsed: 0.1s
Progress: 86% – Elapsed: 0.1s
Progress: 95% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 60 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.0s
Progress: 70% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.0s
Progress: 90% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       28.91% |       0.7165 |          0.1000 |
|      50 |          50 |       00:00:00 |       91.41% |       0.1362 |          0.0656 |
|     100 |         100 |       00:00:00 |       97.66% |       0.0729 |          0.0387 |
|     150 |         150 |       00:00:00 |       97.66% |       0.0667 |          0.0229 |
|     200 |         200 |       00:00:00 |       97.66% |       0.0651 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000
AUC: 1.0000
Processing dataset: Chub lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 16 / 16 (100.0%)
[DivideNet] Attempts made: 36 | Failed attempts: 20
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 67
    Train Negative: 134
    Test  Positive: 16
    Test  Negative: 32
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 201 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.1s
Progress: 100% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 25% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 42% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 75% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 92% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       35.94% |       0.8261 |          0.1000 |
|      50 |          50 |       00:00:00 |       92.19% |       0.1859 |          0.0656 |
|     100 |         100 |       00:00:00 |       96.09% |       0.1031 |          0.0387 |
|     150 |         150 |       00:00:00 |       96.09% |       0.0883 |          0.0229 |
|     200 |         200 |       00:00:00 |       96.09% |       0.0842 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000
AUC: 1.0000
Processing dataset: Chub lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 13 / 13 (100.0%)
[DivideNet] Attempts made: 30 | Failed attempts: 17
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 70
    Train Negative: 140
    Test  Positive: 13
    Test  Negative: 26
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 210 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.1s
Progress: 100% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 39 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Progress: 15% – Elapsed: 0.0s
Progress: 23% – Elapsed: 0.0s
Progress: 31% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 46% – Elapsed: 0.0s
Progress: 54% – Elapsed: 0.0s
Progress: 62% – Elapsed: 0.0s
Progress: 69% – Elapsed: 0.0s
Progress: 77% – Elapsed: 0.0s
Progress: 85% – Elapsed: 0.0s
Progress: 92% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       88.28% |       0.6279 |          0.1000 |
|      50 |          50 |       00:00:00 |       92.19% |       0.1320 |          0.0656 |
|     100 |         100 |       00:00:00 |       97.66% |       0.0780 |          0.0387 |
|     150 |         150 |       00:00:00 |       97.66% |       0.0677 |          0.0229 |
|     200 |         200 |       00:00:00 |       97.66% |       0.0645 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.9231, F1-Score: 0.9600
AUC: 1.0000
Processing dataset: Chub lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 8 / 8 (100.0%)
[DivideNet] Attempts made: 16 | Failed attempts: 8
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 75
    Train Negative: 150
    Test  Positive: 8
    Test  Negative: 16
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 225 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 59% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 24 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 25% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 42% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 75% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 92% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       71.88% |       0.6726 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0577 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0031 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0016 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0012 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000
AUC: 1.0000
Processing dataset: Chub lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 28 / 72 (38.9%)
[DivideNet] Attempts made: 80 | Failed attempts: 52
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 55
    Train Negative: 110
    Test  Positive: 28
    Test  Negative: 56
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 165 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 87% – Elapsed: 0.1s
Progress: 97% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 84 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 76% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.0s
Progress: 95% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       14.84% |       0.7271 |          0.1000 |
|      50 |          50 |       00:00:00 |       94.53% |       0.1087 |          0.0656 |
|     100 |         100 |       00:00:00 |       99.22% |       0.0312 |          0.0387 |
|     150 |         150 |       00:00:00 |       99.22% |       0.0304 |          0.0229 |
|     200 |         200 |       00:00:00 |       99.22% |       0.0302 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.00, Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000
AUC: 0.7991
Processing dataset: Chub lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 28 / 68 (41.2%)
[DivideNet] Attempts made: 80 | Failed attempts: 52
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 55
    Train Negative: 110
    Test  Positive: 28
    Test  Negative: 56
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 165 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.1s
Progress: 87% – Elapsed: 0.1s
Progress: 97% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 84 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 76% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.0s
Progress: 95% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       17.97% |       0.7372 |          0.1000 |
|      50 |          50 |       00:00:00 |       96.09% |       0.0998 |          0.0656 |
|     100 |         100 |       00:00:00 |       99.22% |       0.0349 |          0.0387 |
|     150 |         150 |       00:00:00 |       99.22% |       0.0327 |          0.0229 |
|     200 |         200 |       00:00:00 |       99.22% |       0.0323 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.8400, Recall: 0.7500, F1-Score: 0.7925
AUC: 0.8673
Processing dataset: Chub lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 28 / 64 (43.8%)
[DivideNet] Attempts made: 80 | Failed attempts: 52
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 55
    Train Negative: 110
    Test  Positive: 28
    Test  Negative: 56
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 165 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 87% – Elapsed: 0.1s
Progress: 97% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 84 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 76% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.0s
Progress: 95% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       63.28% |       0.7092 |          0.1000 |
|      50 |          50 |       00:00:00 |       99.22% |       0.0292 |          0.0656 |
|     100 |         100 |       00:00:00 |       99.22% |       0.0279 |          0.0387 |
|     150 |         150 |       00:00:00 |       99.22% |       0.0279 |          0.0229 |
|     200 |         200 |       00:00:00 |       99.22% |       0.0278 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.5000, Recall: 0.0357, F1-Score: 0.0667
AUC: 0.6735
Processing dataset: Chub lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 28 / 60 (46.7%)
[DivideNet] Attempts made: 80 | Failed attempts: 52
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 55
    Train Negative: 110
    Test  Positive: 28
    Test  Negative: 56
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 165 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 87% – Elapsed: 0.1s
Progress: 97% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 84 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 76% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.0s
Progress: 95% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       34.38% |       0.7098 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0648 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0012 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0007 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0006 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.00, Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000
AUC: 0.7985
Processing dataset: Chub lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 28 / 56 (50.0%)
[DivideNet] Attempts made: 80 | Failed attempts: 52
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 55
    Train Negative: 110
    Test  Positive: 28
    Test  Negative: 56
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 165 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 87% – Elapsed: 0.0s
Progress: 97% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 84 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 76% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.0s
Progress: 95% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       66.41% |       0.6311 |          0.1000 |
|      50 |          50 |       00:00:00 |       98.44% |       0.0787 |          0.0656 |
|     100 |         100 |       00:00:00 |       98.44% |       0.0484 |          0.0387 |
|     150 |         150 |       00:00:00 |       98.44% |       0.0479 |          0.0229 |
|     200 |         200 |       00:00:00 |       98.44% |       0.0478 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.90, Precision: 1.0000, Recall: 0.2500, F1-Score: 0.4000
AUC: 0.7449
