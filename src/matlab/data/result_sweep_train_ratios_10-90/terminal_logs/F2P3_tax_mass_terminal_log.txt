Processing dataset: F2P3_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 73 / 169 (43.2%)
[DivideNet] Attempts made: 259 | Failed attempts: 186
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 193
    Train Negative: 386
    Test  Positive: 73
    Test  Negative: 146
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 579 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.1s
Done. Total time: 0.2s
Encoding 219 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 77% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.0s
Progress: 96% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       48.44% |       0.7044 |          0.1000 |
|      13 |          50 |       00:00:00 |       87.50% |       0.3023 |          0.0900 |
|      25 |         100 |       00:00:00 |       91.41% |       0.2368 |          0.0810 |
|      38 |         150 |       00:00:00 |       89.84% |       0.2536 |          0.0729 |
|      50 |         200 |       00:00:00 |       92.19% |       0.2139 |          0.0656 |
|      63 |         250 |       00:00:00 |       89.84% |       0.2397 |          0.0531 |
|      75 |         300 |       00:00:00 |       92.19% |       0.2070 |          0.0478 |
|      88 |         350 |       00:00:00 |       90.62% |       0.2339 |          0.0430 |
|     100 |         400 |       00:00:00 |       92.19% |       0.2125 |          0.0387 |
|     113 |         450 |       00:00:00 |       90.62% |       0.2328 |          0.0314 |
|     125 |         500 |       00:00:00 |       92.19% |       0.2022 |          0.0282 |
|     138 |         550 |       00:00:00 |       90.62% |       0.2325 |          0.0254 |
|     150 |         600 |       00:00:00 |       92.19% |       0.2008 |          0.0229 |
|     163 |         650 |       00:00:00 |       90.62% |       0.2320 |          0.0185 |
|     175 |         700 |       00:00:00 |       92.19% |       0.2000 |          0.0167 |
|     188 |         750 |       00:00:00 |       90.62% |       0.2317 |          0.0150 |
|     200 |         800 |       00:00:00 |       92.19% |       0.1995 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.15, Precision: 0.7538, Recall: 0.6712, F1-Score: 0.7101
AUC: 0.9229
Processing dataset: F2P3_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 72 / 156 (46.2%)
[DivideNet] Attempts made: 259 | Failed attempts: 187
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 194
    Train Negative: 388
    Test  Positive: 72
    Test  Negative: 144
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 582 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.1s
Progress: 100% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 216 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 88% – Elapsed: 0.0s
Progress: 97% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       25.00% |       0.9350 |          0.1000 |
|      13 |          50 |       00:00:00 |       84.38% |       0.3917 |          0.0900 |
|      25 |         100 |       00:00:00 |       89.06% |       0.2199 |          0.0810 |
|      38 |         150 |       00:00:00 |       86.72% |       0.2876 |          0.0729 |
|      50 |         200 |       00:00:00 |       91.41% |       0.2022 |          0.0656 |
|      63 |         250 |       00:00:00 |       86.72% |       0.2756 |          0.0531 |
|      75 |         300 |       00:00:00 |       91.41% |       0.1993 |          0.0478 |
|      88 |         350 |       00:00:00 |       87.50% |       0.2697 |          0.0430 |
|     100 |         400 |       00:00:00 |       91.41% |       0.1987 |          0.0387 |
|     113 |         450 |       00:00:00 |       88.28% |       0.2633 |          0.0314 |
|     125 |         500 |       00:00:00 |       91.41% |       0.1964 |          0.0282 |
|     138 |         550 |       00:00:00 |       88.28% |       0.2607 |          0.0254 |
|     150 |         600 |       00:00:00 |       91.41% |       0.1960 |          0.0229 |
|     163 |         650 |       00:00:00 |       88.28% |       0.2595 |          0.0185 |
|     175 |         700 |       00:00:00 |       91.41% |       0.1958 |          0.0167 |
|     188 |         750 |       00:00:00 |       88.28% |       0.2588 |          0.0150 |
|     200 |         800 |       00:00:00 |       91.41% |       0.1955 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.6667, Recall: 0.5278, F1-Score: 0.5891
AUC: 0.8214
Processing dataset: F2P3_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 72 / 143 (50.3%)
[DivideNet] Attempts made: 259 | Failed attempts: 187
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 194
    Train Negative: 388
    Test  Positive: 72
    Test  Negative: 144
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 582 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.1s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 216 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 88% – Elapsed: 0.0s
Progress: 97% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       31.25% |       0.8930 |          0.1000 |
|      13 |          50 |       00:00:00 |       87.50% |       0.3432 |          0.0900 |
|      25 |         100 |       00:00:00 |       89.06% |       0.2375 |          0.0810 |
|      38 |         150 |       00:00:00 |       90.62% |       0.2378 |          0.0729 |
|      50 |         200 |       00:00:00 |       89.06% |       0.2232 |          0.0656 |
|      63 |         250 |       00:00:00 |       91.41% |       0.2187 |          0.0531 |
|      75 |         300 |       00:00:00 |       89.06% |       0.2208 |          0.0478 |
|      88 |         350 |       00:00:00 |       91.41% |       0.2163 |          0.0430 |
|     100 |         400 |       00:00:00 |       89.06% |       0.2195 |          0.0387 |
|     113 |         450 |       00:00:00 |       91.41% |       0.2143 |          0.0314 |
|     125 |         500 |       00:00:00 |       89.06% |       0.2191 |          0.0282 |
|     138 |         550 |       00:00:00 |       91.41% |       0.2131 |          0.0254 |
|     150 |         600 |       00:00:00 |       89.06% |       0.2184 |          0.0229 |
|     163 |         650 |       00:00:00 |       91.41% |       0.2120 |          0.0185 |
|     175 |         700 |       00:00:00 |       89.06% |       0.2171 |          0.0167 |
|     188 |         750 |       00:00:00 |       91.41% |       0.2124 |          0.0150 |
|     200 |         800 |       00:00:00 |       89.06% |       0.2159 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.6914, Recall: 0.7778, F1-Score: 0.7320
AUC: 0.8884
Processing dataset: F2P3_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 72 / 130 (55.4%)
[DivideNet] Attempts made: 259 | Failed attempts: 187
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 194
    Train Negative: 388
    Test  Positive: 72
    Test  Negative: 144
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 582 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 216 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 88% – Elapsed: 0.1s
Progress: 97% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       67.97% |       0.6341 |          0.1000 |
|      13 |          50 |       00:00:00 |       91.41% |       0.2394 |          0.0900 |
|      25 |         100 |       00:00:00 |       89.06% |       0.2247 |          0.0810 |
|      38 |         150 |       00:00:00 |       91.41% |       0.2083 |          0.0729 |
|      50 |         200 |       00:00:00 |       89.06% |       0.2179 |          0.0656 |
|      63 |         250 |       00:00:00 |       91.41% |       0.2069 |          0.0531 |
|      75 |         300 |       00:00:00 |       89.06% |       0.2161 |          0.0478 |
|      88 |         350 |       00:00:00 |       91.41% |       0.2066 |          0.0430 |
|     100 |         400 |       00:00:00 |       89.06% |       0.2157 |          0.0387 |
|     113 |         450 |       00:00:00 |       91.41% |       0.2064 |          0.0314 |
|     125 |         500 |       00:00:00 |       89.06% |       0.2153 |          0.0282 |
|     138 |         550 |       00:00:00 |       91.41% |       0.2062 |          0.0254 |
|     150 |         600 |       00:00:00 |       89.06% |       0.2153 |          0.0229 |
|     163 |         650 |       00:00:00 |       91.41% |       0.2063 |          0.0185 |
|     175 |         700 |       00:00:00 |       89.06% |       0.2149 |          0.0167 |
|     188 |         750 |       00:00:01 |       91.41% |       0.2061 |          0.0150 |
|     200 |         800 |       00:00:01 |       89.06% |       0.2147 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.75, Precision: 1.0000, Recall: 0.5694, F1-Score: 0.7257
AUC: 0.9213
Processing dataset: F2P3_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 73 / 117 (62.4%)
[DivideNet] Attempts made: 259 | Failed attempts: 186
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 193
    Train Negative: 386
    Test  Positive: 73
    Test  Negative: 146
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 579 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.2s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 219 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 77% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.1s
Progress: 96% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       53.12% |       0.6792 |          0.1000 |
|      13 |          50 |       00:00:00 |       89.06% |       0.2920 |          0.0900 |
|      25 |         100 |       00:00:00 |       91.41% |       0.2181 |          0.0810 |
|      38 |         150 |       00:00:00 |       89.84% |       0.2196 |          0.0729 |
|      50 |         200 |       00:00:00 |       91.41% |       0.2134 |          0.0656 |
|      63 |         250 |       00:00:00 |       89.84% |       0.2137 |          0.0531 |
|      75 |         300 |       00:00:00 |       91.41% |       0.2123 |          0.0478 |
|      88 |         350 |       00:00:00 |       89.84% |       0.2124 |          0.0430 |
|     100 |         400 |       00:00:00 |       91.41% |       0.2120 |          0.0387 |
|     113 |         450 |       00:00:00 |       89.84% |       0.2115 |          0.0314 |
|     125 |         500 |       00:00:00 |       91.41% |       0.2111 |          0.0282 |
|     138 |         550 |       00:00:00 |       89.84% |       0.2113 |          0.0254 |
|     150 |         600 |       00:00:00 |       91.41% |       0.2110 |          0.0229 |
|     163 |         650 |       00:00:00 |       89.84% |       0.2111 |          0.0185 |
|     175 |         700 |       00:00:01 |       91.41% |       0.2105 |          0.0167 |
|     188 |         750 |       00:00:01 |       89.84% |       0.2110 |          0.0150 |
|     200 |         800 |       00:00:01 |       91.41% |       0.2106 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.15, Precision: 0.7976, Recall: 0.9178, F1-Score: 0.8535
AUC: 0.9449
Processing dataset: F2P3_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 73 / 104 (70.2%)
[DivideNet] Attempts made: 259 | Failed attempts: 186
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 193
    Train Negative: 386
    Test  Positive: 73
    Test  Negative: 146
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 579 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.2s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 219 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 77% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.0s
Progress: 96% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       75.78% |       0.6561 |          0.1000 |
|      13 |          50 |       00:00:00 |       88.28% |       0.2696 |          0.0900 |
|      25 |         100 |       00:00:00 |       89.84% |       0.2377 |          0.0810 |
|      38 |         150 |       00:00:00 |       89.84% |       0.2115 |          0.0729 |
|      50 |         200 |       00:00:00 |       89.84% |       0.2331 |          0.0656 |
|      63 |         250 |       00:00:00 |       89.84% |       0.2074 |          0.0531 |
|      75 |         300 |       00:00:00 |       89.84% |       0.2316 |          0.0478 |
|      88 |         350 |       00:00:00 |       90.62% |       0.2027 |          0.0430 |
|     100 |         400 |       00:00:00 |       89.84% |       0.2312 |          0.0387 |
|     113 |         450 |       00:00:00 |       90.62% |       0.2006 |          0.0314 |
|     125 |         500 |       00:00:00 |       89.84% |       0.2301 |          0.0282 |
|     138 |         550 |       00:00:00 |       90.62% |       0.2002 |          0.0254 |
|     150 |         600 |       00:00:00 |       89.84% |       0.2299 |          0.0229 |
|     163 |         650 |       00:00:00 |       90.62% |       0.1999 |          0.0185 |
|     175 |         700 |       00:00:00 |       89.84% |       0.2297 |          0.0167 |
|     188 |         750 |       00:00:00 |       90.62% |       0.1998 |          0.0150 |
|     200 |         800 |       00:00:00 |       89.84% |       0.2296 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.15, Precision: 0.7206, Recall: 0.6712, F1-Score: 0.6950
AUC: 0.9135
Processing dataset: F2P3_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 72 / 91 (79.1%)
[DivideNet] Attempts made: 259 | Failed attempts: 187
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 194
    Train Negative: 388
    Test  Positive: 72
    Test  Negative: 144
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 582 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 216 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 88% – Elapsed: 0.1s
Progress: 97% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       43.75% |       0.7122 |          0.1000 |
|      13 |          50 |       00:00:00 |       90.62% |       0.2395 |          0.0900 |
|      25 |         100 |       00:00:00 |       91.41% |       0.2106 |          0.0810 |
|      38 |         150 |       00:00:00 |       92.19% |       0.1949 |          0.0729 |
|      50 |         200 |       00:00:00 |       91.41% |       0.1992 |          0.0656 |
|      63 |         250 |       00:00:00 |       92.97% |       0.1866 |          0.0531 |
|      75 |         300 |       00:00:00 |       91.41% |       0.1971 |          0.0478 |
|      88 |         350 |       00:00:00 |       92.97% |       0.1829 |          0.0430 |
|     100 |         400 |       00:00:00 |       91.41% |       0.1962 |          0.0387 |
|     113 |         450 |       00:00:00 |       92.97% |       0.1812 |          0.0314 |
|     125 |         500 |       00:00:01 |       91.41% |       0.1953 |          0.0282 |
|     138 |         550 |       00:00:01 |       92.97% |       0.1806 |          0.0254 |
|     150 |         600 |       00:00:01 |       91.41% |       0.1950 |          0.0229 |
|     163 |         650 |       00:00:01 |       92.97% |       0.1800 |          0.0185 |
|     175 |         700 |       00:00:01 |       91.41% |       0.1944 |          0.0167 |
|     188 |         750 |       00:00:01 |       92.97% |       0.1798 |          0.0150 |
|     200 |         800 |       00:00:01 |       91.41% |       0.1942 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.6667, Recall: 0.6389, F1-Score: 0.6525
AUC: 0.8550
Processing dataset: F2P3_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 73 / 78 (93.6%)
[DivideNet] Attempts made: 259 | Failed attempts: 186
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 193
    Train Negative: 386
    Test  Positive: 73
    Test  Negative: 146
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 579 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.2s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 219 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 77% – Elapsed: 0.1s
Progress: 86% – Elapsed: 0.1s
Progress: 96% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       52.34% |       0.6824 |          0.1000 |
|      13 |          50 |       00:00:00 |       72.66% |       0.3435 |          0.0900 |
|      25 |         100 |       00:00:00 |       90.62% |       0.2366 |          0.0810 |
|      38 |         150 |       00:00:00 |       92.19% |       0.2026 |          0.0729 |
|      50 |         200 |       00:00:00 |       90.62% |       0.2160 |          0.0656 |
|      63 |         250 |       00:00:00 |       92.19% |       0.2182 |          0.0531 |
|      75 |         300 |       00:00:00 |       91.41% |       0.2133 |          0.0478 |
|      88 |         350 |       00:00:00 |       92.19% |       0.1963 |          0.0430 |
|     100 |         400 |       00:00:00 |       91.41% |       0.2095 |          0.0387 |
|     113 |         450 |       00:00:00 |       92.19% |       0.1919 |          0.0314 |
|     125 |         500 |       00:00:00 |       91.41% |       0.2082 |          0.0282 |
|     138 |         550 |       00:00:00 |       92.19% |       0.1950 |          0.0254 |
|     150 |         600 |       00:00:00 |       91.41% |       0.2073 |          0.0229 |
|     163 |         650 |       00:00:00 |       92.19% |       0.1948 |          0.0185 |
|     175 |         700 |       00:00:01 |       91.41% |       0.2081 |          0.0167 |
|     188 |         750 |       00:00:01 |       92.19% |       0.1938 |          0.0150 |
|     200 |         800 |       00:00:01 |       91.41% |       0.2064 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.15, Precision: 0.6765, Recall: 0.6301, F1-Score: 0.6525
AUC: 0.8590
Processing dataset: F2P3_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 65 / 65 (100.0%)
[DivideNet] Attempts made: 223 | Failed attempts: 158
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 201
    Train Negative: 402
    Test  Positive: 65
    Test  Negative: 130
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 603 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.1s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 195 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 88% – Elapsed: 0.0s
Progress: 97% – Elapsed: 0.0s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       42.19% |       0.7276 |          0.1000 |
|      13 |          50 |       00:00:00 |       89.06% |       0.2940 |          0.0900 |
|      25 |         100 |       00:00:00 |       68.75% |       0.4399 |          0.0810 |
|      38 |         150 |       00:00:00 |       92.19% |       0.2131 |          0.0729 |
|      50 |         200 |       00:00:00 |       89.06% |       0.2436 |          0.0656 |
|      63 |         250 |       00:00:00 |       92.19% |       0.1999 |          0.0531 |
|      75 |         300 |       00:00:00 |       90.62% |       0.2095 |          0.0478 |
|      88 |         350 |       00:00:00 |       92.19% |       0.1971 |          0.0430 |
|     100 |         400 |       00:00:00 |       90.62% |       0.2061 |          0.0387 |
|     113 |         450 |       00:00:00 |       92.19% |       0.1963 |          0.0314 |
|     125 |         500 |       00:00:00 |       90.62% |       0.2055 |          0.0282 |
|     138 |         550 |       00:00:00 |       92.19% |       0.1958 |          0.0254 |
|     150 |         600 |       00:00:00 |       90.62% |       0.2055 |          0.0229 |
|     163 |         650 |       00:00:00 |       92.19% |       0.1953 |          0.0185 |
|     175 |         700 |       00:00:00 |       90.62% |       0.2055 |          0.0167 |
|     188 |         750 |       00:00:01 |       92.19% |       0.1953 |          0.0150 |
|     200 |         800 |       00:00:01 |       90.62% |       0.2048 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.15, Precision: 0.7160, Recall: 0.8923, F1-Score: 0.7945
AUC: 0.8633
Processing dataset: F2P3_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 52 / 52 (100.0%)
[DivideNet] Attempts made: 164 | Failed attempts: 112
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 214
    Train Negative: 428
    Test  Positive: 52
    Test  Negative: 104
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 642 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 156 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 77% – Elapsed: 0.0s
Progress: 87% – Elapsed: 0.0s
Progress: 96% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       65.62% |       0.6668 |          0.1000 |
|      10 |          50 |       00:00:00 |       89.06% |       0.2668 |          0.1000 |
|      20 |         100 |       00:00:00 |       63.28% |       0.5498 |          0.0900 |
|      30 |         150 |       00:00:00 |       67.19% |       0.5036 |          0.0810 |
|      40 |         200 |       00:00:00 |       69.53% |       0.4643 |          0.0729 |
|      50 |         250 |       00:00:00 |       70.31% |       0.4551 |          0.0656 |
|      60 |         300 |       00:00:00 |       70.31% |       0.4513 |          0.0590 |
|      70 |         350 |       00:00:00 |       70.31% |       0.4504 |          0.0531 |
|      80 |         400 |       00:00:00 |       70.31% |       0.4490 |          0.0478 |
|      90 |         450 |       00:00:00 |       72.66% |       0.4364 |          0.0430 |
|     100 |         500 |       00:00:00 |       70.31% |       0.4530 |          0.0387 |
|     110 |         550 |       00:00:00 |       72.66% |       0.4337 |          0.0349 |
|     120 |         600 |       00:00:00 |       69.53% |       0.4519 |          0.0314 |
|     130 |         650 |       00:00:00 |       70.31% |       0.4464 |          0.0282 |
|     140 |         700 |       00:00:01 |       70.31% |       0.4457 |          0.0254 |
|     150 |         750 |       00:00:01 |       70.31% |       0.4451 |          0.0229 |
|     160 |         800 |       00:00:01 |       70.31% |       0.4449 |          0.0206 |
|     170 |         850 |       00:00:01 |       70.31% |       0.4448 |          0.0185 |
|     180 |         900 |       00:00:01 |       70.31% |       0.4446 |          0.0167 |
|     190 |         950 |       00:00:01 |       70.31% |       0.4444 |          0.0150 |
|     200 |        1000 |       00:00:01 |       70.31% |       0.4443 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.15, Precision: 0.5051, Recall: 0.9615, F1-Score: 0.6623
AUC: 0.8197
Processing dataset: F2P3_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 39 / 39 (100.0%)
[DivideNet] Attempts made: 104 | Failed attempts: 65
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 227
    Train Negative: 454
    Test  Positive: 39
    Test  Negative: 78
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 681 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.1s
Progress: 80% – Elapsed: 0.1s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 117 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 47% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 66% – Elapsed: 0.0s
Progress: 75% – Elapsed: 0.0s
Progress: 85% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       66.41% |       0.6423 |          0.1000 |
|      10 |          50 |       00:00:00 |       86.72% |       0.2680 |          0.1000 |
|      20 |         100 |       00:00:00 |       86.72% |       0.2481 |          0.0900 |
|      30 |         150 |       00:00:00 |       86.72% |       0.2340 |          0.0810 |
|      40 |         200 |       00:00:00 |       86.72% |       0.2454 |          0.0729 |
|      50 |         250 |       00:00:00 |       86.72% |       0.2248 |          0.0656 |
|      60 |         300 |       00:00:00 |       87.50% |       0.2315 |          0.0590 |
|      70 |         350 |       00:00:00 |       87.50% |       0.2202 |          0.0531 |
|      80 |         400 |       00:00:00 |       86.72% |       0.2222 |          0.0478 |
|      90 |         450 |       00:00:00 |       89.06% |       0.2167 |          0.0430 |
|     100 |         500 |       00:00:00 |       89.84% |       0.2142 |          0.0387 |
|     110 |         550 |       00:00:00 |       89.84% |       0.2117 |          0.0349 |
|     120 |         600 |       00:00:00 |       89.84% |       0.2095 |          0.0314 |
|     130 |         650 |       00:00:00 |       89.84% |       0.2075 |          0.0282 |
|     140 |         700 |       00:00:00 |       89.84% |       0.2065 |          0.0254 |
|     150 |         750 |       00:00:00 |       89.84% |       0.2056 |          0.0229 |
|     160 |         800 |       00:00:00 |       89.84% |       0.2042 |          0.0206 |
|     170 |         850 |       00:00:01 |       89.84% |       0.2039 |          0.0185 |
|     180 |         900 |       00:00:01 |       89.84% |       0.2038 |          0.0167 |
|     190 |         950 |       00:00:01 |       89.84% |       0.2020 |          0.0150 |
|     200 |        1000 |       00:00:01 |       89.84% |       0.2025 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.20, Precision: 0.8444, Recall: 0.9744, F1-Score: 0.9048
AUC: 0.9786
Processing dataset: F2P3_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 26 / 26 (100.0%)
[DivideNet] Attempts made: 85 | Failed attempts: 59
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 240
    Train Negative: 480
    Test  Positive: 26
    Test  Negative: 52
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 720 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 78 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Progress: 18% – Elapsed: 0.0s
Progress: 27% – Elapsed: 0.0s
Progress: 36% – Elapsed: 0.0s
Progress: 45% – Elapsed: 0.0s
Progress: 54% – Elapsed: 0.0s
Progress: 63% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 81% – Elapsed: 0.0s
Progress: 90% – Elapsed: 0.0s
Progress: 99% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       37.50% |       0.8052 |          0.1000 |
|      10 |          50 |       00:00:00 |       87.50% |       0.2789 |          0.1000 |
|      20 |         100 |       00:00:00 |       87.50% |       0.2553 |          0.0900 |
|      30 |         150 |       00:00:00 |       89.06% |       0.2430 |          0.0810 |
|      40 |         200 |       00:00:00 |       90.62% |       0.2355 |          0.0729 |
|      50 |         250 |       00:00:00 |       89.84% |       0.2271 |          0.0656 |
|      60 |         300 |       00:00:00 |       89.84% |       0.2213 |          0.0590 |
|      70 |         350 |       00:00:00 |       90.62% |       0.2156 |          0.0531 |
|      80 |         400 |       00:00:00 |       90.62% |       0.2130 |          0.0478 |
|      90 |         450 |       00:00:00 |       90.62% |       0.2106 |          0.0430 |
|     100 |         500 |       00:00:00 |       91.41% |       0.2080 |          0.0387 |
|     110 |         550 |       00:00:00 |       91.41% |       0.2061 |          0.0349 |
|     120 |         600 |       00:00:00 |       91.41% |       0.2054 |          0.0314 |
|     130 |         650 |       00:00:00 |       90.62% |       0.2052 |          0.0282 |
|     140 |         700 |       00:00:01 |       90.62% |       0.2042 |          0.0254 |
|     150 |         750 |       00:00:01 |       90.62% |       0.2031 |          0.0229 |
|     160 |         800 |       00:00:01 |       92.19% |       0.2024 |          0.0206 |
|     170 |         850 |       00:00:01 |       92.19% |       0.2021 |          0.0185 |
|     180 |         900 |       00:00:01 |       92.19% |       0.2013 |          0.0167 |
|     190 |         950 |       00:00:01 |       91.41% |       0.2011 |          0.0150 |
|     200 |        1000 |       00:00:01 |       92.19% |       0.2007 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.55, Precision: 0.7647, Recall: 1.0000, F1-Score: 0.8667
AUC: 0.9527
Processing dataset: F2P3_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 73 / 234 (31.2%)
[DivideNet] Attempts made: 259 | Failed attempts: 186
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 193
    Train Negative: 386
    Test  Positive: 73
    Test  Negative: 146
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 579 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.2s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 219 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 77% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.1s
Progress: 96% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       14.06% |       0.7234 |          0.1000 |
|      13 |          50 |       00:00:00 |       87.50% |       0.3222 |          0.0900 |
|      25 |         100 |       00:00:00 |       93.75% |       0.1745 |          0.0810 |
|      38 |         150 |       00:00:00 |       88.28% |       0.2502 |          0.0729 |
|      50 |         200 |       00:00:00 |       93.75% |       0.1632 |          0.0656 |
|      63 |         250 |       00:00:00 |       88.28% |       0.2413 |          0.0531 |
|      75 |         300 |       00:00:00 |       93.75% |       0.1615 |          0.0478 |
|      88 |         350 |       00:00:00 |       89.06% |       0.2383 |          0.0430 |
|     100 |         400 |       00:00:00 |       93.75% |       0.1609 |          0.0387 |
|     113 |         450 |       00:00:00 |       89.06% |       0.2375 |          0.0314 |
|     125 |         500 |       00:00:00 |       93.75% |       0.1603 |          0.0282 |
|     138 |         550 |       00:00:00 |       89.06% |       0.2366 |          0.0254 |
|     150 |         600 |       00:00:00 |       93.75% |       0.1602 |          0.0229 |
|     163 |         650 |       00:00:00 |       89.06% |       0.2362 |          0.0185 |
|     175 |         700 |       00:00:00 |       93.75% |       0.1601 |          0.0167 |
|     188 |         750 |       00:00:01 |       89.06% |       0.2361 |          0.0150 |
|     200 |         800 |       00:00:01 |       93.75% |       0.1596 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.80, Precision: 1.0000, Recall: 0.8082, F1-Score: 0.8939
AUC: 0.9569
Processing dataset: F2P3_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 72 / 221 (32.6%)
[DivideNet] Attempts made: 259 | Failed attempts: 187
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 194
    Train Negative: 388
    Test  Positive: 72
    Test  Negative: 144
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 582 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 216 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 97% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       60.16% |       0.6930 |          0.1000 |
|      13 |          50 |       00:00:00 |       85.16% |       0.3409 |          0.0900 |
|      25 |         100 |       00:00:00 |       88.28% |       0.2584 |          0.0810 |
|      38 |         150 |       00:00:00 |       89.06% |       0.2307 |          0.0729 |
|      50 |         200 |       00:00:00 |       88.28% |       0.2446 |          0.0656 |
|      63 |         250 |       00:00:00 |       89.06% |       0.2145 |          0.0531 |
|      75 |         300 |       00:00:00 |       88.28% |       0.2421 |          0.0478 |
|      88 |         350 |       00:00:00 |       89.84% |       0.2091 |          0.0430 |
|     100 |         400 |       00:00:00 |       88.28% |       0.2412 |          0.0387 |
|     113 |         450 |       00:00:00 |       89.84% |       0.2075 |          0.0314 |
|     125 |         500 |       00:00:00 |       88.28% |       0.2408 |          0.0282 |
|     138 |         550 |       00:00:00 |       89.84% |       0.2067 |          0.0254 |
|     150 |         600 |       00:00:00 |       88.28% |       0.2406 |          0.0229 |
|     163 |         650 |       00:00:00 |       89.84% |       0.2062 |          0.0185 |
|     175 |         700 |       00:00:01 |       88.28% |       0.2403 |          0.0167 |
|     188 |         750 |       00:00:01 |       89.84% |       0.2059 |          0.0150 |
|     200 |         800 |       00:00:01 |       88.28% |       0.2403 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.75, Precision: 0.9259, Recall: 0.3472, F1-Score: 0.5051
AUC: 0.7971
Processing dataset: F2P3_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 72 / 208 (34.6%)
[DivideNet] Attempts made: 259 | Failed attempts: 187
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 194
    Train Negative: 388
    Test  Positive: 72
    Test  Negative: 144
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 582 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.2s
Progress: 60% – Elapsed: 0.2s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.3s
Progress: 100% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 216 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.1s
Progress: 68% – Elapsed: 0.1s
Progress: 78% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 97% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       63.28% |       0.6493 |          0.1000 |
|      13 |          50 |       00:00:00 |       91.41% |       0.2564 |          0.0900 |
|      25 |         100 |       00:00:00 |       89.84% |       0.2548 |          0.0810 |
|      38 |         150 |       00:00:00 |       92.19% |       0.2063 |          0.0729 |
|      50 |         200 |       00:00:00 |       89.84% |       0.2398 |          0.0656 |
|      63 |         250 |       00:00:00 |       92.19% |       0.2016 |          0.0531 |
|      75 |         300 |       00:00:00 |       90.62% |       0.2351 |          0.0478 |
|      88 |         350 |       00:00:00 |       92.19% |       0.1997 |          0.0430 |
|     100 |         400 |       00:00:00 |       90.62% |       0.2338 |          0.0387 |
|     113 |         450 |       00:00:00 |       92.19% |       0.1991 |          0.0314 |
|     125 |         500 |       00:00:00 |       90.62% |       0.2319 |          0.0282 |
|     138 |         550 |       00:00:00 |       92.19% |       0.1988 |          0.0254 |
|     150 |         600 |       00:00:01 |       90.62% |       0.2314 |          0.0229 |
|     163 |         650 |       00:00:01 |       92.19% |       0.1988 |          0.0185 |
|     175 |         700 |       00:00:01 |       90.62% |       0.2311 |          0.0167 |
|     188 |         750 |       00:00:01 |       92.19% |       0.1984 |          0.0150 |
|     200 |         800 |       00:00:01 |       90.62% |       0.2309 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.15, Precision: 0.6333, Recall: 0.5278, F1-Score: 0.5758
AUC: 0.8611
Processing dataset: F2P3_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 73 / 195 (37.4%)
[DivideNet] Attempts made: 259 | Failed attempts: 186
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 193
    Train Negative: 386
    Test  Positive: 73
    Test  Negative: 146
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 579 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.2s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 219 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 77% – Elapsed: 0.1s
Progress: 86% – Elapsed: 0.1s
Progress: 96% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       37.50% |       0.6996 |          0.1000 |
|      13 |          50 |       00:00:00 |       89.06% |       0.2670 |          0.0900 |
|      25 |         100 |       00:00:00 |       89.84% |       0.2148 |          0.0810 |
|      38 |         150 |       00:00:00 |       91.41% |       0.2001 |          0.0729 |
|      50 |         200 |       00:00:00 |       90.62% |       0.2032 |          0.0656 |
|      63 |         250 |       00:00:00 |       91.41% |       0.1940 |          0.0531 |
|      75 |         300 |       00:00:00 |       90.62% |       0.2009 |          0.0478 |
|      88 |         350 |       00:00:00 |       91.41% |       0.1925 |          0.0430 |
|     100 |         400 |       00:00:00 |       90.62% |       0.1997 |          0.0387 |
|     113 |         450 |       00:00:00 |       91.41% |       0.1921 |          0.0314 |
|     125 |         500 |       00:00:00 |       90.62% |       0.1991 |          0.0282 |
|     138 |         550 |       00:00:00 |       91.41% |       0.1919 |          0.0254 |
|     150 |         600 |       00:00:00 |       90.62% |       0.1987 |          0.0229 |
|     163 |         650 |       00:00:00 |       91.41% |       0.1917 |          0.0185 |
|     175 |         700 |       00:00:00 |       90.62% |       0.1985 |          0.0167 |
|     188 |         750 |       00:00:00 |       91.41% |       0.1916 |          0.0150 |
|     200 |         800 |       00:00:01 |       90.62% |       0.1984 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.7527, Recall: 0.9589, F1-Score: 0.8434
AUC: 0.9293
Processing dataset: F2P3_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 73 / 182 (40.1%)
[DivideNet] Attempts made: 259 | Failed attempts: 186
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 193
    Train Negative: 386
    Test  Positive: 73
    Test  Negative: 146
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 579 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 219 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 77% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.1s
Progress: 96% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       27.34% |       0.7651 |          0.1000 |
|      13 |          50 |       00:00:00 |       83.59% |       0.3346 |          0.0900 |
|      25 |         100 |       00:00:00 |       85.16% |       0.3528 |          0.0810 |
|      38 |         150 |       00:00:00 |       92.19% |       0.1957 |          0.0729 |
|      50 |         200 |       00:00:00 |       85.16% |       0.2949 |          0.0656 |
|      63 |         250 |       00:00:00 |       92.19% |       0.1896 |          0.0531 |
|      75 |         300 |       00:00:00 |       85.16% |       0.2873 |          0.0478 |
|      88 |         350 |       00:00:00 |       92.19% |       0.1879 |          0.0430 |
|     100 |         400 |       00:00:00 |       85.94% |       0.2891 |          0.0387 |
|     113 |         450 |       00:00:00 |       92.19% |       0.1858 |          0.0314 |
|     125 |         500 |       00:00:00 |       85.94% |       0.2761 |          0.0282 |
|     138 |         550 |       00:00:00 |       92.19% |       0.1844 |          0.0254 |
|     150 |         600 |       00:00:00 |       85.94% |       0.2761 |          0.0229 |
|     163 |         650 |       00:00:00 |       92.19% |       0.1842 |          0.0185 |
|     175 |         700 |       00:00:00 |       85.94% |       0.2755 |          0.0167 |
|     188 |         750 |       00:00:00 |       92.19% |       0.1841 |          0.0150 |
|     200 |         800 |       00:00:00 |       85.94% |       0.2748 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.15, Precision: 0.6944, Recall: 0.6849, F1-Score: 0.6897
AUC: 0.8867
