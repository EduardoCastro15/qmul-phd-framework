Processing dataset: F2P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 6 / 114 (5.3%)
[DivideNet] Attempts made: 174 | Failed attempts: 168
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 173
    Train Negative: 346
    Test  Positive: 6
    Test  Negative: 12
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 519 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 18 subgraphs (K = 10)...
Progress: 6% – Elapsed: 0.0s
Progress: 11% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 22% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 44% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 61% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       72.66% |       0.6531 |          0.1000 |
|      13 |          50 |       00:00:00 |       98.44% |       0.1088 |          0.0900 |
|      25 |         100 |       00:00:00 |       95.31% |       0.1383 |          0.0810 |
|      38 |         150 |       00:00:00 |       98.44% |       0.0803 |          0.0729 |
|      50 |         200 |       00:00:00 |       96.09% |       0.1298 |          0.0656 |
|      63 |         250 |       00:00:00 |       98.44% |       0.0764 |          0.0531 |
|      75 |         300 |       00:00:00 |       96.09% |       0.1332 |          0.0478 |
|      88 |         350 |       00:00:00 |       98.44% |       0.0771 |          0.0430 |
|     100 |         400 |       00:00:00 |       96.09% |       0.1283 |          0.0387 |
|     113 |         450 |       00:00:00 |       98.44% |       0.0769 |          0.0314 |
|     125 |         500 |       00:00:00 |       96.09% |       0.1279 |          0.0282 |
|     138 |         550 |       00:00:00 |       98.44% |       0.0771 |          0.0254 |
|     150 |         600 |       00:00:00 |       96.09% |       0.1279 |          0.0229 |
|     163 |         650 |       00:00:00 |       98.44% |       0.0762 |          0.0185 |
|     175 |         700 |       00:00:00 |       96.09% |       0.1279 |          0.0167 |
|     188 |         750 |       00:00:00 |       98.44% |       0.0759 |          0.0150 |
|     200 |         800 |       00:00:00 |       96.09% |       0.1279 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.6667, F1-Score: 0.8000
AUC: 0.9444
Processing dataset: F2P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 6 / 105 (5.7%)
[DivideNet] Attempts made: 174 | Failed attempts: 168
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 173
    Train Negative: 346
    Test  Positive: 6
    Test  Negative: 12
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 519 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.1s
Done. Total time: 0.2s
Encoding 18 subgraphs (K = 10)...
Progress: 6% – Elapsed: 0.0s
Progress: 11% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 22% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 44% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 61% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       71.09% |       0.6182 |          0.1000 |
|      13 |          50 |       00:00:00 |       97.66% |       0.1100 |          0.0900 |
|      25 |         100 |       00:00:00 |       97.66% |       0.0936 |          0.0810 |
|      38 |         150 |       00:00:00 |       97.66% |       0.0885 |          0.0729 |
|      50 |         200 |       00:00:00 |       97.66% |       0.0906 |          0.0656 |
|      63 |         250 |       00:00:00 |       97.66% |       0.0891 |          0.0531 |
|      75 |         300 |       00:00:00 |       97.66% |       0.0895 |          0.0478 |
|      88 |         350 |       00:00:00 |       97.66% |       0.0882 |          0.0430 |
|     100 |         400 |       00:00:00 |       97.66% |       0.0895 |          0.0387 |
|     113 |         450 |       00:00:00 |       97.66% |       0.0876 |          0.0314 |
|     125 |         500 |       00:00:00 |       97.66% |       0.0888 |          0.0282 |
|     138 |         550 |       00:00:00 |       97.66% |       0.0875 |          0.0254 |
|     150 |         600 |       00:00:00 |       97.66% |       0.0887 |          0.0229 |
|     163 |         650 |       00:00:00 |       97.66% |       0.0876 |          0.0185 |
|     175 |         700 |       00:00:00 |       97.66% |       0.0884 |          0.0167 |
|     188 |         750 |       00:00:00 |       97.66% |       0.0872 |          0.0150 |
|     200 |         800 |       00:00:00 |       97.66% |       0.0884 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.6667, F1-Score: 0.8000
AUC: 0.9167
Processing dataset: F2P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 6 / 96 (6.2%)
[DivideNet] Attempts made: 174 | Failed attempts: 168
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 173
    Train Negative: 346
    Test  Positive: 6
    Test  Negative: 12
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 519 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 18 subgraphs (K = 10)...
Progress: 6% – Elapsed: 0.0s
Progress: 11% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 22% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 44% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 61% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       30.47% |       0.7328 |          0.1000 |
|      13 |          50 |       00:00:00 |       96.09% |       0.1685 |          0.0900 |
|      25 |         100 |       00:00:00 |       97.66% |       0.1256 |          0.0810 |
|      38 |         150 |       00:00:00 |       96.88% |       0.1056 |          0.0729 |
|      50 |         200 |       00:00:00 |       97.66% |       0.0840 |          0.0656 |
|      63 |         250 |       00:00:00 |       96.88% |       0.1026 |          0.0531 |
|      75 |         300 |       00:00:00 |       97.66% |       0.0822 |          0.0478 |
|      88 |         350 |       00:00:00 |       96.88% |       0.1020 |          0.0430 |
|     100 |         400 |       00:00:00 |       97.66% |       0.0817 |          0.0387 |
|     113 |         450 |       00:00:00 |       96.88% |       0.1017 |          0.0314 |
|     125 |         500 |       00:00:00 |       97.66% |       0.0815 |          0.0282 |
|     138 |         550 |       00:00:00 |       96.88% |       0.1016 |          0.0254 |
|     150 |         600 |       00:00:00 |       97.66% |       0.0814 |          0.0229 |
|     163 |         650 |       00:00:00 |       96.88% |       0.1015 |          0.0185 |
|     175 |         700 |       00:00:00 |       97.66% |       0.0813 |          0.0167 |
|     188 |         750 |       00:00:00 |       96.88% |       0.1014 |          0.0150 |
|     200 |         800 |       00:00:00 |       97.66% |       0.0812 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.3333, F1-Score: 0.5000
AUC: 1.0000
Processing dataset: F2P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 6 / 87 (6.9%)
[DivideNet] Attempts made: 174 | Failed attempts: 168
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 173
    Train Negative: 346
    Test  Positive: 6
    Test  Negative: 12
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 519 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.2s
Progress: 88% – Elapsed: 0.2s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 18 subgraphs (K = 10)...
Progress: 6% – Elapsed: 0.0s
Progress: 11% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 22% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 44% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 61% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       29.69% |       0.7196 |          0.1000 |
|      13 |          50 |       00:00:00 |       96.09% |       0.2070 |          0.0900 |
|      25 |         100 |       00:00:00 |       96.09% |       0.1327 |          0.0810 |
|      38 |         150 |       00:00:00 |       96.09% |       0.1247 |          0.0729 |
|      50 |         200 |       00:00:00 |       96.09% |       0.1237 |          0.0656 |
|      63 |         250 |       00:00:00 |       96.09% |       0.1235 |          0.0531 |
|      75 |         300 |       00:00:00 |       96.09% |       0.1226 |          0.0478 |
|      88 |         350 |       00:00:00 |       96.09% |       0.1232 |          0.0430 |
|     100 |         400 |       00:00:00 |       96.09% |       0.1222 |          0.0387 |
|     113 |         450 |       00:00:00 |       96.09% |       0.1231 |          0.0314 |
|     125 |         500 |       00:00:00 |       96.09% |       0.1220 |          0.0282 |
|     138 |         550 |       00:00:00 |       96.09% |       0.1230 |          0.0254 |
|     150 |         600 |       00:00:00 |       96.09% |       0.1218 |          0.0229 |
|     163 |         650 |       00:00:00 |       96.09% |       0.1230 |          0.0185 |
|     175 |         700 |       00:00:01 |       96.09% |       0.1217 |          0.0167 |
|     188 |         750 |       00:00:01 |       96.09% |       0.1229 |          0.0150 |
|     200 |         800 |       00:00:01 |       96.09% |       0.1217 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.7500, Recall: 0.5000, F1-Score: 0.6000
AUC: 0.9514
Processing dataset: F2P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 6 / 79 (7.6%)
[DivideNet] Attempts made: 174 | Failed attempts: 168
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 173
    Train Negative: 346
    Test  Positive: 6
    Test  Negative: 12
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 519 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 18 subgraphs (K = 10)...
Progress: 6% – Elapsed: 0.0s
Progress: 11% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 22% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 44% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 61% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       11.72% |       0.7009 |          0.1000 |
|      13 |          50 |       00:00:00 |       92.97% |       0.2515 |          0.0900 |
|      25 |         100 |       00:00:00 |       97.66% |       0.0979 |          0.0810 |
|      38 |         150 |       00:00:00 |       94.53% |       0.1485 |          0.0729 |
|      50 |         200 |       00:00:00 |       97.66% |       0.0993 |          0.0656 |
|      63 |         250 |       00:00:00 |       94.53% |       0.1457 |          0.0531 |
|      75 |         300 |       00:00:00 |       97.66% |       0.0969 |          0.0478 |
|      88 |         350 |       00:00:00 |       94.53% |       0.1457 |          0.0430 |
|     100 |         400 |       00:00:00 |       97.66% |       0.0967 |          0.0387 |
|     113 |         450 |       00:00:00 |       94.53% |       0.1442 |          0.0314 |
|     125 |         500 |       00:00:00 |       97.66% |       0.0960 |          0.0282 |
|     138 |         550 |       00:00:00 |       94.53% |       0.1438 |          0.0254 |
|     150 |         600 |       00:00:00 |       97.66% |       0.0960 |          0.0229 |
|     163 |         650 |       00:00:00 |       94.53% |       0.1436 |          0.0185 |
|     175 |         700 |       00:00:00 |       97.66% |       0.0958 |          0.0167 |
|     188 |         750 |       00:00:00 |       94.53% |       0.1434 |          0.0150 |
|     200 |         800 |       00:00:00 |       97.66% |       0.0957 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.6667, F1-Score: 0.8000
AUC: 0.9444
Processing dataset: F2P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 6 / 70 (8.6%)
[DivideNet] Attempts made: 174 | Failed attempts: 168
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 173
    Train Negative: 346
    Test  Positive: 6
    Test  Negative: 12
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 519 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.2s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 18 subgraphs (K = 10)...
Progress: 6% – Elapsed: 0.0s
Progress: 11% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 22% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 44% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 61% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       67.19% |       0.6691 |          0.1000 |
|      13 |          50 |       00:00:00 |       94.53% |       0.1843 |          0.0900 |
|      25 |         100 |       00:00:00 |       97.66% |       0.0986 |          0.0810 |
|      38 |         150 |       00:00:00 |       96.09% |       0.1298 |          0.0729 |
|      50 |         200 |       00:00:00 |       97.66% |       0.0905 |          0.0656 |
|      63 |         250 |       00:00:00 |       96.09% |       0.1277 |          0.0531 |
|      75 |         300 |       00:00:00 |       97.66% |       0.0844 |          0.0478 |
|      88 |         350 |       00:00:00 |       96.09% |       0.1227 |          0.0430 |
|     100 |         400 |       00:00:00 |       97.66% |       0.0842 |          0.0387 |
|     113 |         450 |       00:00:00 |       96.09% |       0.1221 |          0.0314 |
|     125 |         500 |       00:00:00 |       97.66% |       0.0836 |          0.0282 |
|     138 |         550 |       00:00:00 |       96.09% |       0.1218 |          0.0254 |
|     150 |         600 |       00:00:00 |       97.66% |       0.0823 |          0.0229 |
|     163 |         650 |       00:00:00 |       96.09% |       0.1217 |          0.0185 |
|     175 |         700 |       00:00:01 |       97.66% |       0.0830 |          0.0167 |
|     188 |         750 |       00:00:01 |       96.09% |       0.1216 |          0.0150 |
|     200 |         800 |       00:00:01 |       97.66% |       0.0829 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.5000, F1-Score: 0.6667
AUC: 0.9306
Processing dataset: F2P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 6 / 61 (9.8%)
[DivideNet] Attempts made: 174 | Failed attempts: 168
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 173
    Train Negative: 346
    Test  Positive: 6
    Test  Negative: 12
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 519 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.2s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 18 subgraphs (K = 10)...
Progress: 6% – Elapsed: 0.0s
Progress: 11% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 22% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 44% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 61% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       81.25% |       0.6767 |          0.1000 |
|      13 |          50 |       00:00:00 |       92.19% |       0.2431 |          0.0900 |
|      25 |         100 |       00:00:00 |       96.09% |       0.1450 |          0.0810 |
|      38 |         150 |       00:00:00 |       96.09% |       0.1129 |          0.0729 |
|      50 |         200 |       00:00:00 |       96.09% |       0.1232 |          0.0656 |
|      63 |         250 |       00:00:00 |       96.88% |       0.1046 |          0.0531 |
|      75 |         300 |       00:00:00 |       96.09% |       0.1203 |          0.0478 |
|      88 |         350 |       00:00:00 |       96.88% |       0.1031 |          0.0430 |
|     100 |         400 |       00:00:00 |       96.09% |       0.1213 |          0.0387 |
|     113 |         450 |       00:00:00 |       96.88% |       0.1028 |          0.0314 |
|     125 |         500 |       00:00:00 |       96.09% |       0.1191 |          0.0282 |
|     138 |         550 |       00:00:00 |       96.88% |       0.1023 |          0.0254 |
|     150 |         600 |       00:00:00 |       96.09% |       0.1195 |          0.0229 |
|     163 |         650 |       00:00:01 |       96.88% |       0.1022 |          0.0185 |
|     175 |         700 |       00:00:01 |       96.09% |       0.1188 |          0.0167 |
|     188 |         750 |       00:00:01 |       96.88% |       0.1020 |          0.0150 |
|     200 |         800 |       00:00:01 |       96.09% |       0.1185 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.5000, F1-Score: 0.6667
AUC: 0.9861
Processing dataset: F2P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 6 / 53 (11.3%)
[DivideNet] Attempts made: 174 | Failed attempts: 168
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 173
    Train Negative: 346
    Test  Positive: 6
    Test  Negative: 12
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 519 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.2s
Progress: 88% – Elapsed: 0.2s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 18 subgraphs (K = 10)...
Progress: 6% – Elapsed: 0.0s
Progress: 11% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 22% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 44% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 61% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       32.03% |       0.6911 |          0.1000 |
|      13 |          50 |       00:00:00 |       96.88% |       0.1286 |          0.0900 |
|      25 |         100 |       00:00:00 |       95.31% |       0.1556 |          0.0810 |
|      38 |         150 |       00:00:00 |       97.66% |       0.0874 |          0.0729 |
|      50 |         200 |       00:00:00 |       95.31% |       0.1475 |          0.0656 |
|      63 |         250 |       00:00:00 |       97.66% |       0.0834 |          0.0531 |
|      75 |         300 |       00:00:00 |       95.31% |       0.1426 |          0.0478 |
|      88 |         350 |       00:00:00 |       97.66% |       0.0828 |          0.0430 |
|     100 |         400 |       00:00:00 |       95.31% |       0.1418 |          0.0387 |
|     113 |         450 |       00:00:00 |       97.66% |       0.0823 |          0.0314 |
|     125 |         500 |       00:00:00 |       95.31% |       0.1408 |          0.0282 |
|     138 |         550 |       00:00:00 |       97.66% |       0.0817 |          0.0254 |
|     150 |         600 |       00:00:00 |       95.31% |       0.1401 |          0.0229 |
|     163 |         650 |       00:00:00 |       97.66% |       0.0814 |          0.0185 |
|     175 |         700 |       00:00:00 |       95.31% |       0.1395 |          0.0167 |
|     188 |         750 |       00:00:01 |       97.66% |       0.0813 |          0.0150 |
|     200 |         800 |       00:00:01 |       95.31% |       0.1393 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.5000, F1-Score: 0.6667
AUC: 0.9722
Processing dataset: F2P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 6 / 44 (13.6%)
[DivideNet] Attempts made: 174 | Failed attempts: 168
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 173
    Train Negative: 346
    Test  Positive: 6
    Test  Negative: 12
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 519 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.2s
Progress: 69% – Elapsed: 0.2s
Progress: 79% – Elapsed: 0.2s
Progress: 88% – Elapsed: 0.3s
Progress: 98% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 18 subgraphs (K = 10)...
Progress: 6% – Elapsed: 0.0s
Progress: 11% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 22% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 44% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 61% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       66.41% |       0.6728 |          0.1000 |
|      13 |          50 |       00:00:00 |       97.66% |       0.1018 |          0.0900 |
|      25 |         100 |       00:00:00 |       97.66% |       0.0965 |          0.0810 |
|      38 |         150 |       00:00:00 |       98.44% |       0.0708 |          0.0729 |
|      50 |         200 |       00:00:00 |       97.66% |       0.0890 |          0.0656 |
|      63 |         250 |       00:00:00 |       98.44% |       0.0681 |          0.0531 |
|      75 |         300 |       00:00:00 |       97.66% |       0.0883 |          0.0478 |
|      88 |         350 |       00:00:00 |       98.44% |       0.0675 |          0.0430 |
|     100 |         400 |       00:00:00 |       97.66% |       0.0876 |          0.0387 |
|     113 |         450 |       00:00:01 |       98.44% |       0.0674 |          0.0314 |
|     125 |         500 |       00:00:01 |       97.66% |       0.0877 |          0.0282 |
|     138 |         550 |       00:00:01 |       98.44% |       0.0669 |          0.0254 |
|     150 |         600 |       00:00:01 |       97.66% |       0.0874 |          0.0229 |
|     163 |         650 |       00:00:01 |       98.44% |       0.0669 |          0.0185 |
|     175 |         700 |       00:00:01 |       97.66% |       0.0876 |          0.0167 |
|     188 |         750 |       00:00:01 |       98.44% |       0.0666 |          0.0150 |
|     200 |         800 |       00:00:01 |       97.66% |       0.0875 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.5000, Recall: 0.5000, F1-Score: 0.5000
AUC: 0.8125
Processing dataset: F2P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 6 / 35 (17.1%)
[DivideNet] Attempts made: 174 | Failed attempts: 168
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 173
    Train Negative: 346
    Test  Positive: 6
    Test  Negative: 12
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 519 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.1s
Done. Total time: 0.2s
Encoding 18 subgraphs (K = 10)...
Progress: 6% – Elapsed: 0.0s
Progress: 11% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 22% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 44% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 61% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       64.06% |       0.6542 |          0.1000 |
|      13 |          50 |       00:00:00 |       97.66% |       0.1213 |          0.0900 |
|      25 |         100 |       00:00:00 |       98.44% |       0.0802 |          0.0810 |
|      38 |         150 |       00:00:00 |       97.66% |       0.0906 |          0.0729 |
|      50 |         200 |       00:00:00 |       98.44% |       0.0746 |          0.0656 |
|      63 |         250 |       00:00:00 |       97.66% |       0.0912 |          0.0531 |
|      75 |         300 |       00:00:00 |       98.44% |       0.0706 |          0.0478 |
|      88 |         350 |       00:00:00 |       97.66% |       0.0903 |          0.0430 |
|     100 |         400 |       00:00:00 |       98.44% |       0.0706 |          0.0387 |
|     113 |         450 |       00:00:00 |       97.66% |       0.0903 |          0.0314 |
|     125 |         500 |       00:00:00 |       98.44% |       0.0701 |          0.0282 |
|     138 |         550 |       00:00:00 |       97.66% |       0.0900 |          0.0254 |
|     150 |         600 |       00:00:00 |       98.44% |       0.0690 |          0.0229 |
|     163 |         650 |       00:00:00 |       97.66% |       0.0900 |          0.0185 |
|     175 |         700 |       00:00:00 |       98.44% |       0.0680 |          0.0167 |
|     188 |         750 |       00:00:00 |       97.66% |       0.0901 |          0.0150 |
|     200 |         800 |       00:00:00 |       98.44% |       0.0692 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.7500, Recall: 0.5000, F1-Score: 0.6000
AUC: 0.9236
Processing dataset: F2P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 6 / 27 (22.2%)
[DivideNet] Attempts made: 174 | Failed attempts: 168
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 173
    Train Negative: 346
    Test  Positive: 6
    Test  Negative: 12
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 519 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.2s
Progress: 79% – Elapsed: 0.2s
Progress: 88% – Elapsed: 0.2s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 18 subgraphs (K = 10)...
Progress: 6% – Elapsed: 0.0s
Progress: 11% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 22% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 44% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 61% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       31.25% |       0.7147 |          0.1000 |
|      13 |          50 |       00:00:00 |       97.66% |       0.1361 |          0.0900 |
|      25 |         100 |       00:00:00 |       95.31% |       0.1604 |          0.0810 |
|      38 |         150 |       00:00:00 |       99.22% |       0.0544 |          0.0729 |
|      50 |         200 |       00:00:00 |       95.31% |       0.1478 |          0.0656 |
|      63 |         250 |       00:00:00 |       99.22% |       0.0532 |          0.0531 |
|      75 |         300 |       00:00:00 |       95.31% |       0.1448 |          0.0478 |
|      88 |         350 |       00:00:00 |       99.22% |       0.0520 |          0.0430 |
|     100 |         400 |       00:00:00 |       95.31% |       0.1431 |          0.0387 |
|     113 |         450 |       00:00:00 |       99.22% |       0.0508 |          0.0314 |
|     125 |         500 |       00:00:00 |       95.31% |       0.1424 |          0.0282 |
|     138 |         550 |       00:00:00 |       99.22% |       0.0501 |          0.0254 |
|     150 |         600 |       00:00:00 |       95.31% |       0.1419 |          0.0229 |
|     163 |         650 |       00:00:01 |       99.22% |       0.0496 |          0.0185 |
|     175 |         700 |       00:00:01 |       95.31% |       0.1414 |          0.0167 |
|     188 |         750 |       00:00:01 |       99.22% |       0.0492 |          0.0150 |
|     200 |         800 |       00:00:01 |       95.31% |       0.1414 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.6000, Recall: 0.5000, F1-Score: 0.5455
AUC: 0.8750
Processing dataset: F2P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 6 / 18 (33.3%)
[DivideNet] Attempts made: 174 | Failed attempts: 168
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 173
    Train Negative: 346
    Test  Positive: 6
    Test  Negative: 12
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 519 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.2s
Progress: 69% – Elapsed: 0.2s
Progress: 79% – Elapsed: 0.2s
Progress: 88% – Elapsed: 0.3s
Progress: 98% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 18 subgraphs (K = 10)...
Progress: 6% – Elapsed: 0.0s
Progress: 11% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 22% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 44% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 61% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       11.72% |       0.7199 |          0.1000 |
|      13 |          50 |       00:00:00 |       92.97% |       0.3141 |          0.0900 |
|      25 |         100 |       00:00:00 |       94.53% |       0.1513 |          0.0810 |
|      38 |         150 |       00:00:00 |       96.09% |       0.1225 |          0.0729 |
|      50 |         200 |       00:00:00 |       95.31% |       0.1399 |          0.0656 |
|      63 |         250 |       00:00:00 |       96.09% |       0.1207 |          0.0531 |
|      75 |         300 |       00:00:00 |       95.31% |       0.1349 |          0.0478 |
|      88 |         350 |       00:00:00 |       96.09% |       0.1198 |          0.0430 |
|     100 |         400 |       00:00:00 |       95.31% |       0.1336 |          0.0387 |
|     113 |         450 |       00:00:00 |       96.09% |       0.1195 |          0.0314 |
|     125 |         500 |       00:00:00 |       95.31% |       0.1341 |          0.0282 |
|     138 |         550 |       00:00:00 |       96.09% |       0.1194 |          0.0254 |
|     150 |         600 |       00:00:01 |       95.31% |       0.1332 |          0.0229 |
|     163 |         650 |       00:00:01 |       96.09% |       0.1194 |          0.0185 |
|     175 |         700 |       00:00:01 |       95.31% |       0.1330 |          0.0167 |
|     188 |         750 |       00:00:01 |       96.09% |       0.1193 |          0.0150 |
|     200 |         800 |       00:00:01 |       95.31% |       0.1329 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.5000, F1-Score: 0.6667
AUC: 1.0000
Processing dataset: F2P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 6 / 157 (3.8%)
[DivideNet] Attempts made: 174 | Failed attempts: 168
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 173
    Train Negative: 346
    Test  Positive: 6
    Test  Negative: 12
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 519 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.2s
Progress: 88% – Elapsed: 0.2s
Progress: 98% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 18 subgraphs (K = 10)...
Progress: 6% – Elapsed: 0.0s
Progress: 11% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 22% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 44% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 61% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       12.50% |       0.7466 |          0.1000 |
|      13 |          50 |       00:00:00 |       95.31% |       0.1927 |          0.0900 |
|      25 |         100 |       00:00:00 |       96.09% |       0.1252 |          0.0810 |
|      38 |         150 |       00:00:00 |       95.31% |       0.1428 |          0.0729 |
|      50 |         200 |       00:00:00 |       96.09% |       0.1194 |          0.0656 |
|      63 |         250 |       00:00:00 |       95.31% |       0.1388 |          0.0531 |
|      75 |         300 |       00:00:01 |       96.09% |       0.1192 |          0.0478 |
|      88 |         350 |       00:00:01 |       95.31% |       0.1390 |          0.0430 |
|     100 |         400 |       00:00:01 |       96.09% |       0.1189 |          0.0387 |
|     113 |         450 |       00:00:01 |       95.31% |       0.1387 |          0.0314 |
|     125 |         500 |       00:00:01 |       96.09% |       0.1188 |          0.0282 |
|     138 |         550 |       00:00:01 |       95.31% |       0.1383 |          0.0254 |
|     150 |         600 |       00:00:01 |       96.09% |       0.1187 |          0.0229 |
|     163 |         650 |       00:00:01 |       95.31% |       0.1382 |          0.0185 |
|     175 |         700 |       00:00:01 |       96.09% |       0.1186 |          0.0167 |
|     188 |         750 |       00:00:01 |       95.31% |       0.1380 |          0.0150 |
|     200 |         800 |       00:00:01 |       96.09% |       0.1186 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.5000, F1-Score: 0.6667
AUC: 1.0000
Processing dataset: F2P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 6 / 148 (4.1%)
[DivideNet] Attempts made: 174 | Failed attempts: 168
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 173
    Train Negative: 346
    Test  Positive: 6
    Test  Negative: 12
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 519 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.2s
Progress: 69% – Elapsed: 0.2s
Progress: 79% – Elapsed: 0.2s
Progress: 88% – Elapsed: 0.2s
Progress: 98% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 18 subgraphs (K = 10)...
Progress: 6% – Elapsed: 0.0s
Progress: 11% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 22% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 44% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 61% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       58.59% |       0.6945 |          0.1000 |
|      13 |          50 |       00:00:00 |       96.09% |       0.2409 |          0.0900 |
|      25 |         100 |       00:00:00 |       95.31% |       0.1554 |          0.0810 |
|      38 |         150 |       00:00:00 |       96.09% |       0.1267 |          0.0729 |
|      50 |         200 |       00:00:00 |       95.31% |       0.1406 |          0.0656 |
|      63 |         250 |       00:00:00 |       96.09% |       0.1250 |          0.0531 |
|      75 |         300 |       00:00:00 |       95.31% |       0.1349 |          0.0478 |
|      88 |         350 |       00:00:00 |       96.09% |       0.1238 |          0.0430 |
|     100 |         400 |       00:00:00 |       95.31% |       0.1322 |          0.0387 |
|     113 |         450 |       00:00:00 |       96.09% |       0.1234 |          0.0314 |
|     125 |         500 |       00:00:01 |       95.31% |       0.1336 |          0.0282 |
|     138 |         550 |       00:00:01 |       96.09% |       0.1232 |          0.0254 |
|     150 |         600 |       00:00:01 |       95.31% |       0.1330 |          0.0229 |
|     163 |         650 |       00:00:01 |       96.09% |       0.1229 |          0.0185 |
|     175 |         700 |       00:00:01 |       95.31% |       0.1328 |          0.0167 |
|     188 |         750 |       00:00:01 |       96.09% |       0.1229 |          0.0150 |
|     200 |         800 |       00:00:01 |       95.31% |       0.1329 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.6667, Recall: 0.3333, F1-Score: 0.4444
AUC: 0.9375
Processing dataset: F2P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 6 / 140 (4.3%)
[DivideNet] Attempts made: 174 | Failed attempts: 168
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 173
    Train Negative: 346
    Test  Positive: 6
    Test  Negative: 12
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 519 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.2s
Progress: 88% – Elapsed: 0.2s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 18 subgraphs (K = 10)...
Progress: 6% – Elapsed: 0.0s
Progress: 11% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 22% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 44% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 61% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       27.34% |       0.7267 |          0.1000 |
|      13 |          50 |       00:00:00 |       95.31% |       0.2307 |          0.0900 |
|      25 |         100 |       00:00:00 |       94.53% |       0.1950 |          0.0810 |
|      38 |         150 |       00:00:00 |       99.22% |       0.0737 |          0.0729 |
|      50 |         200 |       00:00:00 |       94.53% |       0.1656 |          0.0656 |
|      63 |         250 |       00:00:00 |      100.00% |       0.0550 |          0.0531 |
|      75 |         300 |       00:00:00 |       94.53% |       0.1575 |          0.0478 |
|      88 |         350 |       00:00:00 |      100.00% |       0.0467 |          0.0430 |
|     100 |         400 |       00:00:00 |       94.53% |       0.1549 |          0.0387 |
|     113 |         450 |       00:00:00 |      100.00% |       0.0411 |          0.0314 |
|     125 |         500 |       00:00:00 |       94.53% |       0.1553 |          0.0282 |
|     138 |         550 |       00:00:00 |      100.00% |       0.0428 |          0.0254 |
|     150 |         600 |       00:00:00 |       94.53% |       0.1534 |          0.0229 |
|     163 |         650 |       00:00:00 |      100.00% |       0.0377 |          0.0185 |
|     175 |         700 |       00:00:01 |       94.53% |       0.1526 |          0.0167 |
|     188 |         750 |       00:00:01 |      100.00% |       0.0372 |          0.0150 |
|     200 |         800 |       00:00:01 |       94.53% |       0.1526 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.6667, F1-Score: 0.8000
AUC: 0.9167
Processing dataset: F2P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 6 / 131 (4.6%)
[DivideNet] Attempts made: 174 | Failed attempts: 168
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 173
    Train Negative: 346
    Test  Positive: 6
    Test  Negative: 12
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 519 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 18 subgraphs (K = 10)...
Progress: 6% – Elapsed: 0.0s
Progress: 11% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 22% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 44% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 61% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       31.25% |       0.7443 |          0.1000 |
|      13 |          50 |       00:00:00 |       95.31% |       0.1594 |          0.0900 |
|      25 |         100 |       00:00:00 |       94.53% |       0.2126 |          0.0810 |
|      38 |         150 |       00:00:00 |       97.66% |       0.0867 |          0.0729 |
|      50 |         200 |       00:00:00 |       96.88% |       0.1108 |          0.0656 |
|      63 |         250 |       00:00:00 |       97.66% |       0.0824 |          0.0531 |
|      75 |         300 |       00:00:00 |       96.88% |       0.1073 |          0.0478 |
|      88 |         350 |       00:00:00 |       97.66% |       0.0819 |          0.0430 |
|     100 |         400 |       00:00:00 |       96.88% |       0.1064 |          0.0387 |
|     113 |         450 |       00:00:00 |       97.66% |       0.0817 |          0.0314 |
|     125 |         500 |       00:00:00 |       96.88% |       0.1060 |          0.0282 |
|     138 |         550 |       00:00:00 |       97.66% |       0.0815 |          0.0254 |
|     150 |         600 |       00:00:00 |       96.88% |       0.1059 |          0.0229 |
|     163 |         650 |       00:00:00 |       97.66% |       0.0815 |          0.0185 |
|     175 |         700 |       00:00:00 |       96.88% |       0.1057 |          0.0167 |
|     188 |         750 |       00:00:00 |       97.66% |       0.0814 |          0.0150 |
|     200 |         800 |       00:00:01 |       96.88% |       0.1057 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.6667, F1-Score: 0.8000
AUC: 1.0000
Processing dataset: F2P2_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 6 / 122 (4.9%)
[DivideNet] Attempts made: 174 | Failed attempts: 168
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 173
    Train Negative: 346
    Test  Positive: 6
    Test  Negative: 12
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 519 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 18 subgraphs (K = 10)...
Progress: 6% – Elapsed: 0.0s
Progress: 11% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 22% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 44% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 61% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 89% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Progress: 100% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |        9.38% |       0.7426 |          0.1000 |
|      13 |          50 |       00:00:00 |       94.53% |       0.1413 |          0.0900 |
|      25 |         100 |       00:00:00 |       95.31% |       0.1816 |          0.0810 |
|      38 |         150 |       00:00:00 |       98.44% |       0.0733 |          0.0729 |
|      50 |         200 |       00:00:00 |       95.31% |       0.1463 |          0.0656 |
|      63 |         250 |       00:00:00 |       99.22% |       0.0600 |          0.0531 |
|      75 |         300 |       00:00:00 |       95.31% |       0.1433 |          0.0478 |
|      88 |         350 |       00:00:00 |       99.22% |       0.0536 |          0.0430 |
|     100 |         400 |       00:00:00 |       95.31% |       0.1413 |          0.0387 |
|     113 |         450 |       00:00:00 |       99.22% |       0.0506 |          0.0314 |
|     125 |         500 |       00:00:00 |       95.31% |       0.1397 |          0.0282 |
|     138 |         550 |       00:00:00 |       99.22% |       0.0504 |          0.0254 |
|     150 |         600 |       00:00:00 |       95.31% |       0.1387 |          0.0229 |
|     163 |         650 |       00:00:00 |       99.22% |       0.0491 |          0.0185 |
|     175 |         700 |       00:00:00 |       95.31% |       0.1383 |          0.0167 |
|     188 |         750 |       00:00:00 |       99.22% |       0.0481 |          0.0150 |
|     200 |         800 |       00:00:00 |       95.31% |       0.1380 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.6000, Recall: 0.5000, F1-Score: 0.5455
AUC: 0.8750
