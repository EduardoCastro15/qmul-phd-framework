Processing dataset: Balsam lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 98 / 168 (58.3%)
[DivideNet] Attempts made: 258 | Failed attempts: 160
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 163
    Train Negative: 326
    Test  Positive: 98
    Test  Negative: 196
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 489 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 294 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 59% – Elapsed: 0.0s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 99% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       65.62% |       0.6613 |          0.1000 |
|      17 |          50 |       00:00:00 |       98.44% |       0.0563 |          0.0900 |
|      34 |         100 |       00:00:00 |      100.00% |       0.0119 |          0.0729 |
|      50 |         150 |       00:00:00 |       99.22% |       0.0329 |          0.0656 |
|      67 |         200 |       00:00:00 |       98.44% |       0.0576 |          0.0531 |
|      84 |         250 |       00:00:00 |      100.00% |       0.0091 |          0.0430 |
|     100 |         300 |       00:00:00 |       99.22% |       0.0323 |          0.0387 |
|     117 |         350 |       00:00:00 |       98.44% |       0.0574 |          0.0314 |
|     134 |         400 |       00:00:00 |      100.00% |       0.0098 |          0.0254 |
|     150 |         450 |       00:00:00 |       99.22% |       0.0321 |          0.0229 |
|     167 |         500 |       00:00:00 |       98.44% |       0.0570 |          0.0185 |
|     184 |         550 |       00:00:00 |      100.00% |       0.0095 |          0.0150 |
|     200 |         600 |       00:00:00 |       99.22% |       0.0320 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9600, Recall: 0.7347, F1-Score: 0.8324
AUC: 0.9598
Processing dataset: Balsam lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 98 / 155 (63.2%)
[DivideNet] Attempts made: 258 | Failed attempts: 160
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 163
    Train Negative: 326
    Test  Positive: 98
    Test  Negative: 196
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 489 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 294 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 59% – Elapsed: 0.0s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 99% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       36.72% |       0.7262 |          0.1000 |
|      17 |          50 |       00:00:00 |       99.22% |       0.0419 |          0.0900 |
|      34 |         100 |       00:00:00 |      100.00% |       0.0044 |          0.0729 |
|      50 |         150 |       00:00:00 |      100.00% |       0.0037 |          0.0656 |
|      67 |         200 |       00:00:00 |       99.22% |       0.0387 |          0.0531 |
|      84 |         250 |       00:00:00 |      100.00% |       0.0037 |          0.0430 |
|     100 |         300 |       00:00:00 |      100.00% |       0.0036 |          0.0387 |
|     117 |         350 |       00:00:00 |       99.22% |       0.0375 |          0.0314 |
|     134 |         400 |       00:00:00 |      100.00% |       0.0033 |          0.0254 |
|     150 |         450 |       00:00:00 |      100.00% |       0.0034 |          0.0229 |
|     167 |         500 |       00:00:00 |       99.22% |       0.0375 |          0.0185 |
|     184 |         550 |       00:00:00 |      100.00% |       0.0032 |          0.0150 |
|     200 |         600 |       00:00:00 |      100.00% |       0.0033 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9143, Recall: 0.6531, F1-Score: 0.7619
AUC: 0.9235
Processing dataset: Balsam lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 98 / 142 (69.0%)
[DivideNet] Attempts made: 258 | Failed attempts: 160
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 163
    Train Negative: 326
    Test  Positive: 98
    Test  Negative: 196
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 489 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 294 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 99% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       69.53% |       0.6768 |          0.1000 |
|      17 |          50 |       00:00:00 |       98.44% |       0.0587 |          0.0900 |
|      34 |         100 |       00:00:00 |       89.06% |       0.2018 |          0.0729 |
|      50 |         150 |       00:00:00 |       98.44% |       0.0649 |          0.0656 |
|      67 |         200 |       00:00:00 |       99.22% |       0.0360 |          0.0531 |
|      84 |         250 |       00:00:00 |      100.00% |       0.0087 |          0.0430 |
|     100 |         300 |       00:00:00 |       98.44% |       0.0602 |          0.0387 |
|     117 |         350 |       00:00:00 |       99.22% |       0.0346 |          0.0314 |
|     134 |         400 |       00:00:00 |      100.00% |       0.0082 |          0.0254 |
|     150 |         450 |       00:00:00 |       98.44% |       0.0596 |          0.0229 |
|     167 |         500 |       00:00:00 |       99.22% |       0.0344 |          0.0185 |
|     184 |         550 |       00:00:00 |      100.00% |       0.0081 |          0.0150 |
|     200 |         600 |       00:00:00 |       98.44% |       0.0593 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9559, Recall: 0.6633, F1-Score: 0.7831
AUC: 0.9468
Processing dataset: Balsam lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 98 / 129 (76.0%)
[DivideNet] Attempts made: 258 | Failed attempts: 160
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 163
    Train Negative: 326
    Test  Positive: 98
    Test  Negative: 196
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 489 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 294 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 99% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       30.47% |       0.7267 |          0.1000 |
|      17 |          50 |       00:00:00 |      100.00% |       0.0102 |          0.0900 |
|      34 |         100 |       00:00:00 |      100.00% |       0.0053 |          0.0729 |
|      50 |         150 |       00:00:00 |       99.22% |       0.0400 |          0.0656 |
|      67 |         200 |       00:00:01 |      100.00% |       0.0030 |          0.0531 |
|      84 |         250 |       00:00:01 |      100.00% |       0.0033 |          0.0430 |
|     100 |         300 |       00:00:01 |       99.22% |       0.0384 |          0.0387 |
|     117 |         350 |       00:00:01 |      100.00% |       0.0029 |          0.0314 |
|     134 |         400 |       00:00:01 |      100.00% |       0.0031 |          0.0254 |
|     150 |         450 |       00:00:02 |       99.22% |       0.0377 |          0.0229 |
|     167 |         500 |       00:00:02 |      100.00% |       0.0028 |          0.0185 |
|     184 |         550 |       00:00:02 |      100.00% |       0.0031 |          0.0150 |
|     200 |         600 |       00:00:02 |       99.22% |       0.0374 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9324, Recall: 0.7041, F1-Score: 0.8023
AUC: 0.9385
Processing dataset: Balsam lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 98 / 117 (83.8%)
[DivideNet] Attempts made: 258 | Failed attempts: 160
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 163
    Train Negative: 326
    Test  Positive: 98
    Test  Negative: 196
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 489 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 294 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 99% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       81.25% |       0.6461 |          0.1000 |
|      17 |          50 |       00:00:00 |       98.44% |       0.0832 |          0.0900 |
|      34 |         100 |       00:00:00 |      100.00% |       0.0070 |          0.0729 |
|      50 |         150 |       00:00:00 |      100.00% |       0.0071 |          0.0656 |
|      67 |         200 |       00:00:00 |       98.44% |       0.0621 |          0.0531 |
|      84 |         250 |       00:00:00 |      100.00% |       0.0057 |          0.0430 |
|     100 |         300 |       00:00:00 |      100.00% |       0.0075 |          0.0387 |
|     117 |         350 |       00:00:00 |       98.44% |       0.0611 |          0.0314 |
|     134 |         400 |       00:00:00 |      100.00% |       0.0055 |          0.0254 |
|     150 |         450 |       00:00:00 |      100.00% |       0.0054 |          0.0229 |
|     167 |         500 |       00:00:00 |       98.44% |       0.0607 |          0.0185 |
|     184 |         550 |       00:00:00 |      100.00% |       0.0055 |          0.0150 |
|     200 |         600 |       00:00:00 |      100.00% |       0.0066 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9367, Recall: 0.7551, F1-Score: 0.8362
AUC: 0.9493
Processing dataset: Balsam lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 99 / 104 (95.2%)
[DivideNet] Attempts made: 258 | Failed attempts: 159
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 162
    Train Negative: 324
    Test  Positive: 99
    Test  Negative: 198
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 486 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 99% – Elapsed: 0.1s
Done. Total time: 0.1s
Encoding 297 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 59% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.1s
Progress: 78% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       64.06% |       0.6601 |          0.1000 |
|      17 |          50 |       00:00:00 |      100.00% |       0.0077 |          0.0900 |
|      34 |         100 |       00:00:00 |      100.00% |       0.0012 |          0.0729 |
|      50 |         150 |       00:00:00 |      100.00% |       0.0002 |          0.0656 |
|      67 |         200 |       00:00:00 |      100.00% |       0.0001 |          0.0531 |
|      84 |         250 |       00:00:00 |      100.00% |       0.0004 |          0.0430 |
|     100 |         300 |       00:00:00 |      100.00% |       0.0001 |          0.0387 |
|     117 |         350 |       00:00:00 |      100.00% |   9.0450e-05 |          0.0314 |
|     134 |         400 |       00:00:00 |      100.00% |       0.0003 |          0.0254 |
|     150 |         450 |       00:00:00 |      100.00% |       0.0001 |          0.0229 |
|     167 |         500 |       00:00:00 |      100.00% |   7.5453e-05 |          0.0185 |
|     184 |         550 |       00:00:00 |      100.00% |       0.0003 |          0.0150 |
|     200 |         600 |       00:00:00 |      100.00% |   9.1844e-05 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.30, Precision: 0.9467, Recall: 0.7172, F1-Score: 0.8161
AUC: 0.9261
Processing dataset: Balsam lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 91 / 91 (100.0%)
[DivideNet] Attempts made: 216 | Failed attempts: 125
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 170
    Train Negative: 340
    Test  Positive: 91
    Test  Negative: 182
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 510 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 273 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 99% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       20.31% |       0.7448 |          0.1000 |
|      17 |          50 |       00:00:00 |       96.88% |       0.1082 |          0.0900 |
|      34 |         100 |       00:00:00 |       98.44% |       0.0402 |          0.0729 |
|      50 |         150 |       00:00:00 |      100.00% |       0.0092 |          0.0656 |
|      67 |         200 |       00:00:00 |       98.44% |       0.0617 |          0.0531 |
|      84 |         250 |       00:00:00 |       99.22% |       0.0322 |          0.0430 |
|     100 |         300 |       00:00:00 |      100.00% |       0.0078 |          0.0387 |
|     117 |         350 |       00:00:00 |       98.44% |       0.0615 |          0.0314 |
|     134 |         400 |       00:00:00 |       99.22% |       0.0318 |          0.0254 |
|     150 |         450 |       00:00:00 |      100.00% |       0.0081 |          0.0229 |
|     167 |         500 |       00:00:01 |       98.44% |       0.0594 |          0.0185 |
|     184 |         550 |       00:00:01 |       99.22% |       0.0316 |          0.0150 |
|     200 |         600 |       00:00:01 |      100.00% |       0.0079 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.75, Precision: 0.9767, Recall: 0.9231, F1-Score: 0.9492
AUC: 0.9843
Processing dataset: Balsam lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 78 / 78 (100.0%)
[DivideNet] Attempts made: 187 | Failed attempts: 109
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 183
    Train Negative: 366
    Test  Positive: 78
    Test  Negative: 156
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 549 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 234 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 59% – Elapsed: 0.0s
Progress: 69% – Elapsed: 0.0s
Progress: 79% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       33.59% |       0.7644 |          0.1000 |
|      13 |          50 |       00:00:00 |       96.88% |       0.1056 |          0.0900 |
|      25 |         100 |       00:00:00 |       99.22% |       0.0284 |          0.0810 |
|      38 |         150 |       00:00:00 |      100.00% |       0.0081 |          0.0729 |
|      50 |         200 |       00:00:00 |      100.00% |       0.0110 |          0.0656 |
|      63 |         250 |       00:00:00 |      100.00% |       0.0077 |          0.0531 |
|      75 |         300 |       00:00:00 |      100.00% |       0.0087 |          0.0478 |
|      88 |         350 |       00:00:00 |      100.00% |       0.0074 |          0.0430 |
|     100 |         400 |       00:00:00 |      100.00% |       0.0078 |          0.0387 |
|     113 |         450 |       00:00:00 |      100.00% |       0.0069 |          0.0314 |
|     125 |         500 |       00:00:00 |      100.00% |       0.0070 |          0.0282 |
|     138 |         550 |       00:00:00 |      100.00% |       0.0069 |          0.0254 |
|     150 |         600 |       00:00:00 |      100.00% |       0.0071 |          0.0229 |
|     163 |         650 |       00:00:00 |      100.00% |       0.0066 |          0.0185 |
|     175 |         700 |       00:00:00 |      100.00% |       0.0070 |          0.0167 |
|     188 |         750 |       00:00:00 |      100.00% |       0.0067 |          0.0150 |
|     200 |         800 |       00:00:01 |      100.00% |       0.0068 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9610, Recall: 0.9487, F1-Score: 0.9548
AUC: 0.9885
Processing dataset: Balsam lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 65 / 65 (100.0%)
[DivideNet] Attempts made: 148 | Failed attempts: 83
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 196
    Train Negative: 392
    Test  Positive: 65
    Test  Negative: 130
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 588 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.2s
Progress: 89% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 195 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 68% – Elapsed: 0.0s
Progress: 78% – Elapsed: 0.0s
Progress: 88% – Elapsed: 0.1s
Progress: 97% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       65.62% |       0.6744 |          0.1000 |
|      13 |          50 |       00:00:00 |       99.22% |       0.0394 |          0.0900 |
|      25 |         100 |       00:00:00 |       99.22% |       0.0174 |          0.0810 |
|      38 |         150 |       00:00:00 |       99.22% |       0.0198 |          0.0729 |
|      50 |         200 |       00:00:00 |       99.22% |       0.0165 |          0.0656 |
|      63 |         250 |       00:00:00 |       99.22% |       0.0118 |          0.0531 |
|      75 |         300 |       00:00:00 |      100.00% |       0.0126 |          0.0478 |
|      88 |         350 |       00:00:00 |       99.22% |       0.0113 |          0.0430 |
|     100 |         400 |       00:00:00 |       99.22% |       0.0137 |          0.0387 |
|     113 |         450 |       00:00:00 |       99.22% |       0.0111 |          0.0314 |
|     125 |         500 |       00:00:00 |       99.22% |       0.0129 |          0.0282 |
|     138 |         550 |       00:00:00 |       99.22% |       0.0114 |          0.0254 |
|     150 |         600 |       00:00:00 |       99.22% |       0.0122 |          0.0229 |
|     163 |         650 |       00:00:01 |       99.22% |       0.0106 |          0.0185 |
|     175 |         700 |       00:00:01 |      100.00% |       0.0119 |          0.0167 |
|     188 |         750 |       00:00:01 |       99.22% |       0.0107 |          0.0150 |
|     200 |         800 |       00:00:01 |       99.22% |       0.0122 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.25, Precision: 0.9692, Recall: 0.9692, F1-Score: 0.9692
AUC: 0.9941
Processing dataset: Balsam lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 52 / 52 (100.0%)
[DivideNet] Attempts made: 123 | Failed attempts: 71
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 209
    Train Negative: 418
    Test  Positive: 52
    Test  Negative: 104
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 627 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 156 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 77% – Elapsed: 0.0s
Progress: 87% – Elapsed: 0.0s
Progress: 96% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       85.16% |       0.6325 |          0.1000 |
|      13 |          50 |       00:00:00 |       96.88% |       0.0872 |          0.0900 |
|      25 |         100 |       00:00:00 |       98.44% |       0.0696 |          0.0810 |
|      38 |         150 |       00:00:00 |       96.88% |       0.1134 |          0.0729 |
|      50 |         200 |       00:00:00 |       98.44% |       0.0663 |          0.0656 |
|      63 |         250 |       00:00:00 |       98.44% |       0.0512 |          0.0531 |
|      75 |         300 |       00:00:00 |       98.44% |       0.0635 |          0.0478 |
|      88 |         350 |       00:00:00 |       99.22% |       0.0426 |          0.0430 |
|     100 |         400 |       00:00:00 |       98.44% |       0.0601 |          0.0387 |
|     113 |         450 |       00:00:00 |       99.22% |       0.0397 |          0.0314 |
|     125 |         500 |       00:00:00 |       98.44% |       0.0578 |          0.0282 |
|     138 |         550 |       00:00:00 |       99.22% |       0.0385 |          0.0254 |
|     150 |         600 |       00:00:00 |       98.44% |       0.0562 |          0.0229 |
|     163 |         650 |       00:00:00 |       99.22% |       0.0378 |          0.0185 |
|     175 |         700 |       00:00:01 |       98.44% |       0.0546 |          0.0167 |
|     188 |         750 |       00:00:01 |       99.22% |       0.0376 |          0.0150 |
|     200 |         800 |       00:00:01 |       98.44% |       0.0536 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.40, Precision: 0.9800, Recall: 0.9423, F1-Score: 0.9608
AUC: 0.9948
Processing dataset: Balsam lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 39 / 39 (100.0%)
[DivideNet] Attempts made: 100 | Failed attempts: 61
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 222
    Train Negative: 444
    Test  Positive: 39
    Test  Negative: 78
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 666 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 117 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 28% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 47% – Elapsed: 0.0s
Progress: 56% – Elapsed: 0.0s
Progress: 66% – Elapsed: 0.0s
Progress: 75% – Elapsed: 0.0s
Progress: 85% – Elapsed: 0.0s
Progress: 94% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       60.94% |       0.6602 |          0.1000 |
|      10 |          50 |       00:00:00 |       97.66% |       0.0704 |          0.1000 |
|      20 |         100 |       00:00:00 |       99.22% |       0.0246 |          0.0900 |
|      30 |         150 |       00:00:00 |       99.22% |       0.0207 |          0.0810 |
|      40 |         200 |       00:00:00 |       99.22% |       0.0227 |          0.0729 |
|      50 |         250 |       00:00:00 |       99.22% |       0.0207 |          0.0656 |
|      60 |         300 |       00:00:00 |       99.22% |       0.0206 |          0.0590 |
|      70 |         350 |       00:00:00 |       99.22% |       0.0201 |          0.0531 |
|      80 |         400 |       00:00:00 |       99.22% |       0.0199 |          0.0478 |
|      90 |         450 |       00:00:00 |       99.22% |       0.0200 |          0.0430 |
|     100 |         500 |       00:00:00 |       99.22% |       0.0197 |          0.0387 |
|     110 |         550 |       00:00:00 |       99.22% |       0.0196 |          0.0349 |
|     120 |         600 |       00:00:00 |       99.22% |       0.0189 |          0.0314 |
|     130 |         650 |       00:00:00 |       99.22% |       0.0190 |          0.0282 |
|     140 |         700 |       00:00:00 |       99.22% |       0.0188 |          0.0254 |
|     150 |         750 |       00:00:00 |       99.22% |       0.0187 |          0.0229 |
|     160 |         800 |       00:00:01 |       99.22% |       0.0188 |          0.0206 |
|     170 |         850 |       00:00:01 |       99.22% |       0.0188 |          0.0185 |
|     180 |         900 |       00:00:01 |       99.22% |       0.0187 |          0.0167 |
|     190 |         950 |       00:00:01 |       99.22% |       0.0186 |          0.0150 |
|     200 |        1000 |       00:00:01 |       99.22% |       0.0187 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9750, Recall: 1.0000, F1-Score: 0.9873
AUC: 0.9977
Processing dataset: Balsam lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 26 / 26 (100.0%)
[DivideNet] Attempts made: 58 | Failed attempts: 32
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 235
    Train Negative: 470
    Test  Positive: 26
    Test  Negative: 52
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 705 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.1s
Progress: 70% – Elapsed: 0.2s
Progress: 79% – Elapsed: 0.3s
Progress: 89% – Elapsed: 0.3s
Progress: 99% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 78 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Progress: 18% – Elapsed: 0.0s
Progress: 27% – Elapsed: 0.0s
Progress: 36% – Elapsed: 0.0s
Progress: 45% – Elapsed: 0.0s
Progress: 54% – Elapsed: 0.0s
Progress: 63% – Elapsed: 0.0s
Progress: 72% – Elapsed: 0.0s
Progress: 81% – Elapsed: 0.0s
Progress: 90% – Elapsed: 0.0s
Progress: 99% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       31.25% |       0.7338 |          0.1000 |
|      10 |          50 |       00:00:00 |       98.44% |       0.0854 |          0.1000 |
|      20 |         100 |       00:00:00 |       98.44% |       0.0559 |          0.0900 |
|      30 |         150 |       00:00:00 |       97.66% |       0.0537 |          0.0810 |
|      40 |         200 |       00:00:00 |       97.66% |       0.0514 |          0.0729 |
|      50 |         250 |       00:00:00 |       97.66% |       0.0481 |          0.0656 |
|      60 |         300 |       00:00:00 |       97.66% |       0.0512 |          0.0590 |
|      70 |         350 |       00:00:01 |       98.44% |       0.0479 |          0.0531 |
|      80 |         400 |       00:00:01 |       97.66% |       0.0458 |          0.0478 |
|      90 |         450 |       00:00:01 |       97.66% |       0.0456 |          0.0430 |
|     100 |         500 |       00:00:01 |       97.66% |       0.0453 |          0.0387 |
|     110 |         550 |       00:00:01 |       97.66% |       0.0451 |          0.0349 |
|     120 |         600 |       00:00:01 |       97.66% |       0.0449 |          0.0314 |
|     130 |         650 |       00:00:01 |       97.66% |       0.0447 |          0.0282 |
|     140 |         700 |       00:00:02 |       97.66% |       0.0445 |          0.0254 |
|     150 |         750 |       00:00:02 |       97.66% |       0.0444 |          0.0229 |
|     160 |         800 |       00:00:02 |       97.66% |       0.0443 |          0.0206 |
|     170 |         850 |       00:00:02 |       97.66% |       0.0442 |          0.0185 |
|     180 |         900 |       00:00:02 |       97.66% |       0.0441 |          0.0167 |
|     190 |         950 |       00:00:02 |       97.66% |       0.0441 |          0.0150 |
|     200 |        1000 |       00:00:02 |       97.66% |       0.0439 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.35, Precision: 0.9630, Recall: 1.0000, F1-Score: 0.9811
AUC: 0.9896
Processing dataset: Balsam lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 99 / 233 (42.5%)
[DivideNet] Attempts made: 258 | Failed attempts: 159
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 162
    Train Negative: 324
    Test  Positive: 99
    Test  Negative: 198
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 486 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 99% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 297 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 59% – Elapsed: 0.1s
Progress: 68% – Elapsed: 0.1s
Progress: 78% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       64.84% |       0.6817 |          0.1000 |
|      17 |          50 |       00:00:00 |       99.22% |       0.0571 |          0.0900 |
|      34 |         100 |       00:00:00 |      100.00% |       0.0015 |          0.0729 |
|      50 |         150 |       00:00:00 |      100.00% |       0.0007 |          0.0656 |
|      67 |         200 |       00:00:00 |      100.00% |       0.0009 |          0.0531 |
|      84 |         250 |       00:00:00 |      100.00% |       0.0002 |          0.0430 |
|     100 |         300 |       00:00:00 |      100.00% |       0.0003 |          0.0387 |
|     117 |         350 |       00:00:00 |      100.00% |       0.0005 |          0.0314 |
|     134 |         400 |       00:00:00 |      100.00% |       0.0001 |          0.0254 |
|     150 |         450 |       00:00:00 |      100.00% |       0.0002 |          0.0229 |
|     167 |         500 |       00:00:00 |      100.00% |       0.0004 |          0.0185 |
|     184 |         550 |       00:00:00 |      100.00% |       0.0001 |          0.0150 |
|     200 |         600 |       00:00:01 |      100.00% |       0.0002 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.50, Precision: 0.9663, Recall: 0.8687, F1-Score: 0.9149
AUC: 0.9863
Processing dataset: Balsam lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 99 / 220 (45.0%)
[DivideNet] Attempts made: 258 | Failed attempts: 159
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 162
    Train Negative: 324
    Test  Positive: 99
    Test  Negative: 198
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 486 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 40% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.2s
Progress: 99% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 297 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 68% – Elapsed: 0.1s
Progress: 78% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       22.66% |       0.7286 |          0.1000 |
|      17 |          50 |       00:00:00 |      100.00% |       0.0013 |          0.0900 |
|      34 |         100 |       00:00:00 |      100.00% |       0.0004 |          0.0729 |
|      50 |         150 |       00:00:00 |      100.00% |       0.0002 |          0.0656 |
|      67 |         200 |       00:00:00 |      100.00% |       0.0002 |          0.0531 |
|      84 |         250 |       00:00:00 |      100.00% |       0.0002 |          0.0430 |
|     100 |         300 |       00:00:00 |      100.00% |       0.0001 |          0.0387 |
|     117 |         350 |       00:00:00 |      100.00% |       0.0001 |          0.0314 |
|     134 |         400 |       00:00:00 |      100.00% |       0.0001 |          0.0254 |
|     150 |         450 |       00:00:00 |      100.00% |       0.0001 |          0.0229 |
|     167 |         500 |       00:00:00 |      100.00% |   9.8733e-05 |          0.0185 |
|     184 |         550 |       00:00:00 |      100.00% |       0.0001 |          0.0150 |
|     200 |         600 |       00:00:00 |      100.00% |       0.0001 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.35, Precision: 0.9310, Recall: 0.5455, F1-Score: 0.6879
AUC: 0.9389
Processing dataset: Balsam lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 99 / 207 (47.8%)
[DivideNet] Attempts made: 258 | Failed attempts: 159
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 162
    Train Negative: 324
    Test  Positive: 99
    Test  Negative: 198
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 486 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.2s
Progress: 79% – Elapsed: 0.2s
Progress: 89% – Elapsed: 0.3s
Progress: 99% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 297 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.2s
Progress: 68% – Elapsed: 0.2s
Progress: 78% – Elapsed: 0.2s
Progress: 88% – Elapsed: 0.2s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       29.69% |       0.6829 |          0.1000 |
|      17 |          50 |       00:00:00 |      100.00% |       0.0093 |          0.0900 |
|      34 |         100 |       00:00:00 |      100.00% |       0.0040 |          0.0729 |
|      50 |         150 |       00:00:00 |       99.22% |       0.0398 |          0.0656 |
|      67 |         200 |       00:00:00 |      100.00% |       0.0035 |          0.0531 |
|      84 |         250 |       00:00:00 |      100.00% |       0.0030 |          0.0430 |
|     100 |         300 |       00:00:00 |       99.22% |       0.0385 |          0.0387 |
|     117 |         350 |       00:00:00 |      100.00% |       0.0032 |          0.0314 |
|     134 |         400 |       00:00:01 |      100.00% |       0.0028 |          0.0254 |
|     150 |         450 |       00:00:01 |       99.22% |       0.0378 |          0.0229 |
|     167 |         500 |       00:00:01 |      100.00% |       0.0031 |          0.0185 |
|     184 |         550 |       00:00:01 |      100.00% |       0.0027 |          0.0150 |
|     200 |         600 |       00:00:01 |       99.22% |       0.0374 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9762, Recall: 0.8283, F1-Score: 0.8962
AUC: 0.9690
Processing dataset: Balsam lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 98 / 194 (50.5%)
[DivideNet] Attempts made: 258 | Failed attempts: 160
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 163
    Train Negative: 326
    Test  Positive: 98
    Test  Negative: 196
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 489 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.2s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 294 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 99% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       17.19% |       0.7411 |          0.1000 |
|      17 |          50 |       00:00:00 |       89.06% |       0.5260 |          0.0900 |
|      34 |         100 |       00:00:00 |       99.22% |       0.0413 |          0.0729 |
|      50 |         150 |       00:00:00 |      100.00% |       0.0105 |          0.0656 |
|      67 |         200 |       00:00:00 |       97.66% |       0.0816 |          0.0531 |
|      84 |         250 |       00:00:00 |       99.22% |       0.0354 |          0.0430 |
|     100 |         300 |       00:00:00 |      100.00% |       0.0102 |          0.0387 |
|     117 |         350 |       00:00:00 |       97.66% |       0.0809 |          0.0314 |
|     134 |         400 |       00:00:00 |       99.22% |       0.0352 |          0.0254 |
|     150 |         450 |       00:00:00 |      100.00% |       0.0099 |          0.0229 |
|     167 |         500 |       00:00:00 |       97.66% |       0.0805 |          0.0185 |
|     184 |         550 |       00:00:00 |       99.22% |       0.0350 |          0.0150 |
|     200 |         600 |       00:00:00 |      100.00% |       0.0100 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.30, Precision: 0.9762, Recall: 0.8367, F1-Score: 0.9011
AUC: 0.9883
Processing dataset: Balsam lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 98 / 181 (54.1%)
[DivideNet] Attempts made: 258 | Failed attempts: 160
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 163
    Train Negative: 326
    Test  Positive: 98
    Test  Negative: 196
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 489 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.1s
Progress: 49% – Elapsed: 0.1s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 88% – Elapsed: 0.1s
Progress: 98% – Elapsed: 0.2s
Done. Total time: 0.2s
Encoding 294 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.0s
Progress: 30% – Elapsed: 0.0s
Progress: 39% – Elapsed: 0.0s
Progress: 49% – Elapsed: 0.0s
Progress: 59% – Elapsed: 0.1s
Progress: 69% – Elapsed: 0.1s
Progress: 79% – Elapsed: 0.1s
Progress: 89% – Elapsed: 0.1s
Progress: 99% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       85.16% |       0.6674 |          0.1000 |
|      17 |          50 |       00:00:00 |       99.22% |       0.0414 |          0.0900 |
|      34 |         100 |       00:00:00 |      100.00% |       0.0081 |          0.0729 |
|      50 |         150 |       00:00:00 |      100.00% |       0.0050 |          0.0656 |
|      67 |         200 |       00:00:00 |       99.22% |       0.0383 |          0.0531 |
|      84 |         250 |       00:00:00 |      100.00% |       0.0034 |          0.0430 |
|     100 |         300 |       00:00:00 |      100.00% |       0.0041 |          0.0387 |
|     117 |         350 |       00:00:00 |       99.22% |       0.0370 |          0.0314 |
|     134 |         400 |       00:00:00 |      100.00% |       0.0031 |          0.0254 |
|     150 |         450 |       00:00:00 |      100.00% |       0.0038 |          0.0229 |
|     167 |         500 |       00:00:00 |       99.22% |       0.0364 |          0.0185 |
|     184 |         550 |       00:00:00 |      100.00% |       0.0029 |          0.0150 |
|     200 |         600 |       00:00:00 |      100.00% |       0.0037 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9420, Recall: 0.6633, F1-Score: 0.7784
AUC: 0.9435
