Processing dataset: German Creek_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 21 / 71 (29.6%)
[DivideNet] Attempts made: 352 | Failed attempts: 331
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 332
    Train Negative: 664
    Test  Positive: 21
    Test  Negative: 42
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 996 subgraphs (K = 10)...
    "Experiment "    "7"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 332
    Train Negative: 664
    Test  Positive: 21
    Test  Negative: 42
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 996 subgraphs (K = 10)...
    "Experiment "    "2"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 332
    Train Negative: 664
    Test  Positive: 21
    Test  Negative: 42
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 996 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.2s
    "Experiment "    "8"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 332
    Train Negative: 664
    Test  Positive: 21
    Test  Negative: 42
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 996 subgraphs (K = 10)...
    "Experiment "    "5"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 332
    Train Negative: 664
    Test  Positive: 21
    Test  Negative: 42
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 996 subgraphs (K = 10)...
    "Experiment "    "4"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 332
    Train Negative: 664
    Test  Positive: 21
    Test  Negative: 42
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 996 subgraphs (K = 10)...
    "Experiment "    "3"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 332
    Train Negative: 664
    Test  Positive: 21
    Test  Negative: 42
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
    "Experiment "    "6"    " (strategy: "    "random"    ") — Running WLNM..."

Progress: 10% – Elapsed: 0.2s
Progress: 20% – Elapsed: 0.3s
Progress: 10% – Elapsed: 0.1s
Progress: 10% – Elapsed: 0.2s
Progress: 10% – Elapsed: 0.2s
Encoding 996 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.1s
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 332
    Train Negative: 664
    Test  Positive: 21
    Test  Negative: 42
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 996 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.1s
Progress: 10% – Elapsed: 0.2s
Progress: 20% – Elapsed: 0.4s
Progress: 20% – Elapsed: 0.4s
Progress: 20% – Elapsed: 0.2s
Progress: 30% – Elapsed: 0.5s
Progress: 20% – Elapsed: 0.3s
Progress: 20% – Elapsed: 0.3s
Progress: 20% – Elapsed: 0.4s
Progress: 20% – Elapsed: 0.3s
Progress: 30% – Elapsed: 0.3s
Progress: 40% – Elapsed: 0.6s
Progress: 30% – Elapsed: 0.5s
Progress: 30% – Elapsed: 0.6s
Progress: 30% – Elapsed: 0.4s
Progress: 30% – Elapsed: 0.5s
Progress: 30% – Elapsed: 0.4s
Progress: 40% – Elapsed: 0.6s
Progress: 40% – Elapsed: 0.7s
Progress: 30% – Elapsed: 0.4s
Progress: 40% – Elapsed: 0.6s
Progress: 40% – Elapsed: 0.5s
Progress: 50% – Elapsed: 0.8s
Progress: 40% – Elapsed: 0.6s
Progress: 50% – Elapsed: 0.7s
Progress: 40% – Elapsed: 0.7s
Progress: 40% – Elapsed: 0.6s
Progress: 50% – Elapsed: 0.7s
Progress: 60% – Elapsed: 0.9s
Progress: 50% – Elapsed: 0.9s
Progress: 50% – Elapsed: 0.8s
Progress: 70% – Elapsed: 1.2s
Progress: 50% – Elapsed: 0.8s
Progress: 60% – Elapsed: 1.0s
Progress: 60% – Elapsed: 0.8s
Progress: 50% – Elapsed: 0.8s
Progress: 60% – Elapsed: 0.9s
Progress: 50% – Elapsed: 0.7s
Progress: 60% – Elapsed: 0.8s
Progress: 60% – Elapsed: 0.9s
Progress: 70% – Elapsed: 1.1s
Progress: 70% – Elapsed: 1.0s
Progress: 60% – Elapsed: 1.0s
Progress: 70% – Elapsed: 1.1s
Progress: 60% – Elapsed: 0.9s
Progress: 70% – Elapsed: 0.9s
Progress: 80% – Elapsed: 1.3s
Progress: 70% – Elapsed: 1.1s
Progress: 80% – Elapsed: 1.2s
Progress: 80% – Elapsed: 1.1s
Progress: 70% – Elapsed: 1.1s
Progress: 80% – Elapsed: 1.2s
Progress: 70% – Elapsed: 1.1s
Progress: 80% – Elapsed: 1.1s
Progress: 80% – Elapsed: 1.1s
Progress: 80% – Elapsed: 1.2s
Progress: 89% – Elapsed: 1.3s
Progress: 89% – Elapsed: 1.2s
Progress: 80% – Elapsed: 1.2s
Progress: 89% – Elapsed: 1.1s
Progress: 99% – Elapsed: 1.2s
Done. Total time: 1.2s
Encoding 63 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 89% – Elapsed: 1.4s
Progress: 99% – Elapsed: 1.6s
Done. Total time: 1.6s
Encoding 63 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.1s
Progress: 57% – Elapsed: 0.1s
Progress: 89% – Elapsed: 1.4s
Progress: 99% – Elapsed: 1.4s
Progress: 89% – Elapsed: 1.4s
Progress: 89% – Elapsed: 1.4s
Progress: 89% – Elapsed: 1.3s
Progress: 57% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.1s
Progress: 76% – Elapsed: 0.1s
Progress: 86% – Elapsed: 0.1s
Progress: 95% – Elapsed: 0.1s
Done. Total time: 0.1s
Progress: 67% – Elapsed: 0.1s
Progress: 76% – Elapsed: 0.1s
Progress: 86% – Elapsed: 0.1s
Progress: 95% – Elapsed: 0.1s
Done. Total time: 0.1s
Progress: 99% – Elapsed: 1.7s
Progress: 99% – Elapsed: 1.7s
Done. Total time: 1.7s
Encoding 63 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Done. Total time: 1.4s
Encoding 63 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.1s
Progress: 38% – Elapsed: 0.1s
Progress: 76% – Elapsed: 0.1s
Progress: 86% – Elapsed: 0.1s
Progress: 95% – Elapsed: 0.1s
Done. Total time: 0.1s
Progress: 99% – Elapsed: 1.6s
Done. Total time: 1.7s
Encoding 63 subgraphs (K = 10)...
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       50.00% |       0.6921 |          0.1000 |
Done. Total time: 1.7s
Encoding 63 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.2s
Progress: 57% – Elapsed: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       26.56% |       0.7480 |          0.1000 |
Progress: 99% – Elapsed: 1.8s
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.1s
Progress: 29% – Elapsed: 0.1s
Progress: 99% – Elapsed: 1.6s
Done. Total time: 1.7s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       50.78% |       0.7018 |          0.1000 |
Progress: 67% – Elapsed: 0.1s
Progress: 76% – Elapsed: 0.2s
Progress: 86% – Elapsed: 0.2s
Progress: 95% – Elapsed: 0.2s
Progress: 67% – Elapsed: 0.2s
Progress: 76% – Elapsed: 0.3s
Progress: 86% – Elapsed: 0.3s
Progress: 95% – Elapsed: 0.3s
Done. Total time: 0.3s
Done. Total time: 1.9s
Encoding 63 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.1s
Progress: 48% – Elapsed: 0.2s
Progress: 57% – Elapsed: 0.2s
Progress: 67% – Elapsed: 0.2s
Progress: 76% – Elapsed: 0.2s
Progress: 86% – Elapsed: 0.2s
Encoding 63 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.1s
Progress: 48% – Elapsed: 0.1s
Progress: 57% – Elapsed: 0.1s
Progress: 67% – Elapsed: 0.1s
Progress: 76% – Elapsed: 0.1s
Progress: 86% – Elapsed: 0.2s
Done. Total time: 0.2s
Progress: 57% – Elapsed: 0.1s
Progress: 67% – Elapsed: 0.1s
Progress: 76% – Elapsed: 0.1s
Progress: 95% – Elapsed: 0.2s
Done. Total time: 0.2s
Progress: 95% – Elapsed: 0.3s
Done. Total time: 0.3s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
Progress: 86% – Elapsed: 0.2s
Progress: 95% – Elapsed: 0.2s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       45.31% |       0.7127 |          0.1000 |
|       8 |          50 |       00:00:00 |       90.62% |       0.2248 |          0.1000 |
|       1 |           1 |       00:00:00 |       39.84% |       0.6995 |          0.1000 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       58.59% |       0.6941 |          0.1000 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       8 |          50 |       00:00:00 |       87.50% |       0.2790 |          0.1000 |
|       8 |          50 |       00:00:00 |       91.41% |       0.2152 |          0.1000 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       54.69% |       0.6731 |          0.1000 |
|       1 |           1 |       00:00:00 |       51.56% |       0.6860 |          0.1000 |
|       8 |          50 |       00:00:00 |       90.62% |       0.2240 |          0.1000 |
|      15 |         100 |       00:00:00 |       92.97% |       0.1942 |          0.0900 |
|       8 |          50 |       00:00:00 |       76.56% |       0.2963 |          0.1000 |
|       8 |          50 |       00:00:00 |       96.09% |       0.1657 |          0.1000 |
|       8 |          50 |       00:00:00 |       89.06% |       0.3000 |          0.1000 |
|       8 |          50 |       00:00:00 |       89.84% |       0.2854 |          0.1000 |
|      15 |         100 |       00:00:00 |       92.19% |       0.1867 |          0.0900 |
|      15 |         100 |       00:00:00 |       94.53% |       0.1362 |          0.0900 |
|      15 |         100 |       00:00:00 |       93.75% |       0.1638 |          0.0900 |
|      15 |         100 |       00:00:00 |       94.53% |       0.1434 |          0.0900 |
|      22 |         150 |       00:00:01 |       93.75% |       0.1627 |          0.0810 |
|      15 |         100 |       00:00:00 |       92.19% |       0.1831 |          0.0900 |
|      22 |         150 |       00:00:01 |       96.09% |       0.1105 |          0.0810 |
|      22 |         150 |       00:00:01 |       89.84% |       0.2303 |          0.0810 |
|      22 |         150 |       00:00:01 |       96.09% |       0.1401 |          0.0810 |
|      15 |         100 |       00:00:00 |       90.62% |       0.1987 |          0.0900 |
|      15 |         100 |       00:00:00 |       92.97% |       0.2082 |          0.0900 |
|      29 |         200 |       00:00:01 |       92.97% |       0.1696 |          0.0810 |
|      22 |         150 |       00:00:01 |       92.97% |       0.1861 |          0.0810 |
|      22 |         150 |       00:00:01 |       94.53% |       0.1485 |          0.0810 |
|      22 |         150 |       00:00:01 |       89.06% |       0.2318 |          0.0810 |
|      22 |         150 |       00:00:00 |       93.75% |       0.1707 |          0.0810 |
|      29 |         200 |       00:00:01 |       93.75% |       0.1626 |          0.0810 |
|      36 |         250 |       00:00:01 |       89.84% |       0.2072 |          0.0729 |
|      36 |         250 |       00:00:01 |       95.31% |       0.1251 |          0.0729 |
|      29 |         200 |       00:00:01 |       92.97% |       0.1773 |          0.0810 |
|      29 |         200 |       00:00:01 |       92.97% |       0.1773 |          0.0810 |
|      29 |         200 |       00:00:01 |       90.62% |       0.2025 |          0.0810 |
|      36 |         250 |       00:00:01 |       96.88% |       0.1147 |          0.0729 |
|      29 |         200 |       00:00:01 |       92.97% |       0.1765 |          0.0810 |
|      36 |         250 |       00:00:01 |       94.53% |       0.1496 |          0.0729 |
|      29 |         200 |       00:00:01 |       90.62% |       0.2028 |          0.0810 |
|      29 |         200 |       00:00:01 |       95.31% |       0.1164 |          0.0810 |
|      43 |         300 |       00:00:02 |       90.62% |       0.2052 |          0.0656 |
|      36 |         250 |       00:00:01 |       92.97% |       0.1733 |          0.0729 |
|      36 |         250 |       00:00:01 |       94.53% |       0.1271 |          0.0729 |
|      36 |         250 |       00:00:01 |       93.75% |       0.1547 |          0.0729 |
|      43 |         300 |       00:00:02 |       92.97% |       0.1726 |          0.0656 |
|      50 |         350 |       00:00:02 |       94.53% |       0.1558 |          0.0656 |
|      43 |         300 |       00:00:01 |       92.19% |       0.1753 |          0.0656 |
|      43 |         300 |       00:00:02 |       95.31% |       0.1423 |          0.0656 |
|      36 |         250 |       00:00:01 |       93.75% |       0.1606 |          0.0729 |
|      58 |         400 |       00:00:02 |       92.97% |       0.1652 |          0.0590 |
|      50 |         350 |       00:00:02 |       92.19% |       0.1908 |          0.0656 |
|      43 |         300 |       00:00:02 |       94.53% |       0.1593 |          0.0656 |
|      43 |         300 |       00:00:02 |       89.06% |       0.2416 |          0.0656 |
|      43 |         300 |       00:00:02 |       96.88% |       0.1240 |          0.0656 |
|      50 |         350 |       00:00:02 |       93.75% |       0.1561 |          0.0656 |
|      50 |         350 |       00:00:02 |       92.97% |       0.1725 |          0.0656 |
|      43 |         300 |       00:00:02 |       96.09% |       0.1154 |          0.0656 |
|      65 |         450 |       00:00:02 |       92.97% |       0.1716 |          0.0531 |
|      58 |         400 |       00:00:02 |       92.97% |       0.1771 |          0.0590 |
|      50 |         350 |       00:00:02 |       91.41% |       0.1867 |          0.0656 |
|      58 |         400 |       00:00:02 |       93.75% |       0.1426 |          0.0590 |
|      50 |         350 |       00:00:02 |       96.88% |       0.1232 |          0.0656 |
|      50 |         350 |       00:00:02 |       92.19% |       0.1701 |          0.0656 |
|      50 |         350 |       00:00:02 |       92.19% |       0.2326 |          0.0656 |
|      72 |         500 |       00:00:03 |       89.84% |       0.2194 |          0.0478 |
|      58 |         400 |       00:00:02 |       91.41% |       0.2026 |          0.0590 |
|      58 |         400 |       00:00:02 |       91.41% |       0.1954 |          0.0590 |
|      65 |         450 |       00:00:03 |       93.75% |       0.1651 |          0.0531 |
|      58 |         400 |       00:00:02 |       96.09% |       0.1297 |          0.0590 |
|      58 |         400 |       00:00:02 |       91.41% |       0.1879 |          0.0590 |
|      65 |         450 |       00:00:03 |       93.75% |       0.1520 |          0.0531 |
|      58 |         400 |       00:00:02 |       92.19% |       0.1825 |          0.0590 |
|      79 |         550 |       00:00:03 |       93.75% |       0.1618 |          0.0478 |
|      65 |         450 |       00:00:03 |       94.53% |       0.1308 |          0.0531 |
|      65 |         450 |       00:00:03 |       94.53% |       0.1396 |          0.0531 |
|      72 |         500 |       00:00:03 |       93.75% |       0.1628 |          0.0478 |
|      65 |         450 |       00:00:03 |       92.97% |       0.1631 |          0.0531 |
|      72 |         500 |       00:00:03 |       96.09% |       0.1096 |          0.0478 |
|      65 |         450 |       00:00:03 |       92.97% |       0.1664 |          0.0531 |
|      65 |         450 |       00:00:03 |       93.75% |       0.1844 |          0.0531 |
|      86 |         600 |       00:00:03 |       89.84% |       0.2049 |          0.0430 |
|      79 |         550 |       00:00:04 |       92.97% |       0.1688 |          0.0478 |
|      72 |         500 |       00:00:03 |       96.09% |       0.1347 |          0.0478 |
|      72 |         500 |       00:00:03 |       89.06% |       0.2314 |          0.0478 |
|      72 |         500 |       00:00:03 |       92.19% |       0.1851 |          0.0478 |
|      79 |         550 |       00:00:04 |       90.62% |       0.2029 |          0.0478 |
|      72 |         500 |       00:00:03 |       94.53% |       0.1525 |          0.0478 |
|      72 |         500 |       00:00:03 |       93.75% |       0.1604 |          0.0478 |
|      93 |         650 |       00:00:04 |       92.97% |       0.1719 |          0.0387 |
|      86 |         600 |       00:00:04 |       95.31% |       0.1223 |          0.0430 |
|      79 |         550 |       00:00:04 |       92.97% |       0.1763 |          0.0478 |
|      79 |         550 |       00:00:04 |       93.75% |       0.1609 |          0.0478 |
|      86 |         600 |       00:00:04 |       94.53% |       0.1486 |          0.0430 |
|      79 |         550 |       00:00:04 |       92.97% |       0.1624 |          0.0478 |
|      86 |         600 |       00:00:04 |       96.88% |       0.1117 |          0.0430 |
|      79 |         550 |       00:00:04 |       92.97% |       0.1738 |          0.0478 |
|      86 |         600 |       00:00:04 |       93.75% |       0.1534 |          0.0430 |
|      79 |         550 |       00:00:04 |       96.09% |       0.1096 |          0.0478 |
|     100 |         700 |       00:00:04 |       94.53% |       0.1551 |          0.0387 |
|      93 |         650 |       00:00:04 |       91.41% |       0.1958 |          0.0387 |
|      86 |         600 |       00:00:04 |       92.97% |       0.1729 |          0.0430 |
|      93 |         650 |       00:00:04 |       94.53% |       0.1585 |          0.0387 |
|      93 |         650 |       00:00:04 |       95.31% |       0.1427 |          0.0387 |
|      86 |         600 |       00:00:04 |       95.31% |       0.1216 |          0.0430 |
|      93 |         650 |       00:00:04 |       96.88% |       0.1294 |          0.0387 |
|      86 |         600 |       00:00:04 |       93.75% |       0.1551 |          0.0430 |
|     108 |         750 |       00:00:04 |       92.97% |       0.1648 |          0.0349 |
|      93 |         650 |       00:00:04 |       92.97% |       0.1718 |          0.0387 |
|      93 |         650 |       00:00:04 |       89.06% |       0.2479 |          0.0387 |
|      93 |         650 |       00:00:04 |       96.09% |       0.1126 |          0.0387 |
|     115 |         800 |       00:00:05 |       92.97% |       0.1712 |          0.0314 |
|     100 |         700 |       00:00:05 |       92.19% |       0.1826 |          0.0387 |
|     108 |         750 |       00:00:05 |       92.97% |       0.1763 |          0.0349 |
|     100 |         700 |       00:00:05 |       93.75% |       0.1535 |          0.0387 |
|     100 |         700 |       00:00:04 |       91.41% |       0.1849 |          0.0387 |
|     100 |         700 |       00:00:05 |       92.97% |       0.1734 |          0.0387 |
|     100 |         700 |       00:00:04 |       92.19% |       0.1728 |          0.0387 |
|     108 |         750 |       00:00:05 |       93.75% |       0.1423 |          0.0349 |
|     108 |         750 |       00:00:05 |       91.41% |       0.1942 |          0.0349 |
|     100 |         700 |       00:00:04 |       92.19% |       0.1831 |          0.0387 |
|     122 |         850 |       00:00:05 |       89.84% |       0.2191 |          0.0282 |
|     108 |         750 |       00:00:05 |       92.19% |       0.1803 |          0.0349 |
|     100 |         700 |       00:00:05 |       96.88% |       0.1142 |          0.0387 |
|     108 |         750 |       00:00:05 |       92.19% |       0.1798 |          0.0349 |
|     115 |         800 |       00:00:05 |       93.75% |       0.1645 |          0.0314 |
|     108 |         750 |       00:00:05 |       91.41% |       0.1951 |          0.0349 |
|     108 |         750 |       00:00:05 |       96.09% |       0.1325 |          0.0349 |
|     115 |         800 |       00:00:05 |       94.53% |       0.1391 |          0.0314 |
|     129 |         900 |       00:00:05 |       93.75% |       0.1618 |          0.0282 |
|     115 |         800 |       00:00:05 |       93.75% |       0.1518 |          0.0314 |
|     122 |         850 |       00:00:06 |       93.75% |       0.1622 |          0.0282 |
|     115 |         800 |       00:00:05 |       94.53% |       0.1299 |          0.0314 |
|     115 |         800 |       00:00:05 |       92.97% |       0.1627 |          0.0314 |
|     115 |         800 |       00:00:05 |       92.19% |       0.1670 |          0.0314 |
|     122 |         850 |       00:00:05 |       89.06% |       0.2272 |          0.0282 |
|     115 |         800 |       00:00:05 |       93.75% |       0.1783 |          0.0314 |
|     136 |         950 |       00:00:06 |       89.84% |       0.2053 |          0.0254 |
|     129 |         900 |       00:00:06 |       92.97% |       0.1687 |          0.0282 |
|     136 |         950 |       00:00:06 |       95.31% |       0.1216 |          0.0254 |
|     122 |         850 |       00:00:05 |       96.09% |       0.1316 |          0.0282 |
|     122 |         850 |       00:00:05 |       92.19% |       0.1819 |          0.0282 |
|     122 |         850 |       00:00:05 |       93.75% |       0.1590 |          0.0282 |
|     122 |         850 |       00:00:06 |       96.09% |       0.1096 |          0.0282 |
|     122 |         850 |       00:00:05 |       94.53% |       0.1434 |          0.0282 |
|     129 |         900 |       00:00:05 |       92.19% |       0.1766 |          0.0282 |
|     143 |        1000 |       00:00:06 |       92.97% |       0.1712 |          0.0229 |
|     143 |        1000 |       00:00:06 |       91.41% |       0.1947 |          0.0229 |
|     129 |         900 |       00:00:06 |       92.97% |       0.1606 |          0.0282 |
|     129 |         900 |       00:00:06 |       92.97% |       0.1607 |          0.0282 |
|     136 |         950 |       00:00:06 |       92.97% |       0.1727 |          0.0254 |
|     129 |         900 |       00:00:06 |       90.62% |       0.2029 |          0.0282 |
|     129 |         900 |       00:00:06 |       92.97% |       0.1731 |          0.0282 |
|     136 |         950 |       00:00:06 |       93.75% |       0.1532 |          0.0254 |
|     129 |         900 |       00:00:05 |       96.09% |       0.1079 |          0.0282 |
|     136 |         950 |       00:00:06 |       93.75% |       0.1549 |          0.0254 |
|     150 |        1050 |       00:00:06 |       94.53% |       0.1547 |          0.0229 |
|     150 |        1050 |       00:00:06 |       92.19% |       0.1823 |          0.0229 |
|     136 |         950 |       00:00:06 |       94.53% |       0.1480 |          0.0254 |
|     143 |        1000 |       00:00:06 |       92.19% |       0.1714 |          0.0229 |
|     143 |        1000 |       00:00:06 |       94.53% |       0.1581 |          0.0229 |
|     136 |         950 |       00:00:06 |       96.88% |       0.1132 |          0.0254 |
|     136 |         950 |       00:00:06 |       95.31% |       0.1212 |          0.0254 |
|     143 |        1000 |       00:00:06 |       96.88% |       0.1229 |          0.0229 |
|     143 |        1000 |       00:00:06 |       96.09% |       0.1134 |          0.0229 |
|     158 |        1100 |       00:00:07 |       92.97% |       0.1648 |          0.0206 |
|     158 |        1100 |       00:00:07 |       92.97% |       0.1762 |          0.0206 |
|     150 |        1050 |       00:00:06 |       91.41% |       0.1847 |          0.0229 |
|     143 |        1000 |       00:00:07 |       95.31% |       0.1417 |          0.0229 |
|     143 |        1000 |       00:00:06 |       89.06% |       0.2332 |          0.0229 |
|     150 |        1050 |       00:00:06 |       92.19% |       0.1685 |          0.0229 |
|     165 |        1150 |       00:00:07 |       92.97% |       0.1711 |          0.0185 |
|     165 |        1150 |       00:00:07 |       93.75% |       0.1644 |          0.0185 |
|     150 |        1050 |       00:00:06 |       93.75% |       0.1534 |          0.0229 |
|     150 |        1050 |       00:00:07 |       92.97% |       0.1716 |          0.0229 |
|     158 |        1100 |       00:00:06 |       92.19% |       0.1857 |          0.0206 |
|     150 |        1050 |       00:00:06 |       92.19% |       0.1802 |          0.0229 |
|     172 |        1200 |       00:00:07 |       89.84% |       0.2189 |          0.0167 |
|     172 |        1200 |       00:00:07 |       93.75% |       0.1621 |          0.0167 |
|     158 |        1100 |       00:00:07 |       91.41% |       0.1934 |          0.0206 |
|     158 |        1100 |       00:00:07 |       92.19% |       0.1801 |          0.0206 |
|     158 |        1100 |       00:00:07 |       93.75% |       0.1417 |          0.0206 |
|     150 |        1050 |       00:00:07 |       96.09% |       0.1195 |          0.0229 |
|     165 |        1150 |       00:00:07 |       94.53% |       0.1390 |          0.0185 |
|     158 |        1100 |       00:00:06 |       92.19% |       0.1782 |          0.0206 |
|     179 |        1250 |       00:00:07 |       93.75% |       0.1616 |          0.0167 |
|     179 |        1250 |       00:00:07 |       92.97% |       0.1687 |          0.0167 |
|     165 |        1150 |       00:00:07 |       94.53% |       0.1299 |          0.0185 |
|     165 |        1150 |       00:00:07 |       92.97% |       0.1627 |          0.0185 |
|     158 |        1100 |       00:00:07 |       97.66% |       0.1202 |          0.0206 |
|     172 |        1200 |       00:00:07 |       89.06% |       0.2309 |          0.0167 |
|     165 |        1150 |       00:00:07 |       93.75% |       0.1771 |          0.0185 |
|     165 |        1150 |       00:00:08 |       93.75% |       0.1516 |          0.0185 |
|     186 |        1300 |       00:00:08 |       89.84% |       0.2050 |          0.0150 |
|     172 |        1200 |       00:00:07 |       92.19% |       0.1812 |          0.0167 |
|     165 |        1150 |       00:00:07 |       92.97% |       0.1642 |          0.0185 |
|     179 |        1250 |       00:00:07 |       92.97% |       0.1760 |          0.0167 |
|     172 |        1200 |       00:00:07 |       93.75% |       0.1586 |          0.0167 |
|     186 |        1300 |       00:00:08 |       95.31% |       0.1215 |          0.0150 |
|     172 |        1200 |       00:00:07 |       96.09% |       0.1306 |          0.0167 |
|     179 |        1250 |       00:00:08 |       92.97% |       0.1603 |          0.0167 |
|     172 |        1200 |       00:00:08 |       96.09% |       0.1096 |          0.0167 |
|     193 |        1350 |       00:00:08 |       92.97% |       0.1711 |          0.0135 |
|     193 |        1350 |       00:00:08 |       91.41% |       0.1947 |          0.0135 |
|     179 |        1250 |       00:00:08 |       92.97% |       0.1605 |          0.0167 |
|     179 |        1250 |       00:00:08 |       90.62% |       0.2027 |          0.0167 |
|     172 |        1200 |       00:00:07 |       94.53% |       0.1429 |          0.0167 |
|     186 |        1300 |       00:00:08 |       93.75% |       0.1531 |          0.0150 |
|     179 |        1250 |       00:00:07 |       96.09% |       0.1074 |          0.0167 |
|     200 |        1400 |       00:00:08 |       94.53% |       0.1544 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.3333, Recall: 0.1429, F1-Score: 0.2000
AUC: 0.8084
|     200 |        1400 |       00:00:08 |       92.19% |       0.1819 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     186 |        1300 |       00:00:08 |       94.53% |       0.1472 |          0.0150 |
|     186 |        1300 |       00:00:08 |       92.97% |       0.1726 |          0.0150 |
|     179 |        1250 |       00:00:08 |       92.97% |       0.1732 |          0.0167 |
|     186 |        1300 |       00:00:08 |       93.75% |       0.1548 |          0.0150 |
Best Threshold: 0.80, Precision: 1.0000, Recall: 0.6667, F1-Score: 0.8000
AUC: 0.9048
|     193 |        1350 |       00:00:08 |       92.97% |       0.1713 |          0.0135 |
|     186 |        1300 |       00:00:08 |       96.88% |       0.1127 |          0.0150 |
|     186 |        1300 |       00:00:08 |       95.31% |       0.1203 |          0.0150 |
|     193 |        1350 |       00:00:08 |       96.88% |       0.1206 |          0.0135 |
|     193 |        1350 |       00:00:08 |       96.09% |       0.1133 |          0.0135 |
  Columns 1 through 4

    "Experiment "    "10"    " (strategy: "    "random"

  Column 5

    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 332
    Train Negative: 664
    Test  Positive: 21
    Test  Negative: 42
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 996 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.1s
Progress: 20% – Elapsed: 0.2s
|     193 |        1350 |       00:00:08 |       94.53% |       0.1580 |          0.0135 |
|     193 |        1350 |       00:00:09 |       95.31% |       0.1414 |          0.0135 |
|     200 |        1400 |       00:00:08 |       92.19% |       0.1692 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.80, Precision: 1.0000, Recall: 0.7619, F1-Score: 0.8649
AUC: 0.9014
|     200 |        1400 |       00:00:08 |       93.75% |       0.1531 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     200 |        1400 |       00:00:08 |       91.41% |       0.1842 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.80, Precision: 1.0000, Recall: 0.8095, F1-Score: 0.8947
AUC: 0.9252
|     193 |        1350 |       00:00:08 |       89.06% |       0.2302 |          0.0135 |
|     200 |        1400 |       00:00:08 |       92.19% |       0.1793 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.85, Precision: 1.0000, Recall: 0.7619, F1-Score: 0.8649
AUC: 0.9002
|     200 |        1400 |       00:00:09 |       92.97% |       0.1714 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.85, Precision: 1.0000, Recall: 0.7143, F1-Score: 0.8333
AUC: 0.8912
Progress: 30% – Elapsed: 0.6s
    "Experiment "    "9"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 332
    Train Negative: 664
    Test  Positive: 21
    Test  Negative: 42
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 996 subgraphs (K = 10)...
Best Threshold: 0.85, Precision: 1.0000, Recall: 0.7619, F1-Score: 0.8649
AUC: 0.9082
|     200 |        1400 |       00:00:09 |       96.88% |       0.1137 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Progress: 40% – Elapsed: 0.7s
Progress: 10% – Elapsed: 0.1s
Best Threshold: 0.85, Precision: 1.0000, Recall: 0.7619, F1-Score: 0.8649
AUC: 0.9229
Progress: 50% – Elapsed: 0.8s
Progress: 60% – Elapsed: 0.8s
Progress: 70% – Elapsed: 0.9s
Progress: 80% – Elapsed: 1.0s
Progress: 20% – Elapsed: 0.2s
Progress: 30% – Elapsed: 0.3s
Progress: 89% – Elapsed: 1.0s
Progress: 40% – Elapsed: 0.3s
Progress: 50% – Elapsed: 0.4s
Progress: 60% – Elapsed: 0.4s
Progress: 99% – Elapsed: 1.1s
Done. Total time: 1.1s
Encoding 63 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 76% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.0s
Progress: 95% – Elapsed: 0.0s
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       66.41% |       0.6681 |          0.1000 |
Progress: 70% – Elapsed: 0.5s
Progress: 80% – Elapsed: 0.6s
Progress: 89% – Elapsed: 0.6s
Progress: 99% – Elapsed: 0.7s
Done. Total time: 0.7s
Encoding 63 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.0s
Progress: 48% – Elapsed: 0.0s
Progress: 57% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 76% – Elapsed: 0.0s
Progress: 86% – Elapsed: 0.0s
Progress: 95% – Elapsed: 0.0s
Done. Total time: 0.0s
|       8 |          50 |       00:00:00 |       89.06% |       0.2905 |          0.1000 |
|      15 |         100 |       00:00:00 |       87.50% |       0.2551 |          0.0900 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       71.09% |       0.6686 |          0.1000 |
|      22 |         150 |       00:00:00 |       89.84% |       0.2131 |          0.0810 |
|       8 |          50 |       00:00:00 |       92.19% |       0.2162 |          0.1000 |
|      15 |         100 |       00:00:00 |       90.62% |       0.2275 |          0.0900 |
|      29 |         200 |       00:00:00 |       93.75% |       0.1445 |          0.0810 |
|      36 |         250 |       00:00:00 |       95.31% |       0.1332 |          0.0729 |
|      22 |         150 |       00:00:00 |       90.62% |       0.2324 |          0.0810 |
|      43 |         300 |       00:00:00 |       97.66% |       0.0987 |          0.0656 |
|      29 |         200 |       00:00:00 |       93.75% |       0.1683 |          0.0810 |
|      36 |         250 |       00:00:00 |       91.41% |       0.1879 |          0.0729 |
|      50 |         350 |       00:00:00 |       94.53% |       0.1549 |          0.0656 |
|      58 |         400 |       00:00:00 |       90.62% |       0.2103 |          0.0590 |
|      43 |         300 |       00:00:00 |       92.19% |       0.1777 |          0.0656 |
|      65 |         450 |       00:00:01 |       88.28% |       0.2406 |          0.0531 |
|      50 |         350 |       00:00:00 |       95.31% |       0.1516 |          0.0656 |
|      58 |         400 |       00:00:00 |       92.97% |       0.1710 |          0.0590 |
|      72 |         500 |       00:00:01 |       89.84% |       0.2168 |          0.0478 |
|      79 |         550 |       00:00:01 |       94.53% |       0.1322 |          0.0478 |
|      65 |         450 |       00:00:01 |       93.75% |       0.1527 |          0.0531 |
|      86 |         600 |       00:00:01 |       95.31% |       0.1292 |          0.0430 |
|      72 |         500 |       00:00:01 |       91.41% |       0.2034 |          0.0478 |
|      79 |         550 |       00:00:01 |       93.75% |       0.1674 |          0.0478 |
|      93 |         650 |       00:00:01 |       97.66% |       0.0970 |          0.0387 |
|     100 |         700 |       00:00:01 |       94.53% |       0.1540 |          0.0387 |
|      86 |         600 |       00:00:01 |       91.41% |       0.1926 |          0.0430 |
|     108 |         750 |       00:00:01 |       90.62% |       0.2104 |          0.0349 |
|     115 |         800 |       00:00:01 |       88.28% |       0.2404 |          0.0314 |
|      93 |         650 |       00:00:01 |       93.75% |       0.1493 |          0.0387 |
|     100 |         700 |       00:00:01 |       95.31% |       0.1441 |          0.0387 |
|     108 |         750 |       00:00:01 |       92.97% |       0.1706 |          0.0349 |
|     122 |         850 |       00:00:02 |       89.84% |       0.2164 |          0.0282 |
|     129 |         900 |       00:00:02 |       94.53% |       0.1317 |          0.0282 |
|     115 |         800 |       00:00:02 |       93.75% |       0.1532 |          0.0314 |
|     136 |         950 |       00:00:02 |       95.31% |       0.1285 |          0.0254 |
|     143 |        1000 |       00:00:02 |       97.66% |       0.0965 |          0.0229 |
|     122 |         850 |       00:00:02 |       91.41% |       0.2031 |          0.0282 |
|     129 |         900 |       00:00:02 |       93.75% |       0.1619 |          0.0282 |
|     136 |         950 |       00:00:02 |       91.41% |       0.1877 |          0.0254 |
|     150 |        1050 |       00:00:02 |       94.53% |       0.1538 |          0.0229 |
|     158 |        1100 |       00:00:02 |       90.62% |       0.2100 |          0.0206 |
|     143 |        1000 |       00:00:02 |       93.75% |       0.1492 |          0.0229 |
|     165 |        1150 |       00:00:02 |       88.28% |       0.2403 |          0.0185 |
|     150 |        1050 |       00:00:02 |       95.31% |       0.1425 |          0.0229 |
|     158 |        1100 |       00:00:02 |       92.97% |       0.1712 |          0.0206 |
|     172 |        1200 |       00:00:02 |       89.84% |       0.2162 |          0.0167 |
|     179 |        1250 |       00:00:03 |       94.53% |       0.1316 |          0.0167 |
|     165 |        1150 |       00:00:02 |       93.75% |       0.1519 |          0.0185 |
|     186 |        1300 |       00:00:03 |       95.31% |       0.1280 |          0.0150 |
|     172 |        1200 |       00:00:03 |       91.41% |       0.2028 |          0.0167 |
|     179 |        1250 |       00:00:03 |       93.75% |       0.1616 |          0.0167 |
|     193 |        1350 |       00:00:03 |       97.66% |       0.0959 |          0.0135 |
|     200 |        1400 |       00:00:03 |       94.53% |       0.1535 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.80, Precision: 0.9412, Recall: 0.7619, F1-Score: 0.8421
AUC: 0.8878
|     186 |        1300 |       00:00:03 |       91.41% |       0.1875 |          0.0150 |
|     193 |        1350 |       00:00:03 |       93.75% |       0.1492 |          0.0135 |
|     200 |        1400 |       00:00:03 |       95.31% |       0.1418 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.80, Precision: 1.0000, Recall: 0.8095, F1-Score: 0.8947
AUC: 0.8673
