Processing dataset: L3P2_tax_mass
    "Processing with K …"    "10"    " using strategy: "    "random"

    "Experiment "    "6"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: Not enough negative links. Reducing k...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',131,0)">line 131</a>)
[sample_neg] Final link counts:
    Train Positive: 80
    Train Negative: 80
    Test  Positive: 20
    Test  Negative: 20
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 160 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.1s
Encoding link 16 of 160: (3,5)
Progress: 20% – Elapsed: 0.1s
Encoding link 32 of 160: (7,10)
Progress: 30% – Elapsed: 0.1s
Encoding link 48 of 160: (3,14)
    "Experiment "    "2"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: Not enough negative links. Reducing k...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',131,0)">line 131</a>)
[sample_neg] Final link counts:
    Train Positive: 80
    Train Negative: 80
    Test  Positive: 20
    Test  Negative: 20
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 160 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 16 of 160: (3,5)
Progress: 20% – Elapsed: 0.0s
Encoding link 32 of 160: (7,10)
Progress: 30% – Elapsed: 0.0s
Encoding link 48 of 160: (3,14)
    "Experiment "    "5"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: Not enough negative links. Reducing k...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',131,0)">line 131</a>)
[sample_neg] Final link counts:
    Train Positive: 80
    Train Negative: 80
    Test  Positive: 20
    Test  Negative: 20
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 160 subgraphs (K = 10)...
    "Experiment "    "3"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: Not enough negative links. Reducing k...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',131,0)">line 131</a>)
[sample_neg] Final link counts:
    Train Positive: 80
    Train Negative: 80
    Test  Positive: 20
    Test  Negative: 20
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 160 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.1s
Encoding link 16 of 160: (3,5)
Progress: 20% – Elapsed: 0.1s
Encoding link 32 of 160: (7,10)
Progress: 30% – Elapsed: 0.1s
Encoding link 48 of 160: (3,14)
Progress: 40% – Elapsed: 0.1s
Encoding link 64 of 160: (20,17)
    "Experiment "    "4"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: Not enough negative links. Reducing k...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',131,0)">line 131</a>)
[sample_neg] Final link counts:
    Train Positive: 80
    Train Negative: 80
    Test  Positive: 20
    Test  Negative: 20
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 160 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 16 of 160: (3,5)
Progress: 20% – Elapsed: 0.1s
Encoding link 32 of 160: (7,10)
Progress: 30% – Elapsed: 0.1s
Encoding link 48 of 160: (3,14)
Progress: 40% – Elapsed: 0.1s
Encoding link 64 of 160: (20,17)
Progress: 50% – Elapsed: 0.1s
Encoding link 80 of 160: (21,23)
Progress: 60% – Elapsed: 0.1s
Encoding link 96 of 160: (3,9)
Progress: 70% – Elapsed: 0.1s
Encoding link 112 of 160: (21,8)
Progress: 80% – Elapsed: 0.1s
Encoding link 128 of 160: (12,4)
Progress: 90% – Elapsed: 0.2s
Encoding link 144 of 160: (18,13)
Progress: 100% – Elapsed: 0.2s
Encoding link 160 of 160: (8,3)
Done. Total time: 0.2s
Encoding 40 subgraphs (K = 10)...
    "Experiment "    "8"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: Not enough negative links. Reducing k...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',131,0)">line 131</a>)
[sample_neg] Final link counts:
    Train Positive: 80
    Train Negative: 80
    Test  Positive: 20
    Test  Negative: 20
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 160 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 16 of 160: (3,5)
Progress: 20% – Elapsed: 0.0s
Encoding link 32 of 160: (7,10)
Progress: 30% – Elapsed: 0.0s
Encoding link 48 of 160: (3,14)
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: Not enough negative links. Reducing k...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',131,0)">line 131</a>)
[sample_neg] Final link counts:
    Train Positive: 80
    Train Negative: 80
    Test  Positive: 20
    Test  Negative: 20
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 160 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 16 of 160: (3,5)
Progress: 20% – Elapsed: 0.0s
Encoding link 32 of 160: (7,10)
Progress: 30% – Elapsed: 0.1s
Encoding link 48 of 160: (3,14)
    "Experiment "    "7"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: Not enough negative links. Reducing k...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',131,0)">line 131</a>)
[sample_neg] Final link counts:
    Train Positive: 80
    Train Negative: 80
    Test  Positive: 20
    Test  Negative: 20
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 160 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 16 of 160: (3,5)
Progress: 20% – Elapsed: 0.1s
Encoding link 32 of 160: (7,10)
Progress: 40% – Elapsed: 0.1s
Encoding link 64 of 160: (20,17)
Progress: 50% – Elapsed: 0.1s
Encoding link 80 of 160: (21,23)
Progress: 60% – Elapsed: 0.1s
Encoding link 96 of 160: (18,22)
Progress: 70% – Elapsed: 0.2s
Encoding link 112 of 160: (12,18)
Progress: 80% – Elapsed: 0.2s
Encoding link 128 of 160: (18,8)
Progress: 90% – Elapsed: 0.2s
Encoding link 144 of 160: (22,12)
Progress: 100% – Elapsed: 0.2s
Encoding link 160 of 160: (9,12)
Done. Total time: 0.2s
Encoding 40 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 4 of 40: (22,1)
Progress: 20% – Elapsed: 0.0s
Encoding link 8 of 40: (6,11)
Progress: 30% – Elapsed: 0.0s
Encoding link 12 of 40: (11,14)
Progress: 40% – Elapsed: 0.2s
Encoding link 64 of 160: (20,17)
Progress: 50% – Elapsed: 0.2s
Encoding link 80 of 160: (21,23)
Progress: 60% – Elapsed: 0.2s
Encoding link 96 of 160: (22,9)
Progress: 70% – Elapsed: 0.2s
Encoding link 112 of 160: (13,12)
Progress: 80% – Elapsed: 0.2s
Encoding link 128 of 160: (18,12)
Progress: 90% – Elapsed: 0.2s
Encoding link 144 of 160: (4,18)
Progress: 100% – Elapsed: 0.2s
Encoding link 160 of 160: (9,7)
Done. Total time: 0.2s
Encoding 40 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.1s
Encoding link 16 of 160: (3,5)
Progress: 20% – Elapsed: 0.1s
Encoding link 32 of 160: (7,10)
Progress: 30% – Elapsed: 0.1s
Encoding link 48 of 160: (3,14)
Progress: 40% – Elapsed: 0.1s
Encoding link 64 of 160: (20,17)
Progress: 50% – Elapsed: 0.1s
Encoding link 80 of 160: (21,23)
Progress: 60% – Elapsed: 0.1s
Encoding link 96 of 160: (1,2)
Progress: 50% – Elapsed: 0.2s
Encoding link 80 of 160: (21,23)
Progress: 60% – Elapsed: 0.2s
Encoding link 96 of 160: (8,6)
Progress: 70% – Elapsed: 0.2s
Encoding link 112 of 160: (7,21)
Progress: 80% – Elapsed: 0.2s
Encoding link 128 of 160: (12,7)
Progress: 90% – Elapsed: 0.2s
Encoding link 144 of 160: (8,9)
Progress: 10% – Elapsed: 0.0s
Encoding link 4 of 40: (22,1)
Progress: 20% – Elapsed: 0.0s
Encoding link 8 of 40: (6,11)
Progress: 30% – Elapsed: 0.0s
Encoding link 12 of 40: (11,14)
Progress: 40% – Elapsed: 0.0s
Encoding link 16 of 40: (3,20)
Progress: 50% – Elapsed: 0.0s
Encoding link 20 of 40: (18,20)
Progress: 60% – Elapsed: 0.1s
Encoding link 24 of 40: (9,18)
Progress: 70% – Elapsed: 0.1s
Encoding link 28 of 40: (18,3)
Progress: 80% – Elapsed: 0.1s
Encoding link 32 of 40: (6,18)
Progress: 90% – Elapsed: 0.1s
Encoding link 36 of 40: (7,8)
Progress: 100% – Elapsed: 0.1s
Encoding link 40 of 40: (13,6)
Done. Total time: 0.1s
Progress: 40% – Elapsed: 0.1s
Encoding link 64 of 160: (20,17)
Progress: 50% – Elapsed: 0.1s
Encoding link 80 of 160: (21,23)
Progress: 60% – Elapsed: 0.1s
Encoding link 96 of 160: (3,22)
Progress: 70% – Elapsed: 0.1s
Encoding link 112 of 160: (21,8)
Progress: 80% – Elapsed: 0.1s
Encoding link 128 of 160: (7,3)
Progress: 90% – Elapsed: 0.2s
Encoding link 144 of 160: (3,13)
Progress: 40% – Elapsed: 0.2s
Encoding link 64 of 160: (20,17)
Progress: 50% – Elapsed: 0.2s
Encoding link 80 of 160: (21,23)
Progress: 60% – Elapsed: 0.2s
Encoding link 96 of 160: (4,6)
Progress: 70% – Elapsed: 0.2s
Encoding link 112 of 160: (3,21)
Progress: 30% – Elapsed: 0.1s
Encoding link 48 of 160: (3,14)
Progress: 40% – Elapsed: 0.1s
Encoding link 64 of 160: (20,17)
Progress: 50% – Elapsed: 0.1s
Encoding link 80 of 160: (21,23)
Progress: 60% – Elapsed: 0.1s
Encoding link 96 of 160: (6,3)
Progress: 70% – Elapsed: 0.1s
Encoding link 112 of 160: (9,3)
Progress: 80% – Elapsed: 0.2s
Encoding link 128 of 160: (6,21)
Progress: 40% – Elapsed: 0.0s
Encoding link 16 of 40: (3,20)
Progress: 50% – Elapsed: 0.0s
Encoding link 20 of 40: (18,20)
Progress: 60% – Elapsed: 0.0s
Encoding link 24 of 40: (9,7)
Progress: 70% – Elapsed: 0.1s
Encoding link 28 of 40: (21,7)
Progress: 80% – Elapsed: 0.1s
Encoding link 32 of 40: (7,4)
Progress: 90% – Elapsed: 0.1s
Encoding link 36 of 40: (18,9)
Progress: 100% – Elapsed: 0.1s
Encoding link 40 of 40: (13,22)
Done. Total time: 0.1s
Progress: 10% – Elapsed: 0.0s
Encoding link 4 of 40: (22,1)
Progress: 20% – Elapsed: 0.0s
Encoding link 8 of 40: (6,11)
Progress: 30% – Elapsed: 0.0s
Encoding link 12 of 40: (11,14)
Progress: 40% – Elapsed: 0.0s
Encoding link 16 of 40: (3,20)
Progress: 50% – Elapsed: 0.0s
Encoding link 20 of 40: (18,20)
Progress: 60% – Elapsed: 0.0s
Encoding link 24 of 40: (8,22)
Progress: 70% – Elapsed: 0.0s
Encoding link 28 of 40: (22,4)
Progress: 80% – Elapsed: 0.0s
Encoding link 32 of 40: (9,22)
Progress: 90% – Elapsed: 0.0s
Encoding link 36 of 40: (12,18)
Progress: 100% – Elapsed: 0.1s
Encoding link 40 of 40: (7,4)
Done. Total time: 0.1s
Progress: 70% – Elapsed: 0.2s
Encoding link 112 of 160: (9,12)
Progress: 80% – Elapsed: 0.2s
Encoding link 128 of 160: (12,7)
Progress: 90% – Elapsed: 0.2s
Encoding link 144 of 160: (3,21)
Progress: 100% – Elapsed: 0.2s
Encoding link 160 of 160: (6,4)
Done. Total time: 0.2s
Encoding 40 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 4 of 40: (22,1)
Progress: 20% – Elapsed: 0.0s
Encoding link 8 of 40: (6,11)
Progress: 30% – Elapsed: 0.0s
Encoding link 12 of 40: (11,14)
Progress: 40% – Elapsed: 0.0s
Encoding link 16 of 40: (3,20)
Progress: 50% – Elapsed: 0.0s
Encoding link 20 of 40: (18,20)
Progress: 60% – Elapsed: 0.0s
Encoding link 24 of 40: (7,18)
Progress: 70% – Elapsed: 0.0s
Encoding link 28 of 40: (18,21)
Progress: 100% – Elapsed: 0.3s
Encoding link 160 of 160: (8,3)
Done. Total time: 0.3s
Encoding 40 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 4 of 40: (22,1)
Progress: 20% – Elapsed: 0.0s
Encoding link 8 of 40: (6,11)
Progress: 30% – Elapsed: 0.0s
Encoding link 12 of 40: (11,14)
Progress: 40% – Elapsed: 0.0s
Encoding link 16 of 40: (3,20)
Progress: 50% – Elapsed: 0.0s
Encoding link 20 of 40: (18,20)
Progress: 60% – Elapsed: 0.0s
Encoding link 24 of 40: (2,1)
Progress: 70% – Elapsed: 0.0s
Encoding link 28 of 40: (1,2)
Progress: 80% – Elapsed: 0.0s
Encoding link 32 of 40: (21,18)
Progress: 90% – Elapsed: 0.0s
Encoding link 36 of 40: (13,18)
Progress: 100% – Elapsed: 0.1s
Encoding link 40 of 40: (22,18)
Done. Total time: 0.1s
Progress: 100% – Elapsed: 0.2s
Encoding link 160 of 160: (6,21)
Done. Total time: 0.2s
Encoding 40 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 4 of 40: (22,1)
Progress: 20% – Elapsed: 0.0s
Encoding link 8 of 40: (6,11)
Progress: 30% – Elapsed: 0.0s
Encoding link 12 of 40: (11,14)
Progress: 40% – Elapsed: 0.0s
Encoding link 16 of 40: (3,20)
Progress: 50% – Elapsed: 0.0s
Encoding link 20 of 40: (18,20)
Progress: 60% – Elapsed: 0.0s
Encoding link 24 of 40: (22,21)
Progress: 70% – Elapsed: 0.0s
Encoding link 28 of 40: (21,22)
Progress: 80% – Elapsed: 0.0s
Encoding link 32 of 40: (13,9)
Progress: 90% – Elapsed: 0.0s
Encoding link 36 of 40: (12,22)
Progress: 100% – Elapsed: 0.0s
Encoding link 40 of 40: (4,22)
Done. Total time: 0.0s
Progress: 80% – Elapsed: 0.3s
Encoding link 128 of 160: (4,22)
Progress: 90% – Elapsed: 0.3s
Encoding link 144 of 160: (22,6)
Progress: 100% – Elapsed: 0.3s
Encoding link 160 of 160: (8,22)
Done. Total time: 0.3s
Encoding 40 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 4 of 40: (22,1)
Progress: 20% – Elapsed: 0.0s
Encoding link 8 of 40: (6,11)
Progress: 30% – Elapsed: 0.0s
Encoding link 12 of 40: (11,14)
Progress: 40% – Elapsed: 0.0s
Encoding link 16 of 40: (3,20)
Progress: 50% – Elapsed: 0.0s
Encoding link 20 of 40: (18,20)
Progress: 60% – Elapsed: 0.0s
Encoding link 24 of 40: (18,7)
Progress: 90% – Elapsed: 0.2s
Encoding link 144 of 160: (12,7)
Progress: 100% – Elapsed: 0.2s
Encoding link 160 of 160: (6,9)
Done. Total time: 0.2s
Encoding 40 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 4 of 40: (22,1)
Progress: 20% – Elapsed: 0.0s
Encoding link 8 of 40: (6,11)
Progress: 30% – Elapsed: 0.0s
Encoding link 12 of 40: (11,14)
Progress: 40% – Elapsed: 0.0s
Encoding link 16 of 40: (3,20)
Progress: 50% – Elapsed: 0.0s
Encoding link 20 of 40: (18,20)
Progress: 60% – Elapsed: 0.0s
Encoding link 24 of 40: (21,6)
Progress: 70% – Elapsed: 0.0s
Encoding link 28 of 40: (8,18)
Progress: 80% – Elapsed: 0.0s
Encoding link 32 of 40: (3,4)
Progress: 90% – Elapsed: 0.0s
Encoding link 36 of 40: (4,22)
Progress: 100% – Elapsed: 0.0s
Encoding link 40 of 40: (18,9)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       46.09% |       0.7093 |          0.1000 |
Progress: 80% – Elapsed: 0.0s
Encoding link 32 of 40: (8,6)
Progress: 70% – Elapsed: 0.0s
Encoding link 28 of 40: (9,3)
Progress: 80% – Elapsed: 0.2s
Encoding link 32 of 40: (18,3)
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       53.91% |       0.7173 |          0.1000 |
Progress: 90% – Elapsed: 0.2s
Encoding link 36 of 40: (13,8)
Progress: 100% – Elapsed: 0.2s
Encoding link 40 of 40: (4,9)
Done. Total time: 0.2s
Progress: 90% – Elapsed: 0.2s
Encoding link 36 of 40: (18,9)
Progress: 100% – Elapsed: 0.2s
Encoding link 40 of 40: (9,22)
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       61.72% |       0.6703 |          0.1000 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       46.09% |       0.6937 |          0.1000 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       50.78% |       0.7177 |          0.1000 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       45.31% |       0.7603 |          0.1000 |
|      50 |          50 |       00:00:00 |       99.22% |       0.0457 |          0.0656 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       14.84% |       0.7375 |          0.1000 |
|       1 |           1 |       00:00:00 |       41.41% |       0.7040 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0136 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0026 |          0.0387 |
|      50 |          50 |       00:00:00 |       99.22% |       0.0427 |          0.0656 |
|      50 |          50 |       00:00:00 |       98.44% |       0.0244 |          0.0656 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0112 |          0.0656 |
|      50 |          50 |       00:00:00 |       99.22% |       0.0344 |          0.0656 |
|      50 |          50 |       00:00:00 |       99.22% |       0.0228 |          0.0656 |
|      50 |          50 |       00:00:00 |       99.22% |       0.0522 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0097 |          0.0387 |
|     100 |         100 |       00:00:00 |       99.22% |       0.0214 |          0.0387 |
|     100 |         100 |       00:00:00 |       99.22% |       0.0353 |          0.0387 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0164 |          0.0387 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0042 |          0.0387 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0025 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0015 |          0.0229 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0015 |          0.0229 |
|     150 |         150 |       00:00:01 |      100.00% |       0.0031 |          0.0229 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0096 |          0.0229 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0015 |          0.0229 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0032 |          0.0387 |
|     200 |         200 |       00:00:01 |      100.00% |       0.0021 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     200 |         200 |       00:00:00 |      100.00% |       0.0011 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9048, Recall: 0.9500, F1-Score: 0.9268
AUC: 0.9625
|     200 |         200 |       00:00:00 |      100.00% |       0.0012 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9524, Recall: 1.0000, F1-Score: 0.9756
AUC: 0.9925
|     150 |         150 |       00:00:00 |      100.00% |       0.0075 |          0.0229 |
|     150 |         150 |       00:00:00 |       99.22% |       0.0282 |          0.0229 |
|     200 |         200 |       00:00:01 |      100.00% |       0.0012 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9500, Recall: 0.9500, F1-Score: 0.9500
AUC: 0.9688
Best Threshold: 0.10, Precision: 0.9524, Recall: 1.0000, F1-Score: 0.9756
AUC: 0.9750
|     200 |         200 |       00:00:00 |      100.00% |       0.0079 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     200 |         200 |       00:00:01 |      100.00% |       0.0034 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     150 |         150 |       00:00:00 |      100.00% |       0.0018 |          0.0229 |
    "Experiment "    "9"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: Not enough negative links. Reducing k...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',131,0)">line 131</a>)
[sample_neg] Final link counts:
    Train Positive: 80
    Train Negative: 80
    Test  Positive: 20
    Test  Negative: 20
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 160 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 16 of 160: (3,5)
Progress: 20% – Elapsed: 0.0s
Encoding link 32 of 160: (7,10)
Progress: 30% – Elapsed: 0.0s
Encoding link 48 of 160: (3,14)
Progress: 40% – Elapsed: 0.1s
Encoding link 64 of 160: (20,17)
Progress: 50% – Elapsed: 0.1s
Encoding link 80 of 160: (21,23)
Progress: 60% – Elapsed: 0.1s
Encoding link 96 of 160: (12,7)
Best Threshold: 0.10, Precision: 0.9524, Recall: 1.0000, F1-Score: 0.9756
AUC: 0.9850
Best Threshold: 0.10, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000
AUC: 1.0000
|     200 |         200 |       00:00:01 |       99.22% |       0.0240 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Progress: 70% – Elapsed: 0.1s
Encoding link 112 of 160: (2,1)
Progress: 80% – Elapsed: 0.1s
Encoding link 128 of 160: (13,6)
Progress: 90% – Elapsed: 0.1s
Encoding link 144 of 160: (13,4)
Progress: 100% – Elapsed: 0.2s
Encoding link 160 of 160: (6,21)
Done. Total time: 0.2s
Encoding 40 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 4 of 40: (22,1)
Progress: 20% – Elapsed: 0.0s
Encoding link 8 of 40: (6,11)
Progress: 30% – Elapsed: 0.0s
Encoding link 12 of 40: (11,14)
Progress: 40% – Elapsed: 0.0s
Encoding link 16 of 40: (3,20)
Progress: 50% – Elapsed: 0.0s
Encoding link 20 of 40: (18,20)
Progress: 60% – Elapsed: 0.0s
Encoding link 24 of 40: (6,22)
Progress: 70% – Elapsed: 0.0s
Encoding link 28 of 40: (6,9)
Progress: 80% – Elapsed: 0.0s
Encoding link 32 of 40: (21,3)
Progress: 90% – Elapsed: 0.0s
Encoding link 36 of 40: (18,9)
Progress: 100% – Elapsed: 0.0s
Encoding link 40 of 40: (21,9)
Done. Total time: 0.0s
|     200 |         200 |       00:00:01 |      100.00% |       0.0014 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000
AUC: 1.0000
Best Threshold: 0.10, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000
AUC: 1.0000
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       48.44% |       0.7533 |          0.1000 |
|      50 |          50 |       00:00:00 |       99.22% |       0.0437 |          0.0656 |
  Columns 1 through 4

    "Experiment "    "10"    " (strategy: "    "random"

  Column 5

    ") — Running WLNM..."

Warning: Not enough negative links. Reducing k...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',131,0)">line 131</a>)
[sample_neg] Final link counts:
    Train Positive: 80
    Train Negative: 80
    Test  Positive: 20
    Test  Negative: 20
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 160 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 16 of 160: (3,5)
Progress: 20% – Elapsed: 0.1s
Encoding link 32 of 160: (7,10)
Progress: 30% – Elapsed: 0.1s
Encoding link 48 of 160: (3,14)
Progress: 40% – Elapsed: 0.1s
Encoding link 64 of 160: (20,17)
Progress: 50% – Elapsed: 0.1s
Encoding link 80 of 160: (21,23)
Progress: 60% – Elapsed: 0.1s
Encoding link 96 of 160: (8,9)
Progress: 70% – Elapsed: 0.1s
Encoding link 112 of 160: (4,22)
Progress: 80% – Elapsed: 0.2s
Encoding link 128 of 160: (9,4)
Progress: 90% – Elapsed: 0.2s
Encoding link 144 of 160: (7,9)
Progress: 100% – Elapsed: 0.2s
Encoding link 160 of 160: (12,13)
Done. Total time: 0.2s
Encoding 40 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 4 of 40: (22,1)
Progress: 20% – Elapsed: 0.0s
Encoding link 8 of 40: (6,11)
Progress: 30% – Elapsed: 0.0s
Encoding link 12 of 40: (11,14)
Progress: 40% – Elapsed: 0.0s
Encoding link 16 of 40: (3,20)
Progress: 50% – Elapsed: 0.0s
Encoding link 20 of 40: (18,20)
Progress: 60% – Elapsed: 0.0s
Encoding link 24 of 40: (8,21)
Progress: 70% – Elapsed: 0.0s
Encoding link 28 of 40: (21,18)
Progress: 80% – Elapsed: 0.0s
Encoding link 32 of 40: (1,2)
Progress: 90% – Elapsed: 0.0s
Encoding link 36 of 40: (9,8)
Progress: 100% – Elapsed: 0.0s
Encoding link 40 of 40: (9,7)
Done. Total time: 0.0s
|     100 |         100 |       00:00:00 |       99.22% |       0.0321 |          0.0387 |
|     150 |         150 |       00:00:00 |       99.22% |       0.0181 |          0.0229 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       65.62% |       0.6580 |          0.1000 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0099 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000
AUC: 1.0000
|      50 |          50 |       00:00:00 |       99.22% |       0.0338 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0089 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0038 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0027 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9524, Recall: 1.0000, F1-Score: 0.9756
AUC: 0.9800
