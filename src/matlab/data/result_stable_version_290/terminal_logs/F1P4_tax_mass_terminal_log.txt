Processing dataset: F1P4_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 24 / 59 (40.7%)
[DivideNet] Attempts made: 291 | Failed attempts: 267
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 271
    Train Negative: 271
    Test  Positive: 24
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 542 subgraphs (K = 10)...
    "Experiment "    "2"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 271
    Train Negative: 271
    Test  Positive: 24
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 542 subgraphs (K = 10)...
    "Experiment "    "3"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 271
    Train Negative: 271
    Test  Positive: 24
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
    "Experiment "    "7"    " (strategy: "    "random"    ") — Running WLNM..."

    "Experiment "    "8"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
    "Experiment "    "5"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 271
    Train Negative: 271
    Test  Positive: 24
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 542 subgraphs (K = 10)...
    "Experiment "    "4"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 271
    Train Negative: 271
    Test  Positive: 24
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 542 subgraphs (K = 10)...
    "Experiment "    "6"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 271
    Train Negative: 271
    Test  Positive: 24
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 542 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.3s
Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 271
    Train Negative: 271
    Test  Positive: 24
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 542 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.3s
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 271
    Train Negative: 271
    Test  Positive: 24
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 542 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.1s
Encoding 542 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.1s
Progress: 20% – Elapsed: 0.4s
Progress: 10% – Elapsed: 0.1s
Progress: 20% – Elapsed: 0.5s
Progress: 10% – Elapsed: 0.1s
Progress: 10% – Elapsed: 0.1s
Progress: 20% – Elapsed: 0.1s
Progress: 20% – Elapsed: 0.2s
Progress: 10% – Elapsed: 0.2s
Progress: 30% – Elapsed: 0.5s
Progress: 20% – Elapsed: 0.2s
Progress: 30% – Elapsed: 0.3s
Progress: 30% – Elapsed: 0.5s
Progress: 40% – Elapsed: 0.6s
Progress: 20% – Elapsed: 0.2s
Progress: 30% – Elapsed: 0.3s
Progress: 20% – Elapsed: 0.3s
Progress: 30% – Elapsed: 0.3s
Progress: 40% – Elapsed: 0.4s
Progress: 20% – Elapsed: 0.3s
Progress: 30% – Elapsed: 0.3s
Progress: 40% – Elapsed: 0.5s
Progress: 50% – Elapsed: 0.6s
Progress: 40% – Elapsed: 0.3s
Progress: 40% – Elapsed: 0.4s
Progress: 30% – Elapsed: 0.4s
Progress: 40% – Elapsed: 0.4s
Progress: 30% – Elapsed: 0.3s
Progress: 40% – Elapsed: 0.3s
Progress: 50% – Elapsed: 0.4s
Progress: 40% – Elapsed: 0.4s
Progress: 60% – Elapsed: 0.7s
Progress: 70% – Elapsed: 0.8s
Progress: 50% – Elapsed: 0.4s
Progress: 50% – Elapsed: 0.7s
Progress: 50% – Elapsed: 0.4s
Progress: 50% – Elapsed: 0.6s
Progress: 60% – Elapsed: 0.7s
Progress: 60% – Elapsed: 0.5s
Progress: 50% – Elapsed: 0.5s
Progress: 60% – Elapsed: 0.6s
Progress: 50% – Elapsed: 0.5s
Progress: 80% – Elapsed: 0.8s
Progress: 90% – Elapsed: 0.9s
Progress: 60% – Elapsed: 0.5s
Progress: 60% – Elapsed: 0.8s
Progress: 70% – Elapsed: 0.9s
Progress: 60% – Elapsed: 0.5s
Progress: 100% – Elapsed: 1.0s
Done. Total time: 1.0s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 25% – Elapsed: 0.1s
Progress: 33% – Elapsed: 0.1s
Progress: 42% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 58% – Elapsed: 0.1s
Progress: 67% – Elapsed: 0.1s
Progress: 75% – Elapsed: 0.1s
Progress: 83% – Elapsed: 0.1s
Progress: 92% – Elapsed: 0.1s
Progress: 100% – Elapsed: 0.1s
Done. Total time: 0.1s
Progress: 70% – Elapsed: 0.7s
Progress: 80% – Elapsed: 1.0s
Progress: 70% – Elapsed: 0.6s
Progress: 70% – Elapsed: 0.8s
Progress: 80% – Elapsed: 0.9s
Progress: 70% – Elapsed: 0.7s
Progress: 80% – Elapsed: 0.8s
Progress: 70% – Elapsed: 0.7s
Progress: 60% – Elapsed: 0.7s
Progress: 70% – Elapsed: 0.8s
Progress: 80% – Elapsed: 0.7s
Progress: 90% – Elapsed: 0.8s
Progress: 90% – Elapsed: 1.1s
Progress: 100% – Elapsed: 1.2s
Progress: 80% – Elapsed: 0.7s
Progress: 90% – Elapsed: 0.8s
Progress: 90% – Elapsed: 0.9s
Progress: 90% – Elapsed: 0.8s
Progress: 100% – Elapsed: 0.9s
Done. Total time: 0.9s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Progress: 80% – Elapsed: 0.8s
Progress: 90% – Elapsed: 0.9s
Progress: 80% – Elapsed: 0.8s
Progress: 90% – Elapsed: 0.9s
Progress: 100% – Elapsed: 1.0s
Done. Total time: 1.0s
Encoding 48 subgraphs (K = 10)...
Progress: 100% – Elapsed: 1.0s
Done. Total time: 1.0s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 25% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 42% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.1s
Done. Total time: 1.2s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 25% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 42% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.1s
Progress: 100% – Elapsed: 1.0s
Done. Total time: 1.0s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 25% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.1s
Progress: 100% – Elapsed: 1.0s
Done. Total time: 1.0s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 25% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 25% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 42% – Elapsed: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       18.75% |       0.7800 |          0.1000 |
Progress: 75% – Elapsed: 0.1s
Progress: 83% – Elapsed: 0.2s
Progress: 92% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Progress: 42% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 58% – Elapsed: 0.1s
Progress: 67% – Elapsed: 0.2s
Progress: 75% – Elapsed: 0.2s
Progress: 83% – Elapsed: 0.2s
Progress: 92% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Progress: 50% – Elapsed: 0.1s
Progress: 58% – Elapsed: 0.1s
Progress: 67% – Elapsed: 0.1s
Progress: 75% – Elapsed: 0.1s
Progress: 83% – Elapsed: 0.1s
Progress: 92% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Progress: 100% – Elapsed: 1.0s
Done. Total time: 1.1s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 25% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 42% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.1s
Progress: 67% – Elapsed: 0.2s
Progress: 75% – Elapsed: 0.2s
Progress: 83% – Elapsed: 0.2s
Progress: 92% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Progress: 42% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 58% – Elapsed: 0.1s
Progress: 67% – Elapsed: 0.1s
Progress: 75% – Elapsed: 0.1s
Progress: 83% – Elapsed: 0.2s
Progress: 92% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.2s
Done. Total time: 0.2s
Progress: 67% – Elapsed: 0.1s
Progress: 75% – Elapsed: 0.1s
Progress: 83% – Elapsed: 0.1s
Progress: 92% – Elapsed: 0.1s
Progress: 100% – Elapsed: 0.1s
Done. Total time: 0.1s
Progress: 8% – Elapsed: 0.2s
Progress: 17% – Elapsed: 0.2s
Progress: 25% – Elapsed: 0.2s
Progress: 33% – Elapsed: 0.2s
Progress: 42% – Elapsed: 0.2s
Progress: 50% – Elapsed: 0.2s
Progress: 58% – Elapsed: 0.2s
Progress: 67% – Elapsed: 0.2s
Progress: 75% – Elapsed: 0.2s
Progress: 83% – Elapsed: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       47.66% |       0.8200 |          0.1000 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       46.09% |       0.6637 |          0.1000 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
Progress: 92% – Elapsed: 0.2s
Progress: 100% – Elapsed: 0.3s
Done. Total time: 0.3s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       52.34% |       0.8089 |          0.1000 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       83.59% |       0.6552 |          0.1000 |
|      13 |          50 |       00:00:00 |       88.28% |       0.3449 |          0.0900 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       13.28% |       0.7061 |          0.1000 |
|       1 |           1 |       00:00:00 |       46.09% |       0.8388 |          0.1000 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       51.56% |       0.7419 |          0.1000 |
|      13 |          50 |       00:00:00 |       89.06% |       0.3013 |          0.0900 |
|      13 |          50 |       00:00:00 |       86.72% |       0.3415 |          0.0900 |
|      13 |          50 |       00:00:00 |       88.28% |       0.2989 |          0.0900 |
|      25 |         100 |       00:00:00 |       95.31% |       0.1743 |          0.0810 |
|      13 |          50 |       00:00:00 |       91.41% |       0.2538 |          0.0900 |
|      13 |          50 |       00:00:00 |       91.41% |       0.2634 |          0.0900 |
|      13 |          50 |       00:00:00 |       87.50% |       0.3475 |          0.0900 |
|      25 |         100 |       00:00:00 |       92.19% |       0.2254 |          0.0810 |
|      25 |         100 |       00:00:00 |       90.62% |       0.2621 |          0.0810 |
|      13 |          50 |       00:00:00 |       85.94% |       0.3291 |          0.0900 |
|      25 |         100 |       00:00:00 |       95.31% |       0.1640 |          0.0810 |
|      25 |         100 |       00:00:00 |       89.84% |       0.2603 |          0.0810 |
|      25 |         100 |       00:00:00 |       90.62% |       0.2767 |          0.0810 |
|      38 |         150 |       00:00:01 |       90.62% |       0.2605 |          0.0729 |
|      38 |         150 |       00:00:01 |       89.84% |       0.2713 |          0.0729 |
|      25 |         100 |       00:00:00 |       91.41% |       0.2438 |          0.0810 |
|      25 |         100 |       00:00:00 |       95.31% |       0.1600 |          0.0810 |
|      38 |         150 |       00:00:01 |       89.06% |       0.2925 |          0.0729 |
|      38 |         150 |       00:00:01 |       92.19% |       0.2256 |          0.0729 |
|      38 |         150 |       00:00:00 |       92.97% |       0.2174 |          0.0729 |
|      50 |         200 |       00:00:01 |       90.62% |       0.2611 |          0.0656 |
|      50 |         200 |       00:00:01 |       95.31% |       0.1603 |          0.0656 |
|      38 |         150 |       00:00:01 |       93.75% |       0.2007 |          0.0729 |
|      50 |         200 |       00:00:01 |       91.41% |       0.2410 |          0.0656 |
|      38 |         150 |       00:00:01 |       89.84% |       0.2788 |          0.0729 |
|      50 |         200 |       00:00:01 |       93.75% |       0.1983 |          0.0656 |
|      50 |         200 |       00:00:01 |       90.62% |       0.2455 |          0.0656 |
|      38 |         150 |       00:00:01 |       90.62% |       0.2545 |          0.0729 |
|      63 |         250 |       00:00:02 |       90.62% |       0.2564 |          0.0531 |
|      50 |         200 |       00:00:01 |       96.88% |       0.1412 |          0.0656 |
|      50 |         200 |       00:00:01 |       92.97% |       0.2100 |          0.0656 |
|      63 |         250 |       00:00:01 |       92.19% |       0.2202 |          0.0531 |
|      63 |         250 |       00:00:01 |       92.97% |       0.2126 |          0.0531 |
|      63 |         250 |       00:00:01 |       89.84% |       0.2864 |          0.0531 |
|      50 |         200 |       00:00:01 |       96.09% |       0.1405 |          0.0656 |
|      63 |         250 |       00:00:01 |       92.19% |       0.2390 |          0.0531 |
|      63 |         250 |       00:00:01 |       89.84% |       0.2693 |          0.0531 |
|      75 |         300 |       00:00:01 |       90.62% |       0.2569 |          0.0478 |
|      75 |         300 |       00:00:02 |       95.31% |       0.1580 |          0.0478 |
|      75 |         300 |       00:00:02 |       91.41% |       0.2320 |          0.0478 |
|      75 |         300 |       00:00:02 |       90.62% |       0.2403 |          0.0478 |
|      63 |         250 |       00:00:01 |       91.41% |       0.2372 |          0.0531 |
|      63 |         250 |       00:00:02 |       93.75% |       0.1932 |          0.0531 |
|      75 |         300 |       00:00:02 |       93.75% |       0.1923 |          0.0478 |
|      88 |         350 |       00:00:02 |       90.62% |       0.2725 |          0.0430 |
|      88 |         350 |       00:00:02 |       92.19% |       0.2357 |          0.0430 |
|      75 |         300 |       00:00:02 |       92.97% |       0.2080 |          0.0478 |
|      88 |         350 |       00:00:02 |       92.19% |       0.2194 |          0.0430 |
|      88 |         350 |       00:00:02 |       92.97% |       0.2105 |          0.0430 |
|      88 |         350 |       00:00:02 |       89.84% |       0.2809 |          0.0430 |
|     100 |         400 |       00:00:03 |       95.31% |       0.1589 |          0.0387 |
|      75 |         300 |       00:00:02 |       96.88% |       0.1325 |          0.0478 |
|     100 |         400 |       00:00:02 |       91.41% |       0.2282 |          0.0387 |
|      88 |         350 |       00:00:02 |       89.84% |       0.2679 |          0.0430 |
|     100 |         400 |       00:00:02 |       90.62% |       0.2540 |          0.0387 |
|      75 |         300 |       00:00:02 |       96.09% |       0.1375 |          0.0478 |
|      88 |         350 |       00:00:02 |       93.75% |       0.1902 |          0.0430 |
|     113 |         450 |       00:00:03 |       92.19% |       0.2342 |          0.0314 |
|     100 |         400 |       00:00:02 |       92.97% |       0.2078 |          0.0387 |
|     100 |         400 |       00:00:02 |       93.75% |       0.1906 |          0.0387 |
|     100 |         400 |       00:00:02 |       90.62% |       0.2385 |          0.0387 |
|     113 |         450 |       00:00:02 |       92.97% |       0.2099 |          0.0314 |
|      88 |         350 |       00:00:02 |       91.41% |       0.2348 |          0.0430 |
|     100 |         400 |       00:00:02 |       96.88% |       0.1310 |          0.0387 |
|     125 |         500 |       00:00:03 |       90.62% |       0.2528 |          0.0282 |
|     113 |         450 |       00:00:03 |       90.62% |       0.2552 |          0.0314 |
|     125 |         500 |       00:00:03 |       91.41% |       0.2266 |          0.0282 |
|     113 |         450 |       00:00:03 |       89.84% |       0.2644 |          0.0314 |
|     113 |         450 |       00:00:03 |       89.84% |       0.2806 |          0.0314 |
|     113 |         450 |       00:00:03 |       92.19% |       0.2193 |          0.0314 |
|     125 |         500 |       00:00:03 |       90.62% |       0.2375 |          0.0282 |
|     100 |         400 |       00:00:03 |       96.09% |       0.1367 |          0.0387 |
|     125 |         500 |       00:00:04 |       95.31% |       0.1572 |          0.0282 |
|     113 |         450 |       00:00:03 |       93.75% |       0.1899 |          0.0314 |
|     125 |         500 |       00:00:03 |       92.97% |       0.2076 |          0.0282 |
|     125 |         500 |       00:00:03 |       93.75% |       0.1900 |          0.0282 |
|     138 |         550 |       00:00:03 |       92.97% |       0.2095 |          0.0254 |
|     113 |         450 |       00:00:03 |       91.41% |       0.2332 |          0.0314 |
|     138 |         550 |       00:00:04 |       92.19% |       0.2335 |          0.0254 |
|     138 |         550 |       00:00:03 |       92.19% |       0.2190 |          0.0254 |
|     138 |         550 |       00:00:04 |       90.62% |       0.2550 |          0.0254 |
|     125 |         500 |       00:00:03 |       96.88% |       0.1300 |          0.0282 |
|     138 |         550 |       00:00:04 |       89.84% |       0.2641 |          0.0254 |
|     138 |         550 |       00:00:04 |       89.84% |       0.2780 |          0.0254 |
|     150 |         600 |       00:00:04 |       90.62% |       0.2371 |          0.0229 |
|     150 |         600 |       00:00:04 |       90.62% |       0.2524 |          0.0229 |
|     125 |         500 |       00:00:04 |       96.09% |       0.1360 |          0.0282 |
|     138 |         550 |       00:00:05 |       93.75% |       0.1895 |          0.0254 |
|     150 |         600 |       00:00:05 |       91.41% |       0.2259 |          0.0229 |
|     150 |         600 |       00:00:06 |       95.31% |       0.1569 |          0.0229 |
|     150 |         600 |       00:00:06 |       92.97% |       0.2074 |          0.0229 |
|     138 |         550 |       00:00:05 |       91.41% |       0.2328 |          0.0254 |
|     163 |         650 |       00:00:06 |       92.19% |       0.2330 |          0.0185 |
|     150 |         600 |       00:00:06 |       93.75% |       0.1896 |          0.0229 |
|     163 |         650 |       00:00:06 |       92.19% |       0.2190 |          0.0185 |
|     163 |         650 |       00:00:06 |       92.97% |       0.2093 |          0.0185 |
|     163 |         650 |       00:00:06 |       89.84% |       0.2633 |          0.0185 |
|     175 |         700 |       00:00:06 |       90.62% |       0.2518 |          0.0167 |
|     150 |         600 |       00:00:06 |       96.88% |       0.1295 |          0.0229 |
|     163 |         650 |       00:00:07 |       90.62% |       0.2547 |          0.0185 |
|     175 |         700 |       00:00:07 |       91.41% |       0.2256 |          0.0167 |
|     150 |         600 |       00:00:07 |       96.09% |       0.1361 |          0.0229 |
|     175 |         700 |       00:00:07 |       92.97% |       0.2073 |          0.0167 |
|     163 |         650 |       00:00:07 |       89.84% |       0.2769 |          0.0185 |
|     188 |         750 |       00:00:08 |       92.19% |       0.2328 |          0.0150 |
|     175 |         700 |       00:00:08 |       90.62% |       0.2360 |          0.0167 |
|     188 |         750 |       00:00:08 |       92.97% |       0.2093 |          0.0150 |
|     163 |         650 |       00:00:08 |       93.75% |       0.1891 |          0.0185 |
|     188 |         750 |       00:00:08 |       89.84% |       0.2633 |          0.0150 |
|     163 |         650 |       00:00:08 |       91.41% |       0.2326 |          0.0185 |
|     175 |         700 |       00:00:09 |       95.31% |       0.1566 |          0.0167 |
|     200 |         800 |       00:00:09 |       91.41% |       0.2250 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     175 |         700 |       00:00:09 |       93.75% |       0.1895 |          0.0167 |
|     188 |         750 |       00:00:09 |       92.19% |       0.2188 |          0.0150 |
|     200 |         800 |       00:00:09 |       90.62% |       0.2514 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.7273, Recall: 0.3333, F1-Score: 0.4571
AUC: 0.7977
Best Threshold: 0.90, Precision: 1.0000, Recall: 0.2917, F1-Score: 0.4516
AUC: 0.3290
|     175 |         700 |       00:00:09 |       96.09% |       0.1360 |          0.0167 |
|     175 |         700 |       00:00:09 |       96.88% |       0.1289 |          0.0167 |
    "Experiment "    "9"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 271
    Train Negative: 271
    Test  Positive: 24
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 542 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.2s
|     200 |         800 |       00:00:09 |       92.97% |       0.2072 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     188 |         750 |       00:00:10 |       89.84% |       0.2769 |          0.0150 |
|     188 |         750 |       00:00:11 |       90.62% |       0.2546 |          0.0150 |
|     200 |         800 |       00:00:10 |       90.62% |       0.2359 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Progress: 20% – Elapsed: 0.5s
Best Threshold: 0.10, Precision: 0.8000, Recall: 0.3333, F1-Score: 0.4706
AUC: 0.4948
Progress: 30% – Elapsed: 0.7s
|     200 |         800 |       00:00:10 |       93.75% |       0.1893 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.7000, Recall: 0.2917, F1-Score: 0.4118
AUC: 0.3655
|     188 |         750 |       00:00:10 |       91.41% |       0.2323 |          0.0150 |
Progress: 40% – Elapsed: 0.9s
Best Threshold: 0.90, Precision: 1.0000, Recall: 0.2917, F1-Score: 0.4516
AUC: 0.8854
|     188 |         750 |       00:00:10 |       93.75% |       0.1890 |          0.0150 |
Progress: 50% – Elapsed: 1.0s
Progress: 60% – Elapsed: 1.1s
|     200 |         800 |       00:00:11 |       95.31% |       0.1565 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     200 |         800 |       00:00:11 |       96.09% |       0.1359 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.8000, Recall: 0.3333, F1-Score: 0.4706
AUC: 0.8594
Progress: 70% – Elapsed: 1.3s
Best Threshold: 0.10, Precision: 0.6154, Recall: 0.3333, F1-Score: 0.4324
AUC: 0.8203
  Columns 1 through 4

    "Experiment "    "10"    " (strategy: "    "random"

  Column 5

    ") — Running WLNM..."

Warning: [sample_neg] Not enough negatives. Reducing a...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 82)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',82,0)">line 82</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 33)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',33,0)">line 33</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 220)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',220,0)">line 220</a>)
[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 271
    Train Negative: 271
    Test  Positive: 24
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 542 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.1s
|     200 |         800 |       00:00:11 |       96.88% |       0.1305 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Progress: 80% – Elapsed: 1.4s
Progress: 90% – Elapsed: 1.4s
Progress: 100% – Elapsed: 1.5s
Done. Total time: 1.5s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 25% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 42% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 75% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.1s
Progress: 92% – Elapsed: 0.1s
Progress: 100% – Elapsed: 0.1s
Done. Total time: 0.1s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.2s
Best Threshold: 0.10, Precision: 0.5833, Recall: 0.2917, F1-Score: 0.3889
AUC: 0.2943
Progress: 40% – Elapsed: 0.3s
Progress: 50% – Elapsed: 0.4s
Progress: 60% – Elapsed: 0.5s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       52.34% |       0.7379 |          0.1000 |
Progress: 70% – Elapsed: 0.5s
Progress: 80% – Elapsed: 0.6s
Progress: 90% – Elapsed: 0.7s
Progress: 100% – Elapsed: 0.8s
Done. Total time: 0.8s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Progress: 17% – Elapsed: 0.0s
Progress: 25% – Elapsed: 0.0s
Progress: 33% – Elapsed: 0.0s
Progress: 42% – Elapsed: 0.0s
Progress: 50% – Elapsed: 0.0s
Progress: 58% – Elapsed: 0.0s
Progress: 67% – Elapsed: 0.0s
Progress: 75% – Elapsed: 0.0s
Progress: 83% – Elapsed: 0.0s
Progress: 92% – Elapsed: 0.1s
Progress: 100% – Elapsed: 0.1s
Done. Total time: 0.1s
|      13 |          50 |       00:00:00 |       89.84% |       0.2788 |          0.0900 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       51.56% |       0.6400 |          0.1000 |
|      13 |          50 |       00:00:00 |       92.19% |       0.2521 |          0.0900 |
|      25 |         100 |       00:00:00 |       93.75% |       0.2036 |          0.0810 |
|      25 |         100 |       00:00:00 |       86.72% |       0.3818 |          0.0810 |
|      38 |         150 |       00:00:00 |       92.19% |       0.2299 |          0.0729 |
|      38 |         150 |       00:00:01 |       93.75% |       0.2106 |          0.0729 |
|      50 |         200 |       00:00:01 |       94.53% |       0.1890 |          0.0656 |
|      63 |         250 |       00:00:01 |       92.19% |       0.2251 |          0.0531 |
|      75 |         300 |       00:00:01 |       94.53% |       0.1853 |          0.0478 |
|      50 |         200 |       00:00:01 |       92.97% |       0.1991 |          0.0656 |
|      63 |         250 |       00:00:01 |       93.75% |       0.1949 |          0.0531 |
|      75 |         300 |       00:00:01 |       94.53% |       0.1773 |          0.0478 |
|      88 |         350 |       00:00:02 |       92.19% |       0.2244 |          0.0430 |
|     100 |         400 |       00:00:02 |       94.53% |       0.1846 |          0.0387 |
|     113 |         450 |       00:00:02 |       92.19% |       0.2241 |          0.0314 |
|      88 |         350 |       00:00:01 |       93.75% |       0.1934 |          0.0430 |
|     100 |         400 |       00:00:02 |       94.53% |       0.1750 |          0.0387 |
|     125 |         500 |       00:00:02 |       94.53% |       0.1828 |          0.0282 |
|     113 |         450 |       00:00:02 |       93.75% |       0.1930 |          0.0314 |
|     125 |         500 |       00:00:02 |       94.53% |       0.1742 |          0.0282 |
|     138 |         550 |       00:00:03 |       92.19% |       0.2238 |          0.0254 |
|     138 |         550 |       00:00:03 |       93.75% |       0.1928 |          0.0254 |
|     150 |         600 |       00:00:03 |       94.53% |       0.1823 |          0.0229 |
|     163 |         650 |       00:00:03 |       92.19% |       0.2237 |          0.0185 |
|     150 |         600 |       00:00:03 |       94.53% |       0.1738 |          0.0229 |
|     163 |         650 |       00:00:03 |       93.75% |       0.1928 |          0.0185 |
|     175 |         700 |       00:00:03 |       94.53% |       0.1819 |          0.0167 |
|     188 |         750 |       00:00:04 |       92.19% |       0.2237 |          0.0150 |
|     200 |         800 |       00:00:04 |       94.53% |       0.1819 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     175 |         700 |       00:00:03 |       94.53% |       0.1736 |          0.0167 |
Best Threshold: 0.10, Precision: 0.6154, Recall: 0.3333, F1-Score: 0.4324
AUC: 0.4036
|     188 |         750 |       00:00:04 |       93.75% |       0.1927 |          0.0150 |
|     200 |         800 |       00:00:04 |       94.53% |       0.1735 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.6667, Recall: 0.3333, F1-Score: 0.4444
AUC: 0.8507
