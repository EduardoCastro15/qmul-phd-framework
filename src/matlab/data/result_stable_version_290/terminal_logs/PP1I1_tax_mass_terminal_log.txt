Processing dataset: PP1I1_tax_mass
    "Processing with K …"    "10"    " using strategy: "    "random"

    "Experiment "    "6"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: Not enough negative links. Reducing k...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',131,0)">line 131</a>)
[sample_neg] Final link counts:
    Train Positive: 90
    Train Negative: 90
    Test  Positive: 23
    Test  Negative: 23
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 180 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 18 of 180: (7,8)
Progress: 20% – Elapsed: 0.1s
Encoding link 36 of 180: (4,13)
Progress: 30% – Elapsed: 0.1s
Encoding link 54 of 180: (12,15)
    "Experiment "    "2"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: Not enough negative links. Reducing k...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',131,0)">line 131</a>)
[sample_neg] Final link counts:
    Train Positive: 90
    Train Negative: 90
    Test  Positive: 23
    Test  Negative: 23
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 180 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 18 of 180: (7,8)
Progress: 20% – Elapsed: 0.0s
Encoding link 36 of 180: (4,13)
Progress: 30% – Elapsed: 0.0s
Encoding link 54 of 180: (12,15)
Progress: 40% – Elapsed: 0.1s
Encoding link 72 of 180: (27,19)
    "Experiment "    "5"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: Not enough negative links. Reducing k...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',131,0)">line 131</a>)
[sample_neg] Final link counts:
    Train Positive: 90
    Train Negative: 90
    Test  Positive: 23
    Test  Negative: 23
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 180 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.1s
Encoding link 18 of 180: (7,8)
Progress: 20% – Elapsed: 0.1s
Encoding link 36 of 180: (4,13)
Progress: 30% – Elapsed: 0.1s
Encoding link 54 of 180: (12,15)
    "Experiment "    "3"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: Not enough negative links. Reducing k...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',131,0)">line 131</a>)
[sample_neg] Final link counts:
    Train Positive: 90
    Train Negative: 90
    Test  Positive: 23
    Test  Negative: 23
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 180 subgraphs (K = 10)...
    "Experiment "    "4"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: Not enough negative links. Reducing k...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',131,0)">line 131</a>)
[sample_neg] Final link counts:
    Train Positive: 90
    Train Negative: 90
    Test  Positive: 23
    Test  Negative: 23
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 180 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.1s
Encoding link 18 of 180: (7,8)
    "Experiment "    "8"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: Not enough negative links. Reducing k...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',131,0)">line 131</a>)
[sample_neg] Final link counts:
    Train Positive: 90
    Train Negative: 90
    Test  Positive: 23
    Test  Negative: 23
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 180 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 18 of 180: (7,8)
Progress: 20% – Elapsed: 0.1s
Encoding link 36 of 180: (4,13)
Progress: 30% – Elapsed: 0.1s
Encoding link 54 of 180: (12,15)
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: Not enough negative links. Reducing k...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',131,0)">line 131</a>)
[sample_neg] Final link counts:
    Train Positive: 90
    Train Negative: 90
    Test  Positive: 23
    Test  Negative: 23
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 180 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 18 of 180: (7,8)
Progress: 20% – Elapsed: 0.0s
Encoding link 36 of 180: (4,13)
Progress: 30% – Elapsed: 0.1s
Encoding link 54 of 180: (12,15)
Progress: 40% – Elapsed: 0.1s
Encoding link 72 of 180: (27,19)
Progress: 50% – Elapsed: 0.2s
Encoding link 90 of 180: (26,24)
Progress: 60% – Elapsed: 0.2s
Encoding link 108 of 180: (25,18)
    "Experiment "    "7"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: Not enough negative links. Reducing k...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',131,0)">line 131</a>)
[sample_neg] Final link counts:
    Train Positive: 90
    Train Negative: 90
    Test  Positive: 23
    Test  Negative: 23
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 180 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 18 of 180: (7,8)
Progress: 40% – Elapsed: 0.1s
Encoding link 72 of 180: (27,19)
Progress: 50% – Elapsed: 0.1s
Encoding link 90 of 180: (26,24)
Progress: 60% – Elapsed: 0.1s
Encoding link 108 of 180: (20,12)
Progress: 70% – Elapsed: 0.1s
Encoding link 126 of 180: (6,20)
Progress: 80% – Elapsed: 0.1s
Encoding link 144 of 180: (18,10)
Progress: 90% – Elapsed: 0.2s
Encoding link 162 of 180: (22,26)
Progress: 50% – Elapsed: 0.1s
Encoding link 90 of 180: (26,24)
Progress: 60% – Elapsed: 0.2s
Encoding link 108 of 180: (10,12)
Progress: 70% – Elapsed: 0.2s
Encoding link 126 of 180: (21,20)
Progress: 80% – Elapsed: 0.2s
Encoding link 144 of 180: (12,5)
Progress: 90% – Elapsed: 0.2s
Encoding link 162 of 180: (25,21)
Progress: 40% – Elapsed: 0.1s
Encoding link 72 of 180: (27,19)
Progress: 50% – Elapsed: 0.1s
Encoding link 90 of 180: (26,24)
Progress: 60% – Elapsed: 0.2s
Encoding link 108 of 180: (18,21)
Progress: 70% – Elapsed: 0.2s
Encoding link 126 of 180: (1,10)
Progress: 80% – Elapsed: 0.2s
Encoding link 144 of 180: (26,10)
Progress: 10% – Elapsed: 0.1s
Encoding link 18 of 180: (7,8)
Progress: 20% – Elapsed: 0.2s
Encoding link 36 of 180: (4,13)
Progress: 30% – Elapsed: 0.2s
Encoding link 54 of 180: (12,15)
Progress: 40% – Elapsed: 0.2s
Encoding link 72 of 180: (27,19)
Progress: 50% – Elapsed: 0.2s
Encoding link 90 of 180: (26,24)
Progress: 60% – Elapsed: 0.2s
Encoding link 108 of 180: (10,12)
Progress: 70% – Elapsed: 0.2s
Encoding link 126 of 180: (25,5)
Progress: 20% – Elapsed: 0.1s
Encoding link 36 of 180: (4,13)
Progress: 30% – Elapsed: 0.1s
Encoding link 54 of 180: (12,15)
Progress: 40% – Elapsed: 0.2s
Encoding link 72 of 180: (27,19)
Progress: 50% – Elapsed: 0.2s
Encoding link 90 of 180: (26,24)
Progress: 60% – Elapsed: 0.2s
Encoding link 108 of 180: (18,25)
Progress: 70% – Elapsed: 0.2s
Encoding link 126 of 180: (10,12)
Progress: 80% – Elapsed: 0.2s
Encoding link 144 of 180: (25,1)
Progress: 40% – Elapsed: 0.1s
Encoding link 72 of 180: (27,19)
Progress: 50% – Elapsed: 0.1s
Encoding link 90 of 180: (26,24)
Progress: 60% – Elapsed: 0.1s
Encoding link 108 of 180: (12,25)
Progress: 70% – Elapsed: 0.1s
Encoding link 126 of 180: (1,22)
Progress: 20% – Elapsed: 0.1s
Encoding link 36 of 180: (4,13)
Progress: 30% – Elapsed: 0.1s
Encoding link 54 of 180: (12,15)
Progress: 40% – Elapsed: 0.1s
Encoding link 72 of 180: (27,19)
Progress: 50% – Elapsed: 0.1s
Encoding link 90 of 180: (26,24)
Progress: 60% – Elapsed: 0.2s
Encoding link 108 of 180: (21,25)
Progress: 100% – Elapsed: 0.2s
Encoding link 180 of 180: (5,20)
Done. Total time: 0.2s
Encoding 46 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Encoding link 4 of 46: (23,3)
Progress: 17% – Elapsed: 0.0s
Encoding link 8 of 46: (10,14)
Progress: 26% – Elapsed: 0.0s
Encoding link 12 of 46: (6,15)
Progress: 35% – Elapsed: 0.0s
Encoding link 16 of 46: (25,15)
Progress: 43% – Elapsed: 0.0s
Encoding link 20 of 46: (26,19)
Progress: 52% – Elapsed: 0.0s
Encoding link 24 of 46: (4,21)
Progress: 61% – Elapsed: 0.0s
Encoding link 28 of 46: (12,18)
Progress: 70% – Elapsed: 0.0s
Encoding link 32 of 46: (12,5)
Progress: 78% – Elapsed: 0.0s
Encoding link 36 of 46: (10,26)
Progress: 87% – Elapsed: 0.0s
Encoding link 40 of 46: (10,6)
Progress: 96% – Elapsed: 0.0s
Encoding link 44 of 46: (1,12)
Done. Total time: 0.0s
Progress: 100% – Elapsed: 0.2s
Encoding link 180 of 180: (4,1)
Done. Total time: 0.2s
Encoding 46 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Encoding link 4 of 46: (23,3)
Progress: 17% – Elapsed: 0.0s
Encoding link 8 of 46: (10,14)
Progress: 26% – Elapsed: 0.0s
Encoding link 12 of 46: (6,15)
Progress: 35% – Elapsed: 0.0s
Encoding link 16 of 46: (25,15)
Progress: 43% – Elapsed: 0.0s
Encoding link 20 of 46: (26,19)
Progress: 52% – Elapsed: 0.0s
Encoding link 24 of 46: (6,10)
Progress: 61% – Elapsed: 0.0s
Encoding link 28 of 46: (1,10)
Progress: 70% – Elapsed: 0.0s
Encoding link 32 of 46: (10,26)
Progress: 78% – Elapsed: 0.0s
Encoding link 36 of 46: (4,5)
Progress: 87% – Elapsed: 0.0s
Encoding link 40 of 46: (20,4)
Progress: 96% – Elapsed: 0.0s
Encoding link 44 of 46: (12,22)
Done. Total time: 0.0s
Progress: 90% – Elapsed: 0.3s
Encoding link 162 of 180: (1,6)
Progress: 100% – Elapsed: 0.3s
Encoding link 180 of 180: (25,4)
Done. Total time: 0.3s
Encoding 46 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Encoding link 4 of 46: (23,3)
Progress: 80% – Elapsed: 0.2s
Encoding link 144 of 180: (6,21)
Progress: 90% – Elapsed: 0.3s
Encoding link 162 of 180: (21,18)
Progress: 100% – Elapsed: 0.3s
Encoding link 180 of 180: (21,4)
Done. Total time: 0.3s
Encoding 46 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Encoding link 4 of 46: (23,3)
Progress: 17% – Elapsed: 0.0s
Encoding link 8 of 46: (10,14)
Progress: 90% – Elapsed: 0.2s
Encoding link 162 of 180: (4,6)
Progress: 100% – Elapsed: 0.3s
Encoding link 180 of 180: (1,6)
Done. Total time: 0.3s
Encoding 46 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Encoding link 4 of 46: (23,3)
Progress: 17% – Elapsed: 0.0s
Encoding link 8 of 46: (10,14)
Progress: 80% – Elapsed: 0.2s
Encoding link 144 of 180: (21,26)
Progress: 90% – Elapsed: 0.2s
Encoding link 162 of 180: (10,1)
Progress: 100% – Elapsed: 0.3s
Encoding link 180 of 180: (4,6)
Done. Total time: 0.3s
Encoding 46 subgraphs (K = 10)...
Progress: 70% – Elapsed: 0.2s
Encoding link 126 of 180: (1,6)
Progress: 80% – Elapsed: 0.2s
Encoding link 144 of 180: (22,12)
Progress: 90% – Elapsed: 0.3s
Encoding link 162 of 180: (20,25)
Progress: 100% – Elapsed: 0.4s
Encoding link 180 of 180: (18,22)
Done. Total time: 0.4s
Encoding 46 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Encoding link 4 of 46: (23,3)
Progress: 17% – Elapsed: 0.0s
Encoding link 8 of 46: (10,14)
Progress: 26% – Elapsed: 0.0s
Encoding link 12 of 46: (6,15)
Progress: 35% – Elapsed: 0.0s
Encoding link 16 of 46: (25,15)
Progress: 43% – Elapsed: 0.0s
Encoding link 20 of 46: (26,19)
Progress: 52% – Elapsed: 0.1s
Encoding link 24 of 46: (25,21)
Progress: 70% – Elapsed: 0.2s
Encoding link 126 of 180: (10,26)
Progress: 80% – Elapsed: 0.2s
Encoding link 144 of 180: (10,6)
Progress: 90% – Elapsed: 0.3s
Encoding link 162 of 180: (4,20)
Progress: 100% – Elapsed: 0.3s
Encoding link 180 of 180: (21,26)
Done. Total time: 0.3s
Encoding 46 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Encoding link 4 of 46: (23,3)
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       42.97% |       0.7040 |          0.1000 |
Progress: 17% – Elapsed: 0.0s
Encoding link 8 of 46: (10,14)
Progress: 26% – Elapsed: 0.0s
Encoding link 12 of 46: (6,15)
Progress: 35% – Elapsed: 0.0s
Encoding link 16 of 46: (25,15)
Progress: 43% – Elapsed: 0.0s
Encoding link 20 of 46: (26,19)
Progress: 52% – Elapsed: 0.0s
Encoding link 24 of 46: (5,18)
Progress: 61% – Elapsed: 0.0s
Encoding link 28 of 46: (25,26)
Progress: 70% – Elapsed: 0.0s
Encoding link 32 of 46: (20,6)
Progress: 78% – Elapsed: 0.0s
Encoding link 36 of 46: (21,22)
Progress: 87% – Elapsed: 0.0s
Encoding link 40 of 46: (22,21)
Progress: 96% – Elapsed: 0.1s
Encoding link 44 of 46: (4,5)
Done. Total time: 0.1s
Progress: 26% – Elapsed: 0.0s
Encoding link 12 of 46: (6,15)
Progress: 35% – Elapsed: 0.0s
Encoding link 16 of 46: (25,15)
Progress: 43% – Elapsed: 0.1s
Encoding link 20 of 46: (26,19)
Progress: 52% – Elapsed: 0.1s
Encoding link 24 of 46: (10,25)
Progress: 61% – Elapsed: 0.1s
Encoding link 28 of 46: (6,26)
Progress: 70% – Elapsed: 0.1s
Encoding link 32 of 46: (6,25)
Progress: 78% – Elapsed: 0.1s
Encoding link 36 of 46: (22,25)
Progress: 87% – Elapsed: 0.1s
Encoding link 40 of 46: (21,25)
Progress: 96% – Elapsed: 0.1s
Encoding link 44 of 46: (5,12)
Done. Total time: 0.1s
Progress: 26% – Elapsed: 0.0s
Encoding link 12 of 46: (6,15)
Progress: 35% – Elapsed: 0.0s
Encoding link 16 of 46: (25,15)
Progress: 43% – Elapsed: 0.0s
Encoding link 20 of 46: (26,19)
Progress: 52% – Elapsed: 0.0s
Encoding link 24 of 46: (1,22)
Progress: 61% – Elapsed: 0.1s
Encoding link 28 of 46: (20,26)
Progress: 70% – Elapsed: 0.1s
Encoding link 32 of 46: (6,26)
Progress: 78% – Elapsed: 0.1s
Encoding link 36 of 46: (25,26)
Progress: 87% – Elapsed: 0.1s
Encoding link 40 of 46: (5,20)
Progress: 96% – Elapsed: 0.1s
Encoding link 44 of 46: (25,21)
Done. Total time: 0.1s
Progress: 9% – Elapsed: 0.0s
Encoding link 4 of 46: (23,3)
Progress: 17% – Elapsed: 0.0s
Encoding link 8 of 46: (10,14)
Progress: 26% – Elapsed: 0.0s
Encoding link 12 of 46: (6,15)
Progress: 35% – Elapsed: 0.0s
Encoding link 16 of 46: (25,15)
Progress: 43% – Elapsed: 0.1s
Encoding link 20 of 46: (26,19)
Progress: 52% – Elapsed: 0.1s
Encoding link 24 of 46: (5,4)
Progress: 61% – Elapsed: 0.1s
Encoding link 28 of 46: (18,1)
Progress: 17% – Elapsed: 0.0s
Encoding link 8 of 46: (10,14)
Progress: 26% – Elapsed: 0.0s
Encoding link 12 of 46: (6,15)
Progress: 35% – Elapsed: 0.0s
Encoding link 16 of 46: (25,15)
Progress: 43% – Elapsed: 0.0s
Encoding link 20 of 46: (26,19)
Progress: 52% – Elapsed: 0.0s
Encoding link 24 of 46: (25,6)
Progress: 61% – Elapsed: 0.0s
Encoding link 28 of 46: (22,18)
Progress: 70% – Elapsed: 0.1s
Encoding link 32 of 46: (18,1)
Progress: 70% – Elapsed: 0.1s
Encoding link 32 of 46: (5,22)
Progress: 78% – Elapsed: 0.2s
Encoding link 36 of 46: (10,4)
Progress: 61% – Elapsed: 0.1s
Encoding link 28 of 46: (25,26)
Progress: 70% – Elapsed: 0.2s
Encoding link 32 of 46: (25,1)
Progress: 78% – Elapsed: 0.2s
Encoding link 36 of 46: (18,5)
Progress: 87% – Elapsed: 0.2s
Encoding link 40 of 46: (4,22)
Progress: 96% – Elapsed: 0.2s
Encoding link 44 of 46: (26,12)
Done. Total time: 0.2s
Progress: 78% – Elapsed: 0.1s
Encoding link 36 of 46: (26,25)
Progress: 87% – Elapsed: 0.1s
Encoding link 40 of 46: (10,25)
Progress: 96% – Elapsed: 0.1s
Encoding link 44 of 46: (1,10)
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       52.34% |       0.6940 |          0.1000 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       42.97% |       0.7100 |          0.1000 |
Progress: 87% – Elapsed: 0.3s
Encoding link 40 of 46: (21,12)
Progress: 96% – Elapsed: 0.4s
Encoding link 44 of 46: (1,20)
Done. Total time: 0.4s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       49.22% |       0.7147 |          0.1000 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       53.12% |       0.7046 |          0.1000 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       49.22% |       0.7189 |          0.1000 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       55.47% |       0.6941 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0025 |          0.0656 |
|      50 |          50 |       00:00:00 |       99.22% |       0.0142 |          0.0656 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0027 |          0.0656 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0022 |          0.0656 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       28.91% |       0.7491 |          0.1000 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0007 |          0.0387 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0040 |          0.0656 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0022 |          0.0656 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0018 |          0.0656 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0008 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0028 |          0.0387 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0007 |          0.0387 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0009 |          0.0387 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0006 |          0.0387 |
|     150 |         150 |       00:00:01 |      100.00% |       0.0016 |          0.0229 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0007 |          0.0229 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0007 |          0.0387 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0003 |          0.0387 |
|     150 |         150 |       00:00:01 |      100.00% |       0.0005 |          0.0229 |
|     150 |         150 |       00:00:01 |      100.00% |       0.0005 |          0.0229 |
|     150 |         150 |       00:00:01 |      100.00% |       0.0005 |          0.0229 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0005 |          0.0387 |
|     150 |         150 |       00:00:01 |      100.00% |       0.0005 |          0.0229 |
|     150 |         150 |       00:00:01 |      100.00% |       0.0002 |          0.0229 |
|     200 |         200 |       00:00:02 |      100.00% |       0.0013 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     200 |         200 |       00:00:02 |      100.00% |       0.0004 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     200 |         200 |       00:00:01 |      100.00% |       0.0006 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     200 |         200 |       00:00:01 |      100.00% |       0.0004 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     200 |         200 |       00:00:01 |      100.00% |       0.0004 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     150 |         150 |       00:00:01 |      100.00% |       0.0004 |          0.0229 |
Best Threshold: 0.65, Precision: 0.9524, Recall: 0.8696, F1-Score: 0.9091
AUC: 0.9698
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.8696, F1-Score: 0.9302
AUC: 0.9773
Best Threshold: 0.10, Precision: 0.9545, Recall: 0.9130, F1-Score: 0.9333
AUC: 0.9896
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.8696, F1-Score: 0.9302
AUC: 0.9745
|     200 |         200 |       00:00:02 |      100.00% |       0.0005 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
    "Experiment "    "9"    " (strategy: "    "random"    ") — Running WLNM..."

Warning: Not enough negative links. Reducing k...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',131,0)">line 131</a>)
[sample_neg] Final link counts:
    Train Positive: 90
    Train Negative: 90
    Test  Positive: 23
    Test  Negative: 23
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 180 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 18 of 180: (7,8)
Progress: 20% – Elapsed: 0.1s
Encoding link 36 of 180: (4,13)
Progress: 30% – Elapsed: 0.1s
Encoding link 54 of 180: (12,15)
Progress: 40% – Elapsed: 0.1s
Encoding link 72 of 180: (27,19)
Progress: 50% – Elapsed: 0.1s
Encoding link 90 of 180: (26,24)
Progress: 60% – Elapsed: 0.1s
Encoding link 108 of 180: (20,18)
Best Threshold: 0.10, Precision: 0.9500, Recall: 0.8261, F1-Score: 0.8837
AUC: 0.9773
|     200 |         200 |       00:00:01 |      100.00% |       0.0002 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Progress: 70% – Elapsed: 0.1s
Encoding link 126 of 180: (18,5)
Progress: 80% – Elapsed: 0.1s
Encoding link 144 of 180: (25,21)
Progress: 90% – Elapsed: 0.1s
Encoding link 162 of 180: (5,22)
Progress: 100% – Elapsed: 0.1s
Encoding link 180 of 180: (18,10)
Done. Total time: 0.1s
Encoding 46 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Encoding link 4 of 46: (23,3)
Progress: 17% – Elapsed: 0.0s
Encoding link 8 of 46: (10,14)
Progress: 26% – Elapsed: 0.0s
Encoding link 12 of 46: (6,15)
Progress: 35% – Elapsed: 0.0s
Encoding link 16 of 46: (25,15)
Progress: 43% – Elapsed: 0.0s
Encoding link 20 of 46: (26,19)
Progress: 52% – Elapsed: 0.0s
Encoding link 24 of 46: (1,18)
Progress: 61% – Elapsed: 0.0s
Encoding link 28 of 46: (1,5)
Progress: 70% – Elapsed: 0.0s
Encoding link 32 of 46: (18,22)
Progress: 78% – Elapsed: 0.0s
Encoding link 36 of 46: (6,18)
Progress: 87% – Elapsed: 0.0s
Encoding link 40 of 46: (21,1)
Progress: 96% – Elapsed: 0.0s
Encoding link 44 of 46: (20,4)
Done. Total time: 0.0s
|     200 |         200 |       00:00:02 |      100.00% |       0.0003 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9545, Recall: 0.9130, F1-Score: 0.9333
AUC: 0.9811
Best Threshold: 0.20, Precision: 1.0000, Recall: 0.8696, F1-Score: 0.9302
AUC: 0.9735
Best Threshold: 0.80, Precision: 0.9500, Recall: 0.8261, F1-Score: 0.8837
AUC: 0.9423
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       44.53% |       0.7045 |          0.1000 |
  Columns 1 through 4

    "Experiment "    "10"    " (strategy: "    "random"

  Column 5

    ") — Running WLNM..."

Warning: Not enough negative links. Reducing k...
> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',131,0)">line 131</a>)
[sample_neg] Final link counts:
    Train Positive: 90
    Train Negative: 90
    Test  Positive: 23
    Test  Negative: 23
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 180 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.1s
Encoding link 18 of 180: (7,8)
Progress: 20% – Elapsed: 0.1s
Encoding link 36 of 180: (4,13)
Progress: 30% – Elapsed: 0.1s
Encoding link 54 of 180: (12,15)
Progress: 40% – Elapsed: 0.1s
Encoding link 72 of 180: (27,19)
Progress: 50% – Elapsed: 0.1s
Encoding link 90 of 180: (26,24)
Progress: 60% – Elapsed: 0.2s
Encoding link 108 of 180: (22,5)
Progress: 70% – Elapsed: 0.2s
Encoding link 126 of 180: (26,10)
Progress: 80% – Elapsed: 0.2s
Encoding link 144 of 180: (10,1)
|      50 |          50 |       00:00:00 |      100.00% |       0.0020 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0005 |          0.0387 |
Progress: 90% – Elapsed: 0.2s
Encoding link 162 of 180: (5,4)
Progress: 100% – Elapsed: 0.2s
Encoding link 180 of 180: (1,21)
Done. Total time: 0.2s
Encoding 46 subgraphs (K = 10)...
Progress: 9% – Elapsed: 0.0s
Encoding link 4 of 46: (23,3)
Progress: 17% – Elapsed: 0.0s
Encoding link 8 of 46: (10,14)
Progress: 26% – Elapsed: 0.0s
Encoding link 12 of 46: (6,15)
Progress: 35% – Elapsed: 0.0s
Encoding link 16 of 46: (25,15)
Progress: 43% – Elapsed: 0.0s
Encoding link 20 of 46: (26,19)
Progress: 52% – Elapsed: 0.0s
Encoding link 24 of 46: (26,5)
Progress: 61% – Elapsed: 0.0s
Encoding link 28 of 46: (21,10)
Progress: 70% – Elapsed: 0.0s
Encoding link 32 of 46: (12,25)
Progress: 78% – Elapsed: 0.0s
Encoding link 36 of 46: (12,20)
Progress: 87% – Elapsed: 0.0s
Encoding link 40 of 46: (21,22)
Progress: 96% – Elapsed: 0.0s
Encoding link 44 of 46: (18,22)
Done. Total time: 0.1s
|     150 |         150 |       00:00:00 |      100.00% |       0.0004 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0004 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9545, Recall: 0.9130, F1-Score: 0.9333
AUC: 0.9707
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       57.03% |       0.6891 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0031 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0008 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0006 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0005 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.7826, F1-Score: 0.8780
AUC: 0.9764
