Processing dataset: F2P3_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 52 / 52 (100.0%)
[DivideNet] Attempts made: 149 | Failed attempts: 97
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 214
    Train Negative: 428
    Test  Positive: 52
    Test  Negative: 104
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 642 subgraphs (K = 10)...
    "Experiment "    "7"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 214
    Train Negative: 428
    Test  Positive: 52
    Test  Negative: 104
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 642 subgraphs (K = 10)...
    "Experiment "    "2"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 214
    Train Negative: 428
    Test  Positive: 52
    Test  Negative: 104
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 642 subgraphs (K = 10)...
    "Experiment "    "5"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 214
    Train Negative: 428
    Test  Positive: 52
    Test  Negative: 104
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 642 subgraphs (K = 10)...
    "Experiment "    "6"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 214
    Train Negative: 428
    Test  Positive: 52
    Test  Negative: 104
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 642 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.3s
    "Experiment "    "8"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 214
    Train Negative: 428
    Test  Positive: 52
    Test  Negative: 104
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 642 subgraphs (K = 10)...
    "Experiment "    "4"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 214
    Train Negative: 428
    Test  Positive: 52
    Test  Negative: 104
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 642 subgraphs (K = 10)...
    "Experiment "    "3"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 214
    Train Negative: 428
    Test  Positive: 52
    Test  Negative: 104
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 642 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.5s
Progress: 10% – Elapsed: 0.4s
Progress: 10% – Elapsed: 0.3s
Progress: 10% – Elapsed: 0.4s
Progress: 10% – Elapsed: 0.4s
Progress: 10% – Elapsed: 0.3s
Progress: 20% – Elapsed: 0.5s
Progress: 20% – Elapsed: 0.5s
Progress: 10% – Elapsed: 0.4s
Progress: 20% – Elapsed: 0.6s
Progress: 20% – Elapsed: 0.5s
Progress: 30% – Elapsed: 0.7s
Progress: 20% – Elapsed: 0.5s
Progress: 20% – Elapsed: 0.6s
Progress: 30% – Elapsed: 0.7s
Progress: 20% – Elapsed: 0.5s
Progress: 20% – Elapsed: 0.5s
Progress: 30% – Elapsed: 0.7s
Progress: 30% – Elapsed: 0.7s
Progress: 40% – Elapsed: 0.8s
Progress: 30% – Elapsed: 0.6s
Progress: 30% – Elapsed: 0.8s
Progress: 40% – Elapsed: 0.8s
Progress: 30% – Elapsed: 0.6s
Progress: 30% – Elapsed: 0.6s
Progress: 40% – Elapsed: 0.9s
Progress: 40% – Elapsed: 0.8s
Progress: 50% – Elapsed: 0.9s
Progress: 60% – Elapsed: 1.0s
Progress: 40% – Elapsed: 0.8s
Progress: 40% – Elapsed: 0.8s
Progress: 50% – Elapsed: 0.9s
Progress: 50% – Elapsed: 1.0s
Progress: 50% – Elapsed: 0.9s
Progress: 50% – Elapsed: 0.9s
Progress: 40% – Elapsed: 0.9s
Progress: 50% – Elapsed: 1.1s
Progress: 50% – Elapsed: 0.9s
Progress: 60% – Elapsed: 1.1s
Progress: 40% – Elapsed: 1.0s
Progress: 60% – Elapsed: 1.2s
Progress: 70% – Elapsed: 1.2s
Progress: 60% – Elapsed: 1.1s
Progress: 60% – Elapsed: 1.2s
Progress: 70% – Elapsed: 1.2s
Progress: 50% – Elapsed: 1.1s
Progress: 60% – Elapsed: 1.5s
Progress: 80% – Elapsed: 1.3s
Progress: 70% – Elapsed: 1.3s
Progress: 60% – Elapsed: 1.4s
Progress: 60% – Elapsed: 1.4s
Progress: 70% – Elapsed: 1.6s
Progress: 90% – Elapsed: 1.6s
Progress: 80% – Elapsed: 1.5s
Progress: 70% – Elapsed: 1.6s
Progress: 80% – Elapsed: 1.5s
Progress: 70% – Elapsed: 1.5s
Progress: 80% – Elapsed: 1.6s
Progress: 70% – Elapsed: 1.7s
Progress: 90% – Elapsed: 1.8s
Progress: 70% – Elapsed: 1.6s
Progress: 100% – Elapsed: 1.9s
Done. Total time: 1.9s
Encoding 156 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.1s
Progress: 90% – Elapsed: 1.7s
Progress: 90% – Elapsed: 1.9s
Progress: 80% – Elapsed: 1.9s
Progress: 100% – Elapsed: 1.9s
Done. Total time: 1.9s
Encoding 156 subgraphs (K = 10)...
Progress: 80% – Elapsed: 1.9s
Progress: 100% – Elapsed: 1.9s
Done. Total time: 1.9s
Encoding 156 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.1s
Progress: 80% – Elapsed: 1.9s
Progress: 80% – Elapsed: 1.8s
Progress: 100% – Elapsed: 2.0s
Done. Total time: 2.1s
Encoding 156 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 90% – Elapsed: 2.1s
Progress: 29% – Elapsed: 0.1s
Progress: 38% – Elapsed: 0.2s
Progress: 48% – Elapsed: 0.2s
Progress: 58% – Elapsed: 0.3s
Progress: 67% – Elapsed: 0.3s
Progress: 77% – Elapsed: 0.4s
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.1s
Progress: 90% – Elapsed: 2.0s
Progress: 38% – Elapsed: 0.2s
Progress: 90% – Elapsed: 2.0s
Progress: 90% – Elapsed: 1.9s
Progress: 19% – Elapsed: 0.1s
Progress: 29% – Elapsed: 0.1s
Progress: 38% – Elapsed: 0.1s
Progress: 87% – Elapsed: 0.4s
Progress: 29% – Elapsed: 0.2s
Progress: 38% – Elapsed: 0.2s
Progress: 48% – Elapsed: 0.2s
Progress: 58% – Elapsed: 0.3s
Progress: 100% – Elapsed: 2.2s
Done. Total time: 2.2s
Encoding 156 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.1s
Progress: 48% – Elapsed: 0.2s
Progress: 58% – Elapsed: 0.2s
Progress: 67% – Elapsed: 0.3s
Progress: 100% – Elapsed: 2.1s
Done. Total time: 2.1s
Encoding 156 subgraphs (K = 10)...
Progress: 48% – Elapsed: 0.2s
Progress: 58% – Elapsed: 0.2s
Progress: 100% – Elapsed: 2.2s
Done. Total time: 2.2s
Encoding 156 subgraphs (K = 10)...
Progress: 96% – Elapsed: 0.5s
Done. Total time: 0.5s
Progress: 67% – Elapsed: 0.3s
Progress: 77% – Elapsed: 0.3s
Progress: 19% – Elapsed: 0.2s
Progress: 29% – Elapsed: 0.2s
Progress: 38% – Elapsed: 0.2s
Progress: 77% – Elapsed: 0.3s
Progress: 87% – Elapsed: 0.4s
Progress: 100% – Elapsed: 2.2s
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.1s
Progress: 67% – Elapsed: 0.3s
Progress: 10% – Elapsed: 0.1s
Progress: 19% – Elapsed: 0.2s
Progress: 87% – Elapsed: 0.4s
Progress: 96% – Elapsed: 0.4s
Done. Total time: 0.5s
Done. Total time: 2.3s
Encoding 156 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.1s
Progress: 29% – Elapsed: 0.1s
Progress: 38% – Elapsed: 0.1s
Progress: 38% – Elapsed: 0.1s
Progress: 48% – Elapsed: 0.2s
Progress: 77% – Elapsed: 0.4s
Progress: 87% – Elapsed: 0.4s
Progress: 29% – Elapsed: 0.2s
Progress: 96% – Elapsed: 0.5s
Done. Total time: 0.5s
Progress: 48% – Elapsed: 0.3s
Progress: 58% – Elapsed: 0.4s
Progress: 96% – Elapsed: 0.6s
Done. Total time: 0.6s
Progress: 38% – Elapsed: 0.3s
Progress: 48% – Elapsed: 0.3s
Progress: 58% – Elapsed: 0.4s
Progress: 58% – Elapsed: 0.4s
Progress: 67% – Elapsed: 0.4s
Progress: 77% – Elapsed: 0.4s
Progress: 48% – Elapsed: 0.3s
Progress: 58% – Elapsed: 0.3s
Progress: 67% – Elapsed: 0.4s
Progress: 77% – Elapsed: 0.4s
Progress: 87% – Elapsed: 0.4s
Progress: 67% – Elapsed: 0.4s
Progress: 77% – Elapsed: 0.5s
Progress: 87% – Elapsed: 0.5s
Progress: 67% – Elapsed: 0.4s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       32.81% |       0.7566 |          0.1000 |
Progress: 87% – Elapsed: 0.5s
Progress: 96% – Elapsed: 0.6s
Done. Total time: 0.6s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       66.41% |       0.6462 |          0.1000 |
Progress: 96% – Elapsed: 0.5s
Progress: 96% – Elapsed: 0.6s
Done. Total time: 0.7s
Progress: 77% – Elapsed: 0.8s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       45.31% |       0.7214 |          0.1000 |
Done. Total time: 0.5s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       32.03% |       0.7349 |          0.1000 |
Progress: 87% – Elapsed: 0.8s
Progress: 96% – Elapsed: 0.9s
Done. Total time: 1.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       35.16% |       0.7267 |          0.1000 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       64.84% |       0.6642 |          0.1000 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       47.66% |       0.6939 |          0.1000 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       37.50% |       0.7115 |          0.1000 |
|      10 |          50 |       00:00:00 |       85.16% |       0.4509 |          0.1000 |
|      10 |          50 |       00:00:00 |       86.72% |       0.3462 |          0.1000 |
|      10 |          50 |       00:00:00 |       90.62% |       0.1927 |          0.1000 |
|      10 |          50 |       00:00:00 |       86.72% |       0.3347 |          0.1000 |
|      10 |          50 |       00:00:00 |       93.75% |       0.1680 |          0.1000 |
|      10 |          50 |       00:00:00 |       92.19% |       0.2705 |          0.1000 |
|      10 |          50 |       00:00:00 |       88.28% |       0.2842 |          0.1000 |
|      20 |         100 |       00:00:01 |       86.72% |       0.2617 |          0.0900 |
|      20 |         100 |       00:00:01 |       90.62% |       0.2510 |          0.0900 |
|      10 |          50 |       00:00:00 |       87.50% |       0.2827 |          0.1000 |
|      20 |         100 |       00:00:01 |       95.31% |       0.1425 |          0.0900 |
|      20 |         100 |       00:00:01 |       89.84% |       0.2445 |          0.0900 |
|      20 |         100 |       00:00:01 |       92.97% |       0.2132 |          0.0900 |
|      20 |         100 |       00:00:00 |       92.19% |       0.2926 |          0.0900 |
|      30 |         150 |       00:00:01 |       89.06% |       0.2428 |          0.0810 |
|      30 |         150 |       00:00:01 |       89.84% |       0.2775 |          0.0810 |
|      20 |         100 |       00:00:01 |       91.41% |       0.2442 |          0.0900 |
|      30 |         150 |       00:00:01 |       95.31% |       0.1303 |          0.0810 |
|      20 |         100 |       00:00:01 |       96.09% |       0.1361 |          0.0900 |
|      30 |         150 |       00:00:01 |       92.97% |       0.1988 |          0.0810 |
|      30 |         150 |       00:00:01 |       89.84% |       0.2411 |          0.0810 |
|      30 |         150 |       00:00:01 |       91.41% |       0.2299 |          0.0810 |
|      40 |         200 |       00:00:02 |       96.09% |       0.1268 |          0.0729 |
|      30 |         150 |       00:00:01 |       96.09% |       0.1483 |          0.0810 |
|      30 |         150 |       00:00:01 |       91.41% |       0.2544 |          0.0810 |
|      40 |         200 |       00:00:02 |       90.62% |       0.2505 |          0.0729 |
|      40 |         200 |       00:00:02 |       89.84% |       0.2339 |          0.0729 |
|      40 |         200 |       00:00:01 |       92.97% |       0.2176 |          0.0729 |
|      40 |         200 |       00:00:02 |       89.06% |       0.2343 |          0.0729 |
|      50 |         250 |       00:00:02 |       91.41% |       0.2194 |          0.0656 |
|      40 |         200 |       00:00:01 |       90.62% |       0.2167 |          0.0729 |
|      50 |         250 |       00:00:02 |       96.09% |       0.1245 |          0.0656 |
|      60 |         300 |       00:00:02 |       96.09% |       0.1229 |          0.0590 |
|      40 |         200 |       00:00:01 |       96.09% |       0.1294 |          0.0729 |
|      40 |         200 |       00:00:01 |       92.97% |       0.1958 |          0.0729 |
|      50 |         250 |       00:00:02 |       90.62% |       0.2351 |          0.0656 |
|      50 |         250 |       00:00:01 |       92.97% |       0.2091 |          0.0656 |
|      50 |         250 |       00:00:02 |       89.06% |       0.2302 |          0.0656 |
|      50 |         250 |       00:00:02 |       91.41% |       0.2107 |          0.0656 |
|      50 |         250 |       00:00:02 |       96.09% |       0.1288 |          0.0656 |
|      50 |         250 |       00:00:02 |       92.97% |       0.1946 |          0.0656 |
|      60 |         300 |       00:00:02 |       91.41% |       0.2243 |          0.0590 |
|      70 |         350 |       00:00:02 |       96.09% |       0.1222 |          0.0531 |
|      60 |         300 |       00:00:02 |       96.88% |       0.1257 |          0.0590 |
|      60 |         300 |       00:00:02 |       90.62% |       0.2256 |          0.0590 |
|      60 |         300 |       00:00:02 |       92.97% |       0.1926 |          0.0590 |
|      60 |         300 |       00:00:03 |       89.06% |       0.2348 |          0.0590 |
|      70 |         350 |       00:00:02 |       91.41% |       0.2146 |          0.0531 |
|      60 |         300 |       00:00:02 |       91.41% |       0.2104 |          0.0590 |
|      80 |         400 |       00:00:03 |       96.09% |       0.1217 |          0.0478 |
|      60 |         300 |       00:00:02 |       92.97% |       0.1937 |          0.0590 |
|      70 |         350 |       00:00:02 |       90.62% |       0.2245 |          0.0531 |
|      70 |         350 |       00:00:02 |       92.97% |       0.1906 |          0.0531 |
|      70 |         350 |       00:00:03 |       89.06% |       0.2370 |          0.0531 |
|      80 |         400 |       00:00:03 |       91.41% |       0.2111 |          0.0478 |
|      70 |         350 |       00:00:02 |       91.41% |       0.2080 |          0.0531 |
|      70 |         350 |       00:00:02 |       96.88% |       0.1213 |          0.0531 |
|      80 |         400 |       00:00:03 |       90.62% |       0.2239 |          0.0478 |
|      90 |         450 |       00:00:03 |       96.09% |       0.1219 |          0.0430 |
|      70 |         350 |       00:00:02 |       92.97% |       0.1907 |          0.0531 |
|      90 |         450 |       00:00:03 |       91.41% |       0.2085 |          0.0430 |
|      80 |         400 |       00:00:03 |       91.41% |       0.2078 |          0.0478 |
|      80 |         400 |       00:00:03 |       96.88% |       0.1213 |          0.0478 |
|      80 |         400 |       00:00:02 |       92.97% |       0.1908 |          0.0478 |
|      80 |         400 |       00:00:04 |       89.06% |       0.2269 |          0.0478 |
|     100 |         500 |       00:00:04 |       96.09% |       0.1212 |          0.0387 |
|      80 |         400 |       00:00:03 |       92.97% |       0.1896 |          0.0478 |
|      90 |         450 |       00:00:03 |       90.62% |       0.2238 |          0.0430 |
|      90 |         450 |       00:00:04 |       89.06% |       0.2288 |          0.0430 |
|     100 |         500 |       00:00:04 |       91.41% |       0.2075 |          0.0387 |
|      90 |         450 |       00:00:03 |       91.41% |       0.2065 |          0.0430 |
|      90 |         450 |       00:00:03 |       96.88% |       0.1210 |          0.0430 |
|      90 |         450 |       00:00:03 |       92.97% |       0.1894 |          0.0430 |
|     110 |         550 |       00:00:04 |       91.41% |       0.2055 |          0.0349 |
|     110 |         550 |       00:00:04 |       96.09% |       0.1210 |          0.0349 |
|      90 |         450 |       00:00:03 |       92.97% |       0.1909 |          0.0430 |
|     100 |         500 |       00:00:04 |       90.62% |       0.2234 |          0.0387 |
|     100 |         500 |       00:00:04 |       91.41% |       0.2055 |          0.0387 |
|     120 |         600 |       00:00:04 |       96.09% |       0.1212 |          0.0314 |
|     100 |         500 |       00:00:04 |       96.88% |       0.1236 |          0.0387 |
|     100 |         500 |       00:00:04 |       89.06% |       0.2274 |          0.0387 |
|     100 |         500 |       00:00:04 |       93.75% |       0.1896 |          0.0387 |
|     110 |         550 |       00:00:04 |       90.62% |       0.2231 |          0.0349 |
|     100 |         500 |       00:00:04 |       92.97% |       0.1914 |          0.0387 |
|     120 |         600 |       00:00:04 |       91.41% |       0.2042 |          0.0314 |
|     130 |         650 |       00:00:05 |       96.09% |       0.1207 |          0.0282 |
|     110 |         550 |       00:00:04 |       96.88% |       0.1168 |          0.0349 |
|     110 |         550 |       00:00:04 |       92.19% |       0.2045 |          0.0349 |
|     120 |         600 |       00:00:05 |       90.62% |       0.2227 |          0.0314 |
|     110 |         550 |       00:00:04 |       92.97% |       0.1918 |          0.0349 |
|     110 |         550 |       00:00:05 |       89.06% |       0.2132 |          0.0349 |
|     110 |         550 |       00:00:04 |       93.75% |       0.1880 |          0.0349 |
|     120 |         600 |       00:00:05 |       89.06% |       0.2223 |          0.0314 |
|     130 |         650 |       00:00:05 |       91.41% |       0.2028 |          0.0282 |
|     120 |         600 |       00:00:05 |       92.19% |       0.2042 |          0.0314 |
|     130 |         650 |       00:00:05 |       90.62% |       0.2232 |          0.0282 |
|     120 |         600 |       00:00:05 |       92.97% |       0.1873 |          0.0314 |
|     140 |         700 |       00:00:05 |       96.09% |       0.1206 |          0.0254 |
|     120 |         600 |       00:00:05 |       96.88% |       0.1180 |          0.0314 |
|     120 |         600 |       00:00:05 |       93.75% |       0.1880 |          0.0314 |
|     130 |         650 |       00:00:06 |       89.84% |       0.2209 |          0.0282 |
|     140 |         700 |       00:00:05 |       91.41% |       0.2018 |          0.0254 |
|     140 |         700 |       00:00:06 |       90.62% |       0.2226 |          0.0254 |
|     130 |         650 |       00:00:05 |       93.75% |       0.1858 |          0.0282 |
|     130 |         650 |       00:00:05 |       92.19% |       0.2038 |          0.0282 |
|     150 |         750 |       00:00:06 |       96.09% |       0.1206 |          0.0229 |
|     130 |         650 |       00:00:05 |       96.88% |       0.1158 |          0.0282 |
|     130 |         650 |       00:00:05 |       93.75% |       0.1902 |          0.0282 |
|     140 |         700 |       00:00:06 |       89.84% |       0.2211 |          0.0254 |
|     150 |         750 |       00:00:06 |       91.41% |       0.2012 |          0.0229 |
|     140 |         700 |       00:00:06 |       92.19% |       0.2035 |          0.0254 |
|     150 |         750 |       00:00:06 |       90.62% |       0.2223 |          0.0229 |
|     140 |         700 |       00:00:05 |       93.75% |       0.1849 |          0.0254 |
|     160 |         800 |       00:00:06 |       96.09% |       0.1203 |          0.0206 |
|     140 |         700 |       00:00:06 |       96.88% |       0.1155 |          0.0254 |
|     140 |         700 |       00:00:06 |       93.75% |       0.1874 |          0.0254 |
|     160 |         800 |       00:00:06 |       91.41% |       0.2013 |          0.0206 |
|     150 |         750 |       00:00:06 |       92.19% |       0.2031 |          0.0229 |
|     150 |         750 |       00:00:06 |       93.75% |       0.1834 |          0.0229 |
|     150 |         750 |       00:00:07 |       89.84% |       0.2182 |          0.0229 |
|     150 |         750 |       00:00:06 |       93.75% |       0.1858 |          0.0229 |
|     160 |         800 |       00:00:07 |       90.62% |       0.2223 |          0.0206 |
|     170 |         850 |       00:00:07 |       91.41% |       0.2006 |          0.0185 |
|     160 |         800 |       00:00:07 |       92.19% |       0.2031 |          0.0206 |
|     170 |         850 |       00:00:07 |       96.09% |       0.1202 |          0.0185 |
|     150 |         750 |       00:00:06 |       96.88% |       0.1127 |          0.0229 |
|     160 |         800 |       00:00:07 |       89.84% |       0.2178 |          0.0206 |
|     160 |         800 |       00:00:07 |       93.75% |       0.1853 |          0.0206 |
|     170 |         850 |       00:00:07 |       90.62% |       0.2222 |          0.0185 |
|     160 |         800 |       00:00:06 |       93.75% |       0.1835 |          0.0206 |
|     160 |         800 |       00:00:07 |       96.88% |       0.1151 |          0.0206 |
|     180 |         900 |       00:00:07 |       91.41% |       0.2003 |          0.0167 |
|     180 |         900 |       00:00:07 |       96.09% |       0.1204 |          0.0167 |
|     170 |         850 |       00:00:07 |       93.75% |       0.1821 |          0.0185 |
|     170 |         850 |       00:00:08 |       89.84% |       0.2173 |          0.0185 |
|     190 |         950 |       00:00:08 |       91.41% |       0.1997 |          0.0150 |
|     170 |         850 |       00:00:07 |       92.19% |       0.2028 |          0.0185 |
|     190 |         950 |       00:00:08 |       96.09% |       0.1202 |          0.0150 |
|     170 |         850 |       00:00:07 |       96.88% |       0.1145 |          0.0185 |
|     170 |         850 |       00:00:07 |       93.75% |       0.1854 |          0.0185 |
|     180 |         900 |       00:00:08 |       90.62% |       0.2221 |          0.0167 |
|     180 |         900 |       00:00:08 |       89.84% |       0.2173 |          0.0167 |
|     180 |         900 |       00:00:08 |       92.19% |       0.2027 |          0.0167 |
|     180 |         900 |       00:00:07 |       93.75% |       0.1819 |          0.0167 |
|     200 |        1000 |       00:00:08 |       91.41% |       0.1998 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     200 |        1000 |       00:00:08 |       96.09% |       0.1202 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     180 |         900 |       00:00:08 |       96.88% |       0.1129 |          0.0167 |
|     180 |         900 |       00:00:08 |       93.75% |       0.1870 |          0.0167 |
|     190 |         950 |       00:00:08 |       90.62% |       0.2221 |          0.0150 |
|     190 |         950 |       00:00:08 |       93.75% |       0.1858 |          0.0150 |
|     190 |         950 |       00:00:08 |       93.75% |       0.1814 |          0.0150 |
|     190 |         950 |       00:00:09 |       89.84% |       0.2190 |          0.0150 |
Best Threshold: 0.15, Precision: 0.7931, Recall: 0.8846, F1-Score: 0.8364
AUC: 0.9323
Best Threshold: 0.75, Precision: 0.8214, Recall: 0.8846, F1-Score: 0.8519
AUC: 0.9192
|     190 |         950 |       00:00:08 |       96.88% |       0.1141 |          0.0150 |
|     200 |        1000 |       00:00:08 |       90.62% |       0.2219 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     190 |         950 |       00:00:08 |       92.19% |       0.2026 |          0.0150 |
|     200 |        1000 |       00:00:09 |       89.84% |       0.2158 |          0.0135 |
|     200 |        1000 |       00:00:08 |       93.75% |       0.1851 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.15, Precision: 0.7460, Recall: 0.9038, F1-Score: 0.8174
AUC: 0.9357
|     200 |        1000 |       00:00:09 |       92.19% |       0.2024 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     200 |        1000 |       00:00:08 |       96.88% |       0.1127 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     200 |        1000 |       00:00:08 |       93.75% |       0.1812 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.25, Precision: 0.7344, Recall: 0.9038, F1-Score: 0.8103
AUC: 0.9044
Best Threshold: 0.10, Precision: 0.8000, Recall: 0.9231, F1-Score: 0.8571
AUC: 0.9364
Best Threshold: 0.15, Precision: 0.7833, Recall: 0.9038, F1-Score: 0.8393
AUC: 0.9493
Best Threshold: 0.35, Precision: 0.7541, Recall: 0.8846, F1-Score: 0.8142
AUC: 0.9259
Best Threshold: 0.15, Precision: 0.7895, Recall: 0.8654, F1-Score: 0.8257
AUC: 0.9227
    "Experiment "    "9"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 214
    Train Negative: 428
    Test  Positive: 52
    Test  Negative: 104
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 642 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.1s
Progress: 60% – Elapsed: 0.2s
Progress: 70% – Elapsed: 0.2s
  Columns 1 through 4

    "Experiment "    "10"    " (strategy: "    "random"

  Column 5

    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 214
    Train Negative: 428
    Test  Positive: 52
    Test  Negative: 104
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 642 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 20% – Elapsed: 0.1s
Progress: 30% – Elapsed: 0.1s
Progress: 40% – Elapsed: 0.1s
Progress: 50% – Elapsed: 0.2s
Progress: 60% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.3s
Progress: 100% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 156 subgraphs (K = 10)...
Progress: 70% – Elapsed: 0.2s
Progress: 80% – Elapsed: 0.2s
Progress: 90% – Elapsed: 0.3s
Progress: 100% – Elapsed: 0.3s
Done. Total time: 0.3s
Encoding 156 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.1s
Progress: 48% – Elapsed: 0.1s
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.0s
Progress: 38% – Elapsed: 0.1s
Progress: 48% – Elapsed: 0.1s
Progress: 58% – Elapsed: 0.1s
Progress: 67% – Elapsed: 0.1s
Progress: 77% – Elapsed: 0.1s
Progress: 87% – Elapsed: 0.1s
Progress: 96% – Elapsed: 0.1s
Done. Total time: 0.2s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       66.41% |       0.6764 |          0.1000 |
Progress: 58% – Elapsed: 0.1s
Progress: 67% – Elapsed: 0.1s
Progress: 77% – Elapsed: 0.1s
Progress: 87% – Elapsed: 0.1s
Progress: 96% – Elapsed: 0.1s
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       37.50% |       0.7261 |          0.1000 |
|      10 |          50 |       00:00:00 |       90.62% |       0.2588 |          0.1000 |
|      10 |          50 |       00:00:00 |       89.06% |       0.2591 |          0.1000 |
|      20 |         100 |       00:00:00 |       93.75% |       0.2381 |          0.0900 |
|      20 |         100 |       00:00:00 |       89.06% |       0.2986 |          0.0900 |
|      30 |         150 |       00:00:00 |       94.53% |       0.2091 |          0.0810 |
|      30 |         150 |       00:00:00 |       92.97% |       0.2020 |          0.0810 |
|      40 |         200 |       00:00:00 |       92.97% |       0.1879 |          0.0729 |
|      40 |         200 |       00:00:00 |       94.53% |       0.1853 |          0.0729 |
|      50 |         250 |       00:00:00 |       94.53% |       0.1836 |          0.0656 |
|      50 |         250 |       00:00:00 |       92.97% |       0.1787 |          0.0656 |
|      60 |         300 |       00:00:00 |       92.97% |       0.1725 |          0.0590 |
|      60 |         300 |       00:00:00 |       94.53% |       0.1678 |          0.0590 |
|      70 |         350 |       00:00:00 |       94.53% |       0.1651 |          0.0531 |
|      70 |         350 |       00:00:00 |       93.75% |       0.1685 |          0.0531 |
|      80 |         400 |       00:00:01 |       93.75% |       0.1659 |          0.0478 |
|      90 |         450 |       00:00:01 |       93.75% |       0.1643 |          0.0430 |
|      80 |         400 |       00:00:01 |       95.31% |       0.1645 |          0.0478 |
|      90 |         450 |       00:00:01 |       95.31% |       0.1546 |          0.0430 |
|     100 |         500 |       00:00:01 |       95.31% |       0.1542 |          0.0387 |
|     100 |         500 |       00:00:01 |       93.75% |       0.1633 |          0.0387 |
|     110 |         550 |       00:00:01 |       93.75% |       0.1626 |          0.0349 |
|     110 |         550 |       00:00:01 |       95.31% |       0.1529 |          0.0349 |
|     120 |         600 |       00:00:01 |       93.75% |       0.1617 |          0.0314 |
|     120 |         600 |       00:00:01 |       95.31% |       0.1454 |          0.0314 |
|     130 |         650 |       00:00:02 |       95.31% |       0.1557 |          0.0282 |
|     130 |         650 |       00:00:02 |       93.75% |       0.1610 |          0.0282 |
|     140 |         700 |       00:00:02 |       95.31% |       0.1487 |          0.0254 |
|     140 |         700 |       00:00:02 |       93.75% |       0.1604 |          0.0254 |
|     150 |         750 |       00:00:02 |       95.31% |       0.1472 |          0.0229 |
|     150 |         750 |       00:00:02 |       93.75% |       0.1601 |          0.0229 |
|     160 |         800 |       00:00:02 |       93.75% |       0.1598 |          0.0206 |
|     160 |         800 |       00:00:02 |       95.31% |       0.1471 |          0.0206 |
|     170 |         850 |       00:00:02 |       95.31% |       0.1464 |          0.0185 |
|     170 |         850 |       00:00:02 |       93.75% |       0.1594 |          0.0185 |
|     180 |         900 |       00:00:02 |       93.75% |       0.1589 |          0.0167 |
|     180 |         900 |       00:00:02 |       95.31% |       0.1429 |          0.0167 |
|     190 |         950 |       00:00:03 |       93.75% |       0.1588 |          0.0150 |
|     190 |         950 |       00:00:03 |       95.31% |       0.1453 |          0.0150 |
|     200 |        1000 |       00:00:03 |       93.75% |       0.1585 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.30, Precision: 0.8214, Recall: 0.8846, F1-Score: 0.8519
AUC: 0.9430
|     200 |        1000 |       00:00:03 |       95.31% |       0.1460 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.25, Precision: 0.7895, Recall: 0.8654, F1-Score: 0.8257
AUC: 0.9144
