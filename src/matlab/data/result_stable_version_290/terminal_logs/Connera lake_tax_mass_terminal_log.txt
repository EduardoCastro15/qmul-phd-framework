Processing dataset: Connera lake_tax_massProcessing with K = 10, strategy: random
[DivideNet] Using directed logic. Connectivity check: 1
[DivideNet] Test links accepted: 83 / 83 (100.0%)
[DivideNet] Attempts made: 171 | Failed attempts: 88
    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 335
    Train Negative: 670
    Test  Positive: 83
    Test  Negative: 166
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 1005 subgraphs (K = 10)...
    "Experiment "    "2"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 335
    Train Negative: 670
    Test  Positive: 83
    Test  Negative: 166
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 1005 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.2s
    "Experiment "    "4"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 335
    Train Negative: 670
    Test  Positive: 83
    Test  Negative: 166
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 1005 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.2s
    "Experiment "    "7"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 335
    Train Negative: 670
    Test  Positive: 83
    Test  Negative: 166
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 1005 subgraphs (K = 10)...
    "Experiment "    "8"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 335
    Train Negative: 670
    Test  Positive: 83
    Test  Negative: 166
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 1005 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.2s
    "Experiment "    "5"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 335
    Train Negative: 670
    Test  Positive: 83
    Test  Negative: 166
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 1005 subgraphs (K = 10)...
    "Experiment "    "3"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 335
    Train Negative: 670
    Test  Positive: 83
    Test  Negative: 166
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 1005 subgraphs (K = 10)...
    "Experiment "    "6"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 335
    Train Negative: 670
    Test  Positive: 83
    Test  Negative: 166
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 1005 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.2s
Progress: 20% – Elapsed: 0.4s
Progress: 30% – Elapsed: 0.4s
Progress: 10% – Elapsed: 0.1s
Progress: 20% – Elapsed: 0.2s
Progress: 20% – Elapsed: 0.3s
Progress: 20% – Elapsed: 0.3s
Progress: 20% – Elapsed: 0.3s
Progress: 10% – Elapsed: 0.2s
Progress: 20% – Elapsed: 0.3s
Progress: 10% – Elapsed: 0.2s
Progress: 10% – Elapsed: 0.2s
Progress: 20% – Elapsed: 0.3s
Progress: 30% – Elapsed: 0.3s
Progress: 30% – Elapsed: 0.4s
Progress: 40% – Elapsed: 0.5s
Progress: 50% – Elapsed: 0.7s
Progress: 30% – Elapsed: 0.5s
Progress: 30% – Elapsed: 0.4s
Progress: 30% – Elapsed: 0.5s
Progress: 20% – Elapsed: 0.3s
Progress: 30% – Elapsed: 0.6s
Progress: 30% – Elapsed: 0.3s
Progress: 40% – Elapsed: 0.6s
Progress: 40% – Elapsed: 0.7s
Progress: 40% – Elapsed: 0.6s
Progress: 40% – Elapsed: 0.7s
Progress: 40% – Elapsed: 0.8s
Progress: 50% – Elapsed: 0.9s
Progress: 60% – Elapsed: 0.9s
Progress: 50% – Elapsed: 0.9s
Progress: 50% – Elapsed: 1.0s
Progress: 60% – Elapsed: 1.1s
Progress: 60% – Elapsed: 1.0s
Progress: 70% – Elapsed: 1.1s
Progress: 50% – Elapsed: 0.9s
Progress: 50% – Elapsed: 0.9s
Progress: 40% – Elapsed: 0.9s
Progress: 40% – Elapsed: 0.8s
Progress: 60% – Elapsed: 1.0s
Progress: 70% – Elapsed: 1.3s
Progress: 80% – Elapsed: 1.2s
Progress: 60% – Elapsed: 1.1s
Progress: 60% – Elapsed: 1.1s
Progress: 50% – Elapsed: 1.0s
Progress: 50% – Elapsed: 0.9s
Progress: 70% – Elapsed: 1.3s
Progress: 70% – Elapsed: 1.3s
Progress: 60% – Elapsed: 1.2s
Progress: 80% – Elapsed: 1.4s
Progress: 90% – Elapsed: 1.4s
Progress: 70% – Elapsed: 1.3s
Progress: 60% – Elapsed: 1.2s
Progress: 70% – Elapsed: 1.2s
Progress: 70% – Elapsed: 1.4s
Progress: 80% – Elapsed: 1.4s
Progress: 80% – Elapsed: 1.5s
Progress: 70% – Elapsed: 1.4s
Progress: 80% – Elapsed: 1.3s
Progress: 90% – Elapsed: 1.6s
Progress: 80% – Elapsed: 1.5s
Progress: 100% – Elapsed: 1.7s
Done. Total time: 1.7s
Encoding 249 subgraphs (K = 10)...
Progress: 90% – Elapsed: 1.6s
Progress: 80% – Elapsed: 1.5s
Progress: 80% – Elapsed: 1.5s
Progress: 90% – Elapsed: 1.5s
Progress: 100% – Elapsed: 1.7s
Done. Total time: 1.7s
Encoding 249 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 100% – Elapsed: 1.7s
Done. Total time: 1.7s
Encoding 249 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.1s
Progress: 19% – Elapsed: 0.1s
Progress: 29% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.1s
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.1s
Progress: 29% – Elapsed: 0.1s
Progress: 100% – Elapsed: 1.7s
Done. Total time: 1.7s
Encoding 249 subgraphs (K = 10)...
Progress: 90% – Elapsed: 1.7s
Progress: 90% – Elapsed: 1.6s
Progress: 19% – Elapsed: 0.1s
Progress: 29% – Elapsed: 0.1s
Progress: 90% – Elapsed: 1.7s
Progress: 39% – Elapsed: 0.1s
Progress: 48% – Elapsed: 0.2s
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.1s
Progress: 29% – Elapsed: 0.1s
Progress: 100% – Elapsed: 1.9s
Progress: 100% – Elapsed: 1.8s
Progress: 90% – Elapsed: 1.7s
Progress: 48% – Elapsed: 0.2s
Progress: 58% – Elapsed: 0.3s
Progress: 67% – Elapsed: 0.3s
Progress: 77% – Elapsed: 0.4s
Progress: 58% – Elapsed: 0.3s
Progress: 67% – Elapsed: 0.3s
Progress: 39% – Elapsed: 0.2s
Done. Total time: 1.9s
Encoding 249 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Done. Total time: 1.8s
Encoding 249 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 29% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.2s
Progress: 48% – Elapsed: 0.2s
Progress: 39% – Elapsed: 0.2s
Progress: 48% – Elapsed: 0.2s
Progress: 58% – Elapsed: 0.3s
Progress: 100% – Elapsed: 1.9s
Done. Total time: 2.0s
Encoding 249 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 77% – Elapsed: 0.3s
Progress: 87% – Elapsed: 0.4s
Progress: 48% – Elapsed: 0.3s
Progress: 58% – Elapsed: 0.3s
Progress: 19% – Elapsed: 0.1s
Progress: 29% – Elapsed: 0.1s
Progress: 100% – Elapsed: 2.0s
Progress: 87% – Elapsed: 0.5s
Progress: 96% – Elapsed: 0.5s
Done. Total time: 0.5s
Progress: 19% – Elapsed: 0.1s
Progress: 29% – Elapsed: 0.1s
Progress: 96% – Elapsed: 0.5s
Done. Total time: 0.5s
Progress: 67% – Elapsed: 0.3s
Progress: 77% – Elapsed: 0.4s
Progress: 39% – Elapsed: 0.2s
Progress: 48% – Elapsed: 0.3s
Progress: 58% – Elapsed: 0.3s
Done. Total time: 2.0s
Encoding 249 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.1s
Progress: 67% – Elapsed: 0.3s
Progress: 77% – Elapsed: 0.4s
Progress: 39% – Elapsed: 0.2s
Progress: 87% – Elapsed: 0.4s
Progress: 67% – Elapsed: 0.4s
Progress: 29% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.2s
Progress: 48% – Elapsed: 0.2s
Progress: 87% – Elapsed: 0.5s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       11.72% |       0.7417 |          0.1000 |
Progress: 48% – Elapsed: 0.2s
Progress: 58% – Elapsed: 0.4s
Progress: 96% – Elapsed: 0.5s
Done. Total time: 0.6s
Progress: 58% – Elapsed: 0.3s
Progress: 67% – Elapsed: 0.4s
Progress: 77% – Elapsed: 0.4s
Progress: 87% – Elapsed: 0.5s
Progress: 77% – Elapsed: 0.4s
Progress: 87% – Elapsed: 0.4s
Progress: 96% – Elapsed: 0.5s
Done. Total time: 0.5s
Progress: 58% – Elapsed: 0.3s
Progress: 96% – Elapsed: 0.5s
Done. Total time: 0.5s
Progress: 67% – Elapsed: 0.5s
Progress: 77% – Elapsed: 0.5s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       32.03% |       0.7694 |          0.1000 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       40.62% |       0.6591 |          0.1000 |
Progress: 96% – Elapsed: 0.6s
Done. Total time: 0.6s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
Progress: 67% – Elapsed: 0.4s
Progress: 77% – Elapsed: 0.4s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
Progress: 87% – Elapsed: 0.7s
Progress: 96% – Elapsed: 0.7s
Done. Total time: 0.7s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       27.34% |       0.7347 |          0.1000 |
Progress: 87% – Elapsed: 0.5s
Progress: 96% – Elapsed: 0.6s
Done. Total time: 0.6s
|       1 |           1 |       00:00:00 |       67.19% |       0.6783 |          0.1000 |
|       1 |           1 |       00:00:00 |       68.75% |       0.7001 |          0.1000 |
|       8 |          50 |       00:00:00 |       96.88% |       0.0938 |          0.1000 |
|      15 |         100 |       00:00:00 |      100.00% |       0.0037 |          0.0900 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       71.09% |       0.6343 |          0.1000 |
|       8 |          50 |       00:00:00 |       99.22% |       0.0517 |          0.1000 |
|      15 |         100 |       00:00:00 |      100.00% |       0.0038 |          0.0900 |
|       8 |          50 |       00:00:00 |       97.66% |       0.0652 |          0.1000 |
|       8 |          50 |       00:00:00 |       99.22% |       0.0372 |          0.1000 |
|       8 |          50 |       00:00:00 |       99.22% |       0.0273 |          0.1000 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       68.75% |       0.6735 |          0.1000 |
|       8 |          50 |       00:00:00 |      100.00% |       0.0147 |          0.1000 |
|       8 |          50 |       00:00:00 |      100.00% |       0.0117 |          0.1000 |
|      15 |         100 |       00:00:00 |      100.00% |       0.0042 |          0.0900 |
|      15 |         100 |       00:00:00 |      100.00% |       0.0040 |          0.0900 |
|      22 |         150 |       00:00:01 |      100.00% |       0.0045 |          0.0810 |
|       8 |          50 |       00:00:00 |      100.00% |       0.0202 |          0.1000 |
|      15 |         100 |       00:00:00 |      100.00% |       0.0066 |          0.0900 |
|      15 |         100 |       00:00:00 |      100.00% |       0.0041 |          0.0900 |
|      15 |         100 |       00:00:00 |      100.00% |       0.0005 |          0.0900 |
|      22 |         150 |       00:00:01 |       99.22% |       0.0238 |          0.0810 |
|      22 |         150 |       00:00:01 |      100.00% |       0.0029 |          0.0810 |
|      15 |         100 |       00:00:00 |      100.00% |       0.0050 |          0.0900 |
|      22 |         150 |       00:00:01 |      100.00% |       0.0032 |          0.0810 |
|      29 |         200 |       00:00:01 |      100.00% |       0.0034 |          0.0810 |
|      22 |         150 |       00:00:01 |      100.00% |       0.0005 |          0.0810 |
|      22 |         150 |       00:00:01 |      100.00% |       0.0023 |          0.0810 |
|      22 |         150 |       00:00:01 |      100.00% |       0.0001 |          0.0810 |
|      29 |         200 |       00:00:01 |      100.00% |       0.0055 |          0.0810 |
|      22 |         150 |       00:00:01 |      100.00% |       0.0036 |          0.0810 |
|      36 |         250 |       00:00:02 |       99.22% |       0.0379 |          0.0729 |
|      29 |         200 |       00:00:01 |       98.44% |       0.0759 |          0.0810 |
|      29 |         200 |       00:00:01 |      100.00% |       0.0002 |          0.0810 |
|      29 |         200 |       00:00:01 |      100.00% |       0.0030 |          0.0810 |
|      29 |         200 |       00:00:01 |      100.00% |       0.0028 |          0.0810 |
|      36 |         250 |       00:00:02 |      100.00% |       0.0038 |          0.0729 |
|      36 |         250 |       00:00:02 |      100.00% |       0.0021 |          0.0729 |
|      43 |         300 |       00:00:02 |       99.22% |       0.0289 |          0.0656 |
|      29 |         200 |       00:00:01 |      100.00% |   9.8947e-05 |          0.0810 |
|      36 |         250 |       00:00:02 |      100.00% |       0.0048 |          0.0729 |
|      36 |         250 |       00:00:02 |       99.22% |       0.0418 |          0.0729 |
|      29 |         200 |       00:00:01 |       98.44% |       0.0677 |          0.0810 |
|      50 |         350 |       00:00:02 |      100.00% |       0.0048 |          0.0656 |
|      36 |         250 |       00:00:02 |      100.00% |       0.0002 |          0.0729 |
|      43 |         300 |       00:00:02 |      100.00% |       0.0036 |          0.0656 |
|      36 |         250 |       00:00:02 |      100.00% |       0.0001 |          0.0729 |
|      36 |         250 |       00:00:02 |       99.22% |       0.0387 |          0.0729 |
|      43 |         300 |       00:00:02 |       99.22% |       0.0402 |          0.0656 |
|      43 |         300 |       00:00:02 |      100.00% |       0.0002 |          0.0656 |
|      50 |         350 |       00:00:02 |       99.22% |       0.0404 |          0.0656 |
|      43 |         300 |       00:00:02 |      100.00% |       0.0029 |          0.0656 |
|      43 |         300 |       00:00:02 |      100.00% |       0.0002 |          0.0656 |
|      43 |         300 |       00:00:02 |      100.00% |       0.0018 |          0.0656 |
|      50 |         350 |       00:00:02 |       99.22% |       0.0396 |          0.0656 |
|      58 |         400 |       00:00:03 |       99.22% |       0.0381 |          0.0590 |
|      50 |         350 |       00:00:02 |      100.00% |       0.0001 |          0.0656 |
|      58 |         400 |       00:00:03 |       99.22% |       0.0413 |          0.0590 |
|      50 |         350 |       00:00:02 |      100.00% |       0.0020 |          0.0656 |
|      50 |         350 |       00:00:02 |      100.00% |   8.6674e-05 |          0.0656 |
|      50 |         350 |       00:00:02 |       99.22% |       0.0244 |          0.0656 |
|      43 |         300 |       00:00:02 |      100.00% |       0.0055 |          0.0656 |
|      58 |         400 |       00:00:02 |      100.00% |       0.0026 |          0.0590 |
|      58 |         400 |       00:00:03 |      100.00% |       0.0003 |          0.0590 |
|      58 |         400 |       00:00:03 |      100.00% |       0.0021 |          0.0590 |
|      50 |         350 |       00:00:02 |      100.00% |       0.0035 |          0.0656 |
|      65 |         450 |       00:00:03 |      100.00% |       0.0027 |          0.0531 |
|      65 |         450 |       00:00:03 |      100.00% |       0.0026 |          0.0531 |
|      58 |         400 |       00:00:03 |      100.00% |   7.8012e-05 |          0.0590 |
|      65 |         450 |       00:00:03 |      100.00% |       0.0023 |          0.0531 |
|      58 |         400 |       00:00:03 |       99.22% |       0.0275 |          0.0590 |
|      58 |         400 |       00:00:03 |      100.00% |       0.0036 |          0.0590 |
|      65 |         450 |       00:00:03 |      100.00% |       0.0037 |          0.0531 |
|      65 |         450 |       00:00:03 |      100.00% |       0.0002 |          0.0531 |
|      65 |         450 |       00:00:03 |      100.00% |       0.0023 |          0.0531 |
|      72 |         500 |       00:00:04 |      100.00% |       0.0038 |          0.0478 |
|      65 |         450 |       00:00:03 |      100.00% |   7.9249e-05 |          0.0531 |
|      72 |         500 |       00:00:03 |       99.22% |       0.0135 |          0.0478 |
|      72 |         500 |       00:00:03 |      100.00% |       0.0015 |          0.0478 |
|      65 |         450 |       00:00:03 |      100.00% |       0.0032 |          0.0531 |
|      72 |         500 |       00:00:03 |      100.00% |       0.0023 |          0.0478 |
|      79 |         550 |       00:00:04 |      100.00% |       0.0022 |          0.0478 |
|      79 |         550 |       00:00:04 |      100.00% |       0.0037 |          0.0478 |
|      72 |         500 |       00:00:03 |      100.00% |   4.8580e-05 |          0.0478 |
|      79 |         550 |       00:00:04 |      100.00% |       0.0029 |          0.0478 |
|      86 |         600 |       00:00:04 |       99.22% |       0.0379 |          0.0430 |
|      72 |         500 |       00:00:03 |      100.00% |   4.0855e-05 |          0.0478 |
|      86 |         600 |       00:00:04 |      100.00% |       0.0027 |          0.0430 |
|      72 |         500 |       00:00:04 |      100.00% |       0.0027 |          0.0478 |
|      79 |         550 |       00:00:04 |      100.00% |   7.5726e-05 |          0.0478 |
|      79 |         550 |       00:00:04 |      100.00% |       0.0036 |          0.0478 |
|      72 |         500 |       00:00:03 |      100.00% |       0.0031 |          0.0478 |
|      86 |         600 |       00:00:04 |      100.00% |       0.0020 |          0.0430 |
|      79 |         550 |       00:00:04 |      100.00% |   4.1033e-05 |          0.0478 |
|      93 |         650 |       00:00:04 |      100.00% |       0.0034 |          0.0387 |
|      79 |         550 |       00:00:04 |       98.44% |       0.0738 |          0.0478 |
|      86 |         600 |       00:00:04 |      100.00% |   5.5032e-05 |          0.0430 |
|      86 |         600 |       00:00:04 |       99.22% |       0.0415 |          0.0430 |
|      79 |         550 |       00:00:04 |       98.44% |       0.0589 |          0.0478 |
|      93 |         650 |       00:00:04 |       99.22% |       0.0206 |          0.0387 |
|      86 |         600 |       00:00:04 |      100.00% |       0.0001 |          0.0430 |
|     100 |         700 |       00:00:04 |       99.22% |       0.0397 |          0.0387 |
|      86 |         600 |       00:00:04 |      100.00% |       0.0052 |          0.0430 |
|      93 |         650 |       00:00:04 |      100.00% |       0.0015 |          0.0387 |
|      93 |         650 |       00:00:04 |       99.22% |       0.0395 |          0.0387 |
|     100 |         700 |       00:00:05 |      100.00% |       0.0064 |          0.0387 |
|      93 |         650 |       00:00:04 |      100.00% |   9.8940e-05 |          0.0387 |
|     108 |         750 |       00:00:05 |       99.22% |       0.0397 |          0.0349 |
|      93 |         650 |       00:00:05 |      100.00% |       0.0026 |          0.0387 |
|      93 |         650 |       00:00:04 |      100.00% |       0.0001 |          0.0387 |
|     100 |         700 |       00:00:05 |      100.00% |   4.8443e-05 |          0.0387 |
|     100 |         700 |       00:00:04 |       99.22% |       0.0156 |          0.0387 |
|      86 |         600 |       00:00:04 |       99.22% |       0.0380 |          0.0430 |
|      93 |         650 |       00:00:04 |      100.00% |       0.0057 |          0.0387 |
|     100 |         700 |       00:00:04 |       99.22% |       0.0391 |          0.0387 |
|     108 |         750 |       00:00:05 |       99.22% |       0.0378 |          0.0349 |
|     108 |         750 |       00:00:05 |      100.00% |       0.0025 |          0.0349 |
|     115 |         800 |       00:00:05 |      100.00% |       0.0024 |          0.0314 |
|     100 |         700 |       00:00:05 |      100.00% |       0.0018 |          0.0387 |
|     108 |         750 |       00:00:05 |      100.00% |       0.0016 |          0.0349 |
|     100 |         700 |       00:00:04 |      100.00% |   6.9501e-05 |          0.0387 |
|     108 |         750 |       00:00:05 |      100.00% |       0.0001 |          0.0349 |
|     115 |         800 |       00:00:05 |      100.00% |       0.0020 |          0.0314 |
|     100 |         700 |       00:00:05 |      100.00% |       0.0029 |          0.0387 |
|     115 |         800 |       00:00:05 |      100.00% |       0.0027 |          0.0314 |
|     115 |         800 |       00:00:05 |      100.00% |       0.0025 |          0.0314 |
|     122 |         850 |       00:00:05 |      100.00% |       0.0090 |          0.0282 |
|     108 |         750 |       00:00:05 |       99.22% |       0.0242 |          0.0349 |
|     122 |         850 |       00:00:06 |      100.00% |       0.0033 |          0.0282 |
|     108 |         750 |       00:00:05 |      100.00% |   4.8712e-05 |          0.0349 |
|     129 |         900 |       00:00:06 |      100.00% |       0.0034 |          0.0282 |
|     115 |         800 |       00:00:05 |      100.00% |       0.0001 |          0.0314 |
|     108 |         750 |       00:00:05 |      100.00% |       0.0032 |          0.0349 |
|     122 |         850 |       00:00:05 |      100.00% |       0.0022 |          0.0282 |
|     115 |         800 |       00:00:05 |      100.00% |       0.0034 |          0.0314 |
|     122 |         850 |       00:00:05 |      100.00% |       0.0015 |          0.0282 |
|     129 |         900 |       00:00:06 |      100.00% |       0.0021 |          0.0282 |
|     129 |         900 |       00:00:06 |      100.00% |       0.0028 |          0.0282 |
|     115 |         800 |       00:00:05 |      100.00% |   5.5144e-05 |          0.0314 |
|     136 |         950 |       00:00:06 |      100.00% |       0.0025 |          0.0254 |
|     122 |         850 |       00:00:06 |      100.00% |   3.3629e-05 |          0.0282 |
|     115 |         800 |       00:00:05 |      100.00% |       0.0029 |          0.0314 |
|     122 |         850 |       00:00:06 |      100.00% |       0.0026 |          0.0282 |
|     129 |         900 |       00:00:06 |      100.00% |   5.4062e-05 |          0.0282 |
|     129 |         900 |       00:00:06 |      100.00% |       0.0028 |          0.0282 |
|     136 |         950 |       00:00:06 |      100.00% |       0.0019 |          0.0254 |
|     122 |         850 |       00:00:06 |      100.00% |   2.9236e-05 |          0.0282 |
|     122 |         850 |       00:00:06 |      100.00% |       0.0030 |          0.0282 |
|     136 |         950 |       00:00:06 |       99.22% |       0.0379 |          0.0254 |
|     143 |        1000 |       00:00:06 |      100.00% |       0.0031 |          0.0229 |
|     136 |         950 |       00:00:06 |      100.00% |   3.9818e-05 |          0.0254 |
|     129 |         900 |       00:00:06 |       98.44% |       0.0529 |          0.0282 |
|     143 |        1000 |       00:00:07 |       99.22% |       0.0171 |          0.0229 |
|     129 |         900 |       00:00:06 |      100.00% |   3.0455e-05 |          0.0282 |
|     129 |         900 |       00:00:06 |       98.44% |       0.0727 |          0.0282 |
|     136 |         950 |       00:00:06 |       99.22% |       0.0423 |          0.0254 |
|     143 |        1000 |       00:00:06 |       99.22% |       0.0393 |          0.0229 |
|     150 |        1050 |       00:00:07 |      100.00% |       0.0065 |          0.0229 |
|     136 |         950 |       00:00:06 |      100.00% |   8.0723e-05 |          0.0254 |
|     150 |        1050 |       00:00:07 |       99.22% |       0.0386 |          0.0229 |
|     136 |         950 |       00:00:06 |      100.00% |       0.0051 |          0.0254 |
|     143 |        1000 |       00:00:06 |      100.00% |   9.0346e-05 |          0.0229 |
|     143 |        1000 |       00:00:06 |      100.00% |       0.0014 |          0.0229 |
|     136 |         950 |       00:00:06 |       99.22% |       0.0378 |          0.0254 |
|     150 |        1050 |       00:00:07 |       99.22% |       0.0388 |          0.0229 |
|     158 |        1100 |       00:00:07 |       99.22% |       0.0393 |          0.0206 |
|     143 |        1000 |       00:00:07 |      100.00% |       0.0025 |          0.0229 |
|     150 |        1050 |       00:00:07 |      100.00% |   3.7601e-05 |          0.0229 |
|     150 |        1050 |       00:00:07 |      100.00% |       0.0075 |          0.0229 |
|     143 |        1000 |       00:00:06 |      100.00% |       0.0060 |          0.0229 |
|     158 |        1100 |       00:00:07 |      100.00% |       0.0025 |          0.0206 |
|     158 |        1100 |       00:00:07 |       99.22% |       0.0380 |          0.0206 |
|     143 |        1000 |       00:00:07 |      100.00% |   7.7035e-05 |          0.0229 |
|     165 |        1150 |       00:00:07 |      100.00% |       0.0023 |          0.0185 |
|     150 |        1050 |       00:00:07 |      100.00% |   5.4976e-05 |          0.0229 |
|     165 |        1150 |       00:00:07 |      100.00% |       0.0025 |          0.0185 |
|     150 |        1050 |       00:00:07 |      100.00% |       0.0016 |          0.0229 |
|     158 |        1100 |       00:00:07 |      100.00% |       0.0001 |          0.0206 |
|     158 |        1100 |       00:00:07 |      100.00% |       0.0014 |          0.0206 |
|     165 |        1150 |       00:00:07 |      100.00% |       0.0016 |          0.0185 |
|     150 |        1050 |       00:00:07 |      100.00% |       0.0026 |          0.0229 |
|     165 |        1150 |       00:00:07 |      100.00% |       0.0026 |          0.0185 |
|     172 |        1200 |       00:00:08 |      100.00% |       0.0030 |          0.0167 |
|     172 |        1200 |       00:00:08 |      100.00% |       0.0060 |          0.0167 |
|     158 |        1100 |       00:00:07 |       99.22% |       0.0222 |          0.0206 |
|     165 |        1150 |       00:00:07 |      100.00% |   9.7113e-05 |          0.0185 |
|     172 |        1200 |       00:00:07 |      100.00% |       0.0021 |          0.0167 |
|     172 |        1200 |       00:00:07 |      100.00% |       0.0012 |          0.0167 |
|     158 |        1100 |       00:00:07 |      100.00% |       0.0028 |          0.0206 |
|     179 |        1250 |       00:00:08 |      100.00% |       0.0028 |          0.0167 |
|     158 |        1100 |       00:00:07 |      100.00% |   3.9688e-05 |          0.0206 |
|     179 |        1250 |       00:00:08 |      100.00% |       0.0030 |          0.0167 |
|     165 |        1150 |       00:00:08 |      100.00% |       0.0034 |          0.0185 |
|     172 |        1200 |       00:00:08 |      100.00% |   2.8416e-05 |          0.0167 |
|     179 |        1250 |       00:00:08 |      100.00% |       0.0019 |          0.0167 |
|     165 |        1150 |       00:00:08 |      100.00% |       0.0028 |          0.0185 |
|     179 |        1250 |       00:00:08 |      100.00% |       0.0021 |          0.0167 |
|     186 |        1300 |       00:00:08 |       99.22% |       0.0375 |          0.0150 |
|     165 |        1150 |       00:00:08 |      100.00% |   4.6943e-05 |          0.0185 |
|     172 |        1200 |       00:00:08 |      100.00% |   2.4834e-05 |          0.0167 |
|     172 |        1200 |       00:00:08 |      100.00% |       0.0026 |          0.0167 |
|     179 |        1250 |       00:00:08 |      100.00% |   4.5998e-05 |          0.0167 |
|     186 |        1300 |       00:00:08 |       99.22% |       0.0420 |          0.0150 |
|     172 |        1200 |       00:00:08 |      100.00% |       0.0030 |          0.0167 |
|     186 |        1300 |       00:00:08 |      100.00% |       0.0019 |          0.0150 |
|     186 |        1300 |       00:00:08 |      100.00% |       0.0023 |          0.0150 |
|     193 |        1350 |       00:00:09 |      100.00% |       0.0031 |          0.0135 |
|     179 |        1250 |       00:00:08 |       98.44% |       0.0723 |          0.0167 |
|     186 |        1300 |       00:00:08 |      100.00% |   3.4046e-05 |          0.0150 |
|     193 |        1350 |       00:00:08 |      100.00% |       0.0013 |          0.0135 |
|     193 |        1350 |       00:00:08 |       99.22% |       0.0391 |          0.0135 |
|     193 |        1350 |       00:00:09 |       99.22% |       0.0152 |          0.0135 |
|     179 |        1250 |       00:00:08 |      100.00% |   2.6297e-05 |          0.0167 |
|     179 |        1250 |       00:00:08 |       98.44% |       0.0501 |          0.0167 |
|     186 |        1300 |       00:00:09 |      100.00% |       0.0051 |          0.0150 |
|     193 |        1350 |       00:00:09 |      100.00% |   7.8466e-05 |          0.0135 |
|     200 |        1400 |       00:00:09 |      100.00% |       0.0052 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9875, Recall: 0.9518, F1-Score: 0.9693
AUC: 0.9985
|     186 |        1300 |       00:00:09 |       99.22% |       0.0377 |          0.0150 |
|     200 |        1400 |       00:00:09 |       99.22% |       0.0387 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     200 |        1400 |       00:00:09 |       99.22% |       0.0378 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.25, Precision: 0.9765, Recall: 1.0000, F1-Score: 0.9881
AUC: 0.9987
|     200 |        1400 |       00:00:10 |      100.00% |       0.0065 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
|     186 |        1300 |       00:00:09 |      100.00% |   7.0259e-05 |          0.0150 |
Best Threshold: 0.10, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000
AUC: 1.0000
Best Threshold: 0.10, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000
AUC: 1.0000
|     200 |        1400 |       00:00:10 |      100.00% |   3.3100e-05 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
  Columns 1 through 4

    "Experiment "    "10"    " (strategy: "    "random"

  Column 5

    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 335
    Train Negative: 670
    Test  Positive: 83
    Test  Negative: 166
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 1005 subgraphs (K = 10)...
    "Experiment "    "9"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts (use_role_filter = 1):
    Train Positive: 335
    Train Negative: 670
    Test  Positive: 83
    Test  Negative: 166
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 1005 subgraphs (K = 10)...
Best Threshold: 0.65, Precision: 0.9881, Recall: 1.0000, F1-Score: 0.9940
AUC: 0.9969
Progress: 10% – Elapsed: 0.2s
|     193 |        1350 |       00:00:10 |      100.00% |   6.7849e-05 |          0.0135 |
Progress: 10% – Elapsed: 0.2s
Progress: 20% – Elapsed: 0.3s
|     193 |        1350 |       00:00:10 |      100.00% |       0.0023 |          0.0135 |
|     193 |        1350 |       00:00:10 |      100.00% |       0.0058 |          0.0135 |
Progress: 20% – Elapsed: 0.3s
|     200 |        1400 |       00:00:10 |      100.00% |       0.0024 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Progress: 30% – Elapsed: 0.5s
|     200 |        1400 |       00:00:10 |      100.00% |       0.0016 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9881, Recall: 1.0000, F1-Score: 0.9940
AUC: 0.9985
Progress: 30% – Elapsed: 0.7s
Best Threshold: 0.10, Precision: 0.9881, Recall: 1.0000, F1-Score: 0.9940
AUC: 0.9992
Progress: 40% – Elapsed: 1.0s
|     200 |        1400 |       00:00:11 |      100.00% |   4.8931e-05 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Progress: 50% – Elapsed: 1.3s
Progress: 40% – Elapsed: 1.0s
Progress: 60% – Elapsed: 1.5s
Best Threshold: 0.10, Precision: 0.9881, Recall: 1.0000, F1-Score: 0.9940
AUC: 0.9964
Progress: 50% – Elapsed: 1.3s
Progress: 70% – Elapsed: 1.6s
Progress: 60% – Elapsed: 1.4s
Progress: 70% – Elapsed: 1.6s
Progress: 80% – Elapsed: 1.7s
Progress: 90% – Elapsed: 1.8s
Progress: 80% – Elapsed: 1.7s
Progress: 100% – Elapsed: 1.9s
Done. Total time: 1.9s
Encoding 249 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.0s
Progress: 90% – Elapsed: 1.7s
Progress: 100% – Elapsed: 1.8s
Done. Total time: 1.8s
Encoding 249 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Progress: 19% – Elapsed: 0.1s
Progress: 29% – Elapsed: 0.1s
Progress: 29% – Elapsed: 0.1s
Progress: 39% – Elapsed: 0.1s
Progress: 48% – Elapsed: 0.1s
Progress: 58% – Elapsed: 0.1s
Progress: 67% – Elapsed: 0.2s
Progress: 77% – Elapsed: 0.2s
Progress: 87% – Elapsed: 0.3s
Progress: 39% – Elapsed: 0.1s
Progress: 48% – Elapsed: 0.1s
Progress: 58% – Elapsed: 0.1s
Progress: 67% – Elapsed: 0.1s
Progress: 96% – Elapsed: 0.4s
Done. Total time: 0.5s
Progress: 77% – Elapsed: 0.3s
Progress: 87% – Elapsed: 0.4s
Progress: 96% – Elapsed: 0.4s
Done. Total time: 0.4s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       82.81% |       0.6516 |          0.1000 |
|       8 |          50 |       00:00:00 |      100.00% |       0.0156 |          0.1000 |
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       85.16% |       0.6790 |          0.1000 |
|       8 |          50 |       00:00:00 |       99.22% |       0.0254 |          0.1000 |
|      15 |         100 |       00:00:00 |      100.00% |       0.0036 |          0.0900 |
|      22 |         150 |       00:00:01 |      100.00% |       0.0018 |          0.0810 |
|      15 |         100 |       00:00:01 |      100.00% |       0.0028 |          0.0900 |
|      29 |         200 |       00:00:02 |      100.00% |       0.0021 |          0.0810 |
|      22 |         150 |       00:00:01 |      100.00% |       0.0014 |          0.0810 |
|      36 |         250 |       00:00:02 |       99.22% |       0.0466 |          0.0729 |
|      29 |         200 |       00:00:02 |       99.22% |       0.0280 |          0.0810 |
|      43 |         300 |       00:00:03 |      100.00% |       0.0015 |          0.0656 |
|      36 |         250 |       00:00:02 |       99.22% |       0.0433 |          0.0729 |
|      50 |         350 |       00:00:03 |      100.00% |       0.0014 |          0.0656 |
|      43 |         300 |       00:00:03 |      100.00% |       0.0030 |          0.0656 |
|      58 |         400 |       00:00:03 |      100.00% |       0.0015 |          0.0590 |
|      65 |         450 |       00:00:04 |      100.00% |       0.0017 |          0.0531 |
|      50 |         350 |       00:00:03 |      100.00% |       0.0072 |          0.0656 |
|      58 |         400 |       00:00:04 |      100.00% |       0.0025 |          0.0590 |
|      72 |         500 |       00:00:04 |      100.00% |       0.0012 |          0.0478 |
|      79 |         550 |       00:00:04 |      100.00% |       0.0014 |          0.0478 |
|      65 |         450 |       00:00:04 |      100.00% |       0.0016 |          0.0531 |
|      72 |         500 |       00:00:04 |      100.00% |       0.0011 |          0.0478 |
|      86 |         600 |       00:00:04 |       99.22% |       0.0447 |          0.0430 |
|      93 |         650 |       00:00:05 |      100.00% |       0.0014 |          0.0387 |
|      79 |         550 |       00:00:04 |       99.22% |       0.0194 |          0.0478 |
|      86 |         600 |       00:00:05 |       99.22% |       0.0418 |          0.0430 |
|     100 |         700 |       00:00:05 |      100.00% |       0.0012 |          0.0387 |
|      93 |         650 |       00:00:05 |      100.00% |       0.0026 |          0.0387 |
|     108 |         750 |       00:00:05 |      100.00% |       0.0013 |          0.0349 |
|     115 |         800 |       00:00:06 |      100.00% |       0.0015 |          0.0314 |
|     100 |         700 |       00:00:05 |      100.00% |       0.0067 |          0.0387 |
|     122 |         850 |       00:00:06 |      100.00% |       0.0011 |          0.0282 |
|     108 |         750 |       00:00:06 |      100.00% |       0.0022 |          0.0349 |
|     129 |         900 |       00:00:06 |      100.00% |       0.0013 |          0.0282 |
|     115 |         800 |       00:00:06 |      100.00% |       0.0014 |          0.0314 |
|     136 |         950 |       00:00:06 |       99.22% |       0.0437 |          0.0254 |
|     122 |         850 |       00:00:06 |      100.00% |       0.0011 |          0.0282 |
|     129 |         900 |       00:00:06 |       99.22% |       0.0156 |          0.0282 |
|     143 |        1000 |       00:00:06 |      100.00% |       0.0014 |          0.0229 |
|     136 |         950 |       00:00:06 |       99.22% |       0.0412 |          0.0254 |
|     150 |        1050 |       00:00:07 |      100.00% |       0.0012 |          0.0229 |
|     143 |        1000 |       00:00:07 |      100.00% |       0.0023 |          0.0229 |
|     150 |        1050 |       00:00:07 |      100.00% |       0.0061 |          0.0229 |
|     158 |        1100 |       00:00:07 |      100.00% |       0.0012 |          0.0206 |
|     165 |        1150 |       00:00:07 |      100.00% |       0.0014 |          0.0185 |
|     172 |        1200 |       00:00:07 |      100.00% |       0.0011 |          0.0167 |
|     158 |        1100 |       00:00:07 |      100.00% |       0.0020 |          0.0206 |
|     179 |        1250 |       00:00:07 |      100.00% |       0.0013 |          0.0167 |
|     165 |        1150 |       00:00:07 |      100.00% |       0.0014 |          0.0185 |
|     186 |        1300 |       00:00:07 |       99.22% |       0.0431 |          0.0150 |
|     172 |        1200 |       00:00:07 |      100.00% |       0.0012 |          0.0167 |
|     179 |        1250 |       00:00:07 |       99.22% |       0.0127 |          0.0167 |
|     186 |        1300 |       00:00:07 |       99.22% |       0.0407 |          0.0150 |
|     193 |        1350 |       00:00:07 |      100.00% |       0.0014 |          0.0135 |
|     200 |        1400 |       00:00:07 |      100.00% |       0.0011 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.45, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000
AUC: 1.0000
|     193 |        1350 |       00:00:07 |      100.00% |       0.0023 |          0.0135 |
|     200 |        1400 |       00:00:08 |      100.00% |       0.0057 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.50, Precision: 0.9765, Recall: 1.0000, F1-Score: 0.9881
AUC: 0.9969
