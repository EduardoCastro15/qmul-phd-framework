Processing dataset: SF1M2_tax_mass
Processing with K = 10
Experiment 1: Running WLNM...
Subgraph Pattern Encoding Begins...
Subgraph Pattern Encoding Progress 10%...
Subgraph Pattern Encoding Progress 20%...
Subgraph Pattern Encoding Progress 30%...
Subgraph Pattern Encoding Progress 40%...
Subgraph Pattern Encoding Progress 50%...
Subgraph Pattern Encoding Progress 60%...
Subgraph Pattern Encoding Progress 70%...
Subgraph Pattern Encoding Progress 80%...
Subgraph Pattern Encoding Progress 90%...
Subgraph Pattern Encoding Begins...
Subgraph Pattern Encoding Progress 10%...
Subgraph Pattern Encoding Progress 20%...
Subgraph Pattern Encoding Progress 30%...
Subgraph Pattern Encoding Progress 40%...
Subgraph Pattern Encoding Progress 50%...
Subgraph Pattern Encoding Progress 60%...
Subgraph Pattern Encoding Progress 70%...
Subgraph Pattern Encoding Progress 80%...
Subgraph Pattern Encoding Progress 90%...
{Undefined function 'imageInputLayer' for input arguments of type 'double'.

Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/MATLAB/WLNM.m', 24)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/WLNM.m',24,0)">line 24</a>)
    layers = [imageInputLayer([K*(K-1)/2 1 1], 'Normalization','none')
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/MATLAB/Main.m', 129)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/Main.m',129,0)">line 129</a>)
    [auc, best_threshold, best_precision, best_recall, best_f1_score] = WLNM(dataname, train, test, K, taxonomy, mass);
                                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/MATLAB/Main.m', 81)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/Main.m',81,0)">line 81</a>)
                results(ith_experiment) = processExperiment(ith_experiment, dataname, net, taxonomy, mass, ratioTrain, K);
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
} 
Processing dataset: SF1M2_tax_mass
Processing with K = 10
Experiment 1: Running WLNM...
Subgraph Pattern Encoding Begins...
Subgraph Pattern Encoding Progress 10%...
Subgraph Pattern Encoding Progress 20%...
Subgraph Pattern Encoding Progress 30%...
Subgraph Pattern Encoding Progress 40%...
Subgraph Pattern Encoding Progress 50%...
Subgraph Pattern Encoding Progress 60%...
Subgraph Pattern Encoding Progress 70%...
Subgraph Pattern Encoding Progress 80%...
Subgraph Pattern Encoding Progress 90%...
Subgraph Pattern Encoding Begins...
Subgraph Pattern Encoding Progress 10%...
Subgraph Pattern Encoding Progress 20%...
Subgraph Pattern Encoding Progress 30%...
Subgraph Pattern Encoding Progress 40%...
Subgraph Pattern Encoding Progress 50%...
Subgraph Pattern Encoding Progress 60%...
Subgraph Pattern Encoding Progress 70%...
Subgraph Pattern Encoding Progress 80%...
Subgraph Pattern Encoding Progress 90%...
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |        6.67% |       0.7094 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |   6.2900e-05 |          0.0656 |
|     100 |         100 |       00:00:01 |      100.00% |   3.8519e-05 |          0.0387 |
|     150 |         150 |       00:00:01 |      100.00% |   3.6851e-05 |          0.0229 |
|     200 |         200 |       00:00:01 |      100.00% |   3.5968e-05 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
    0.0001
    0.0175
    0.0005
    0.0449
    0.0000
    0.0000
    0.8424
    0.0001
    0.0001
    0.0001
    0.0074
    0.0001
    0.0074
    0.9913
    0.0000
    0.0002
    0.0003
    0.9913
    0.0001
    0.0001
    0.0000
    0.0000
    0.0001
    0.9892
    0.0112
    0.0058
    0.0000
    0.9892
    0.0074
    0.9999

    30     1

{Error using <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('perfcurve', '/Applications/MATLAB_R2024b.app/toolbox/shared/mlearnlib/core/perfcurve.m', 460)" style="font-weight:bold">perfcurve</a> (<a href="matlab: opentoline('/Applications/MATLAB_R2024b.app/toolbox/shared/mlearnlib/core/perfcurve.m',460,0)">line 460</a>)
Less than two classes are found in the array of true class labels.

Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/MATLAB/WLNM.m', 49)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/WLNM.m',49,0)">line 49</a>)
    [~, ~, ~, auc] = perfcurve(test_label', scores', 1);
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/MATLAB/Main.m', 129)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/Main.m',129,0)">line 129</a>)
    [auc, best_threshold, best_precision, best_recall, best_f1_score] = WLNM(dataname, train, test, K, taxonomy, mass);
                                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/MATLAB/Main.m', 81)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/Main.m',81,0)">line 81</a>)
                results(ith_experiment) = processExperiment(ith_experiment, dataname, net, taxonomy, mass, ratioTrain, K);
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
} 
Main
Processing dataset: SF1M2_tax_mass
Processing with K = 10
Experiment 1: Running WLNM...
Subgraph Pattern Encoding Begins...
Subgraph Pattern Encoding Progress 10%...
Subgraph Pattern Encoding Progress 20%...
Subgraph Pattern Encoding Progress 30%...
Subgraph Pattern Encoding Progress 40%...
Subgraph Pattern Encoding Progress 50%...
Subgraph Pattern Encoding Progress 60%...
Subgraph Pattern Encoding Progress 70%...
Subgraph Pattern Encoding Progress 80%...
Subgraph Pattern Encoding Progress 90%...
Subgraph Pattern Encoding Begins...
Subgraph Pattern Encoding Progress 10%...
Subgraph Pattern Encoding Progress 20%...
Subgraph Pattern Encoding Progress 30%...
Subgraph Pattern Encoding Progress 40%...
Subgraph Pattern Encoding Progress 50%...
Subgraph Pattern Encoding Progress 60%...
Subgraph Pattern Encoding Progress 70%...
Subgraph Pattern Encoding Progress 80%...
Subgraph Pattern Encoding Progress 90%...
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |        8.33% |       0.7138 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |   4.2526e-05 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |   8.7817e-06 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |   8.5929e-06 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |   8.5333e-06 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
    0.0018
    0.0000
    0.5635
    0.0000
    0.3577
    0.0001
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0041
    0.0000
    0.0000
    0.0000
    0.0041
    0.0000
    0.0000
    0.0000
    0.0000
    0.0001
    0.0000
    1.0000
    0.0002
    0.0005
    0.0001
    1.0000
    0.2431
    1.0000

    33     1

Best Threshold: 0.00, Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000
AUC: 0.7500
Processing dataset: SF1M2_tax_mass
Processing with K = 10
Experiment 1: Running WLNM...
Subgraph Pattern Encoding Begins...
Subgraph Pattern Encoding Progress 10%...
Subgraph Pattern Encoding Progress 20%...
Subgraph Pattern Encoding Progress 30%...
Subgraph Pattern Encoding Progress 40%...
Subgraph Pattern Encoding Progress 50%...
Subgraph Pattern Encoding Progress 60%...
Subgraph Pattern Encoding Progress 70%...
Subgraph Pattern Encoding Progress 80%...
Subgraph Pattern Encoding Progress 90%...
Subgraph Pattern Encoding Begins...
Subgraph Pattern Encoding Progress 10%...
Subgraph Pattern Encoding Progress 20%...
Subgraph Pattern Encoding Progress 30%...
Subgraph Pattern Encoding Progress 40%...
Subgraph Pattern Encoding Progress 50%...
Subgraph Pattern Encoding Progress 60%...
Subgraph Pattern Encoding Progress 70%...
Subgraph Pattern Encoding Progress 80%...
Subgraph Pattern Encoding Progress 90%...
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       44.44% |       0.6808 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |   9.3610e-05 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |   4.2323e-05 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |   3.6020e-05 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |   3.3295e-05 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
    0.9701
    0.9701
    1.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    1.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0003
    0.0496
    0.0003

    19     1

Best Threshold: 0.10, Precision: 0.7500, Recall: 1.0000, F1-Score: 0.8571
AUC: 0.9583
Processing dataset: SF1M2_tax_mass
Processing with K = 10
Experiment 1: Running WLNM...
Subgraph Pattern Encoding Begins...
Subgraph Pattern Encoding Progress 10%...
Subgraph Pattern Encoding Progress 20%...
Subgraph Pattern Encoding Progress 30%...
Subgraph Pattern Encoding Progress 40%...
Subgraph Pattern Encoding Progress 50%...
Subgraph Pattern Encoding Progress 60%...
Subgraph Pattern Encoding Progress 70%...
Subgraph Pattern Encoding Progress 80%...
Subgraph Pattern Encoding Progress 90%...
Subgraph Pattern Encoding Begins...
Subgraph Pattern Encoding Progress 10%...
Subgraph Pattern Encoding Progress 20%...
Subgraph Pattern Encoding Progress 30%...
Subgraph Pattern Encoding Progress 40%...
Subgraph Pattern Encoding Progress 50%...
Subgraph Pattern Encoding Progress 60%...
Subgraph Pattern Encoding Progress 70%...
Subgraph Pattern Encoding Progress 80%...
Subgraph Pattern Encoding Progress 90%...
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       36.11% |       0.7076 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0003 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |   6.6598e-05 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |   5.9544e-05 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |   5.6390e-05 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
    0.9818
    0.9818
    0.0820
    0.0001
    0.0001
    0.0001
    0.0000
    0.0002
    0.9769
    0.0000
    0.0000
    0.4746
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0027
    0.0000
    0.8345
    0.0001
    0.0000
    0.0000
    0.0000
    0.0000
    0.0001
    0.0001
    0.0001
    0.0000
    0.0001
    0.0034
    0.0001
    0.0001
    0.0000
    0.0001
    0.9872
    0.0000
    0.0000
    0.0000
    0.0000
    0.0001
    0.0001
    0.0001
    0.0034
    0.0001
    0.0001
    0.7134
    0.0000
    0.0000
    0.0000
    0.1967
    0.3881
    0.1967

    54     1

Best Threshold: 0.85, Precision: 0.5000, Recall: 0.6667, F1-Score: 0.5714
AUC: 0.9346
Processing dataset: SF1M2_tax_mass
Processing with K = 10
Experiment 1: Running WLNM...
Subgraph Pattern Encoding Begins for 36 samples...
{Error using <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('horzcat')" style="font-weight:bold">horzcat</a>
Dimensions of arrays being concatenated are not consistent.

Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('graph2vector>neighbors_vectorized', '/Users/jorge/Documents/MATLAB/graph2vector.m', 178)" style="font-weight:bold">graph2vector>neighbors_vectorized</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/graph2vector.m',178,0)">line 178</a>)
    N = [repelem(from_nodes, numel(successors))', repmat(successors, numel(from_nodes), 1)];
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('graph2vector>subgraph2vector', '/Users/jorge/Documents/MATLAB/graph2vector.m', 102)" style="font-weight:bold">graph2vector>subgraph2vector</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/graph2vector.m',102,0)">line 102</a>)
        fringe = neighbors_vectorized(fringe, A);
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('graph2vector', '/Users/jorge/Documents/MATLAB/graph2vector.m', 59)" style="font-weight:bold">graph2vector</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/graph2vector.m',59,0)">line 59</a>)
            data(i, :) = subgraph2vector(ind, A, K);
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/MATLAB/WLNM.m', 31)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/WLNM.m',31,0)">line 31</a>)
    [train_data, train_label] = graph2vector(train_pos, train_neg, train, K, useParallel);
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/MATLAB/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/Main.m',131,0)">line 131</a>)
    [auc, best_threshold, best_precision, best_recall, best_f1_score] = WLNM(dataname, train, test, K, taxonomy, mass);
                                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/MATLAB/Main.m', 82)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/Main.m',82,0)">line 82</a>)
                results(ith_experiment) = processExperiment(ith_experiment, dataname, net, taxonomy, mass, ratioTrain, K);
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
} 
opentoline('/Users/jorge/Documents/MATLAB/graph2vector.m',178,0)
Main
Processing dataset: SF1M2_tax_mass
Processing with K = 10
Experiment 1: Running WLNM...
Subgraph Pattern Encoding Begins for 36 samples...
Progress: 8% — Elapsed: 0.3 seconds
Progress: 17% — Elapsed: 0.4 seconds
Progress: 25% — Elapsed: 0.4 seconds
Progress: 33% — Elapsed: 0.4 seconds
Progress: 42% — Elapsed: 0.4 seconds
{Error using <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('setdiff>setdiffR2012a', '/Applications/MATLAB_R2024b.app/toolbox/matlab/ops/setdiff.m', 261)" style="font-weight:bold">setdiff>setdiffR2012a</a> (<a href="matlab: opentoline('/Applications/MATLAB_R2024b.app/toolbox/matlab/ops/setdiff.m',261,0)">line 261</a>)
Inputs A and B must have the same number of columns in the 'rows' case.

Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('setdiff', '/Applications/MATLAB_R2024b.app/toolbox/matlab/ops/setdiff.m', 163)" style="font-weight:bold">setdiff</a> (<a href="matlab: opentoline('/Applications/MATLAB_R2024b.app/toolbox/matlab/ops/setdiff.m',163,0)">line 163</a>)
        [varargout{1:nlhs}] = setdiffR2012a(varargin{1:2},logical(flaginds(1:3)));
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('graph2vector>subgraph2vector', '/Users/jorge/Documents/MATLAB/graph2vector.m', 103)" style="font-weight:bold">graph2vector>subgraph2vector</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/graph2vector.m',103,0)">line 103</a>)
        fringe = setdiff(fringe, links, 'rows');
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('graph2vector', '/Users/jorge/Documents/MATLAB/graph2vector.m', 59)" style="font-weight:bold">graph2vector</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/graph2vector.m',59,0)">line 59</a>)
            data(i, :) = subgraph2vector(ind, A, K);
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/MATLAB/WLNM.m', 31)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/WLNM.m',31,0)">line 31</a>)
    [train_data, train_label] = graph2vector(train_pos, train_neg, train, K, useParallel);
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/MATLAB/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/Main.m',131,0)">line 131</a>)
    [auc, best_threshold, best_precision, best_recall, best_f1_score] = WLNM(dataname, train, test, K, taxonomy, mass);
                                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/MATLAB/Main.m', 82)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/Main.m',82,0)">line 82</a>)
                results(ith_experiment) = processExperiment(ith_experiment, dataname, net, taxonomy, mass, ratioTrain, K);
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
} 
Main
Processing dataset: SF1M2_tax_mass
Processing with K = 10
Experiment 1: Running WLNM...
Subgraph Pattern Encoding Begins for 36 samples...
Progress: 8% — Elapsed: 0.0 seconds
Progress: 17% — Elapsed: 0.1 seconds
Progress: 25% — Elapsed: 0.1 seconds
Progress: 33% — Elapsed: 0.1 seconds
Progress: 42% — Elapsed: 0.1 seconds
Progress: 50% — Elapsed: 0.1 seconds
Progress: 58% — Elapsed: 0.1 seconds
Progress: 67% — Elapsed: 0.2 seconds
Progress: 75% — Elapsed: 0.2 seconds
Progress: 83% — Elapsed: 0.2 seconds
Progress: 92% — Elapsed: 0.2 seconds
Progress: 100% — Elapsed: 0.2 seconds
Subgraph Pattern Encoding Begins for 54 samples...
Progress: 9% — Elapsed: 0.0 seconds
Progress: 19% — Elapsed: 0.0 seconds
Progress: 28% — Elapsed: 0.0 seconds
Progress: 37% — Elapsed: 0.1 seconds
Progress: 46% — Elapsed: 0.1 seconds
Progress: 56% — Elapsed: 0.1 seconds
Progress: 65% — Elapsed: 0.1 seconds
Progress: 74% — Elapsed: 0.1 seconds
Progress: 83% — Elapsed: 0.1 seconds
Progress: 93% — Elapsed: 0.1 seconds
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       63.89% |       0.6955 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0002 |          0.0656 |
|     100 |         100 |       00:00:01 |      100.00% |   5.9447e-05 |          0.0387 |
|     150 |         150 |       00:00:01 |      100.00% |   5.1720e-05 |          0.0229 |
|     200 |         200 |       00:00:01 |      100.00% |   4.8370e-05 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
    0.9916
    0.9916
    0.9783
    0.0000
    0.0000
    0.0000
    0.0000
    0.0001
    0.9986
    0.0000
    0.0000
    0.9999
    0.0000
    1.0000
    0.0000
    0.0000
    0.0000
    0.0000
    1.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0004
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.7865
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0035
    0.0000
    0.0000
    0.4496
    0.0001

    54     1

Best Threshold: 0.80, Precision: 0.4286, Recall: 1.0000, F1-Score: 0.6000
AUC: 0.9216
Processing dataset: SF1M2_tax_mass
Processing with K = 10
Experiment 1: Running WLNM...
Subgraph Pattern Encoding Begins for 36 samples...
{gcp requires <a href="matlab:matlab.internal.addons.launchers.showExplorer('ErrorRecovery', 'identifier', 'DM', 'focused', 'gcp');">Parallel Computing Toolbox</a>.

Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('graph2vector', '/Users/jorge/Documents/MATLAB/graph2vector.m', 41)" style="font-weight:bold">graph2vector</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/graph2vector.m',41,0)">line 41</a>)
        if isempty(gcp('nocreate'))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/MATLAB/WLNM.m', 31)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/WLNM.m',31,0)">line 31</a>)
    [train_data, train_label] = graph2vector(train_pos, train_neg, train, K, useParallel);
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/MATLAB/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/Main.m',131,0)">line 131</a>)
    [auc, best_threshold, best_precision, best_recall, best_f1_score] = WLNM(dataname, train, test, K, taxonomy, mass);
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Error in <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/MATLAB/Main.m', 82)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/Main.m',82,0)">line 82</a>)
                results(ith_experiment) = processExperiment(ith_experiment, dataname, net, taxonomy, mass, ratioTrain, K);
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
} 
matlab.internal.addons.launchers.showExplorer('ErrorRecovery', 'identifier', 'DM', 'focused', 'gcp');
Processing dataset: SF1M2_tax_mass
Processing with K = 10
Experiment 1: Running WLNM...
Subgraph Pattern Encoding Begins for 36 samples...
Starting parallel pool (parpool) using the 'Processes' profile ...
Connected to parallel pool with 8 workers.
Progress: 42% — Elapsed: 2.5 seconds
Progress: 25% — Elapsed: 1.8 seconds
Progress: 75% — Elapsed: 1.7 seconds
Progress: 92% — Elapsed: 1.7 seconds
Progress: 100% — Elapsed: 1.7 seconds
Progress: 17% — Elapsed: 1.9 seconds
Progress: 67% — Elapsed: 1.3 seconds
Progress: 8% — Elapsed: 1.6 seconds
Progress: 33% — Elapsed: 1.6 seconds
Progress: 58% — Elapsed: 1.5 seconds
Progress: 50% — Elapsed: 1.9 seconds
Progress: 83% — Elapsed: 1.4 seconds
Parallel pool using the 'Processes' profile is shutting down.
Subgraph Pattern Encoding Begins for 54 samples...
Starting parallel pool (parpool) using the 'Processes' profile ...
Connected to parallel pool with 8 workers.
Progress: 37% — Elapsed: 1.3 seconds
Progress: 28% — Elapsed: 1.6 seconds
Progress: 9% — Elapsed: 1.3 seconds
Progress: 56% — Elapsed: 1.2 seconds
Progress: 19% — Elapsed: 1.3 seconds
Progress: 65% — Elapsed: 1.4 seconds
Progress: 74% — Elapsed: 1.4 seconds
Progress: 46% — Elapsed: 0.9 seconds
Progress: 83% — Elapsed: 1.3 seconds
Progress: 93% — Elapsed: 1.1 seconds
Parallel pool using the 'Processes' profile is shutting down.
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       66.67% |       0.6941 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0002 |          0.0656 |
|     100 |         100 |       00:00:01 |      100.00% |   6.1060e-05 |          0.0387 |
|     150 |         150 |       00:00:01 |      100.00% |   5.2439e-05 |          0.0229 |
|     200 |         200 |       00:00:01 |      100.00% |   4.8887e-05 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
    0.9869
    0.9869
    0.9766
    0.0000
    0.0000
    0.0000
    0.0000
    0.0002
    0.9943
    0.0000
    0.0000
    0.9999
    0.0000
    1.0000
    0.0000
    0.0000
    0.0000
    0.0000
    1.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0003
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.9001
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0053
    0.0000
    0.0000
    0.0020
    0.0001

    54     1

Best Threshold: 0.10, Precision: 0.3750, Recall: 1.0000, F1-Score: 0.5455
AUC: 0.9216
Processing dataset: SF1M2_tax_mass
Processing with K = 10
Experiment 1: Running WLNM...
Subgraph Pattern Encoding Begins for 48 samples...
Progress: 8% — Elapsed: 0.3 seconds
Progress: 17% — Elapsed: 0.4 seconds
Progress: 25% — Elapsed: 0.4 seconds
Progress: 33% — Elapsed: 0.4 seconds
Progress: 42% — Elapsed: 0.4 seconds
Progress: 50% — Elapsed: 0.4 seconds
Progress: 58% — Elapsed: 0.5 seconds
Progress: 67% — Elapsed: 0.5 seconds
Progress: 75% — Elapsed: 0.5 seconds
Progress: 83% — Elapsed: 0.5 seconds
Progress: 92% — Elapsed: 0.5 seconds
Progress: 100% — Elapsed: 0.5 seconds
Subgraph Pattern Encoding Begins for 42 samples...
Progress: 10% — Elapsed: 0.0 seconds
Progress: 19% — Elapsed: 0.0 seconds
Progress: 29% — Elapsed: 0.1 seconds
Progress: 38% — Elapsed: 0.1 seconds
Progress: 48% — Elapsed: 0.1 seconds
Progress: 57% — Elapsed: 0.1 seconds
Progress: 67% — Elapsed: 0.1 seconds
Progress: 76% — Elapsed: 0.1 seconds
Progress: 86% — Elapsed: 0.1 seconds
Progress: 95% — Elapsed: 0.1 seconds
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       72.92% |       0.6845 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0004 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0001 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0001 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |   9.3657e-05 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
    0.9779
    0.9779
    0.9213
    0.0000
    0.0000
    0.0000
    0.0004
    0.9848
    0.0000
    0.0000
    0.9553
    0.8537
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0004
    0.0000
    0.0000
    0.0000
    0.0000
    0.7579
    0.0000
    0.0000
    0.0001
    0.0000
    0.0000
    0.0000
    0.0000
    0.0360
    0.0000
    0.0000
    0.0001
    0.0005

    42     1

Best Threshold: 0.90, Precision: 0.6000, Recall: 1.0000, F1-Score: 0.7500
AUC: 0.9658
Processing dataset: SF1M2_tax_mass
Processing with K = 10
Experiment 1: Running WLNM...
Subgraph Pattern Encoding Begins for 60 samples...
Progress: 10% — Elapsed: 0.1 seconds
Progress: 20% — Elapsed: 0.1 seconds
Progress: 30% — Elapsed: 0.1 seconds
Progress: 40% — Elapsed: 0.2 seconds
Progress: 50% — Elapsed: 0.2 seconds
Progress: 60% — Elapsed: 0.2 seconds
Progress: 70% — Elapsed: 0.2 seconds
Progress: 80% — Elapsed: 0.2 seconds
Progress: 90% — Elapsed: 0.2 seconds
Progress: 100% — Elapsed: 0.2 seconds
Subgraph Pattern Encoding Begins for 30 samples...
Progress: 10% — Elapsed: 0.0 seconds
Progress: 20% — Elapsed: 0.0 seconds
Progress: 30% — Elapsed: 0.0 seconds
Progress: 40% — Elapsed: 0.0 seconds
Progress: 50% — Elapsed: 0.0 seconds
Progress: 60% — Elapsed: 0.0 seconds
Progress: 70% — Elapsed: 0.0 seconds
Progress: 80% — Elapsed: 0.0 seconds
Progress: 90% — Elapsed: 0.0 seconds
Progress: 100% — Elapsed: 0.0 seconds
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       78.33% |       0.6759 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0010 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0002 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0002 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0002 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
    0.8821
    0.8821
    0.4798
    0.0000
    0.0000
    0.0016
    0.9188
    0.0000
    0.0000
    0.9019
    0.0000
    0.0000
    0.0000
    0.0001
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.6416
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0019
    0.0000
    0.0000
    0.0001
    0.0006

    30     1

Best Threshold: 0.10, Precision: 0.5000, Recall: 1.0000, F1-Score: 0.6667
AUC: 0.9136
Processing dataset: SF1M2_tax_mass
Processing with K = 10
Experiment 1: Running WLNM...
Subgraph Pattern Encoding Begins for 72 samples...
Progress: 10% — Elapsed: 0.0 seconds
Progress: 19% — Elapsed: 0.0 seconds
Progress: 29% — Elapsed: 0.0 seconds
Progress: 39% — Elapsed: 0.0 seconds
Progress: 49% — Elapsed: 0.0 seconds
Progress: 58% — Elapsed: 0.1 seconds
Progress: 68% — Elapsed: 0.1 seconds
Progress: 78% — Elapsed: 0.1 seconds
Progress: 88% — Elapsed: 0.1 seconds
Progress: 97% — Elapsed: 0.1 seconds
Subgraph Pattern Encoding Begins for 18 samples...
Progress: 6% — Elapsed: 0.0 seconds
Progress: 11% — Elapsed: 0.0 seconds
Progress: 17% — Elapsed: 0.0 seconds
Progress: 22% — Elapsed: 0.0 seconds
Progress: 28% — Elapsed: 0.0 seconds
Progress: 33% — Elapsed: 0.0 seconds
Progress: 39% — Elapsed: 0.0 seconds
Progress: 44% — Elapsed: 0.0 seconds
Progress: 50% — Elapsed: 0.0 seconds
Progress: 56% — Elapsed: 0.0 seconds
Progress: 61% — Elapsed: 0.0 seconds
Progress: 67% — Elapsed: 0.0 seconds
Progress: 72% — Elapsed: 0.0 seconds
Progress: 78% — Elapsed: 0.0 seconds
Progress: 83% — Elapsed: 0.0 seconds
Progress: 89% — Elapsed: 0.0 seconds
Progress: 94% — Elapsed: 0.0 seconds
Progress: 100% — Elapsed: 0.0 seconds
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       80.56% |       0.6679 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0028 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0003 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0003 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0002 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
    0.2105
    0.2105
    0.5277
    0.0000
    0.0021
    0.0000
    0.6897
    0.0001
    0.0000
    0.0000
    0.0000
    0.6647
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000

    18     1

Best Threshold: 0.10, Precision: 0.6000, Recall: 1.0000, F1-Score: 0.7500
AUC: 0.8667
Processing dataset: SF1M2_tax_mass
Processing with K = 10
Experiment 1: Running WLNM...
[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/MATLAB/sample_neg.m', 53)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/sample_neg.m',53,0)">line 53</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/MATLAB/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/MATLAB/Main.m', 131)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/Main.m',131,0)">line 131</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/MATLAB/Main.m', 82)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/MATLAB/Main.m',82,0)">line 82</a>)] 
Subgraph Pattern Encoding Begins for 72 samples...
Progress: 10% — Elapsed: 0.2 seconds
Progress: 19% — Elapsed: 0.2 seconds
Progress: 29% — Elapsed: 0.2 seconds
Progress: 39% — Elapsed: 0.2 seconds
Progress: 49% — Elapsed: 0.2 seconds
Progress: 58% — Elapsed: 0.2 seconds
Progress: 68% — Elapsed: 0.2 seconds
Progress: 78% — Elapsed: 0.3 seconds
Progress: 88% — Elapsed: 0.3 seconds
Progress: 97% — Elapsed: 0.3 seconds
Subgraph Pattern Encoding Begins for 18 samples...
Progress: 6% — Elapsed: 0.0 seconds
Progress: 11% — Elapsed: 0.0 seconds
Progress: 17% — Elapsed: 0.0 seconds
Progress: 22% — Elapsed: 0.0 seconds
Progress: 28% — Elapsed: 0.0 seconds
Progress: 33% — Elapsed: 0.0 seconds
Progress: 39% — Elapsed: 0.0 seconds
Progress: 44% — Elapsed: 0.1 seconds
Progress: 50% — Elapsed: 0.1 seconds
Progress: 56% — Elapsed: 0.1 seconds
Progress: 61% — Elapsed: 0.1 seconds
Progress: 67% — Elapsed: 0.1 seconds
Progress: 72% — Elapsed: 0.1 seconds
Progress: 78% — Elapsed: 0.1 seconds
Progress: 83% — Elapsed: 0.1 seconds
Progress: 89% — Elapsed: 0.1 seconds
Progress: 94% — Elapsed: 0.1 seconds
Progress: 100% — Elapsed: 0.1 seconds
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       80.56% |       0.6679 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0028 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0003 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0003 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0002 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
    0.2105
    0.2105
    0.5277
    0.0000
    0.0021
    0.0000
    0.6897
    0.0001
    0.0000
    0.0000
    0.0000
    0.6647
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000

    18     1

Best Threshold: 0.10, Precision: 0.6000, Recall: 1.0000, F1-Score: 0.7500
AUC: 0.8667
Processing dataset: SF1M2_tax_mass
Processing with K = 10
Experiment 1: Running WLNM...
Subgraph Pattern Encoding Begins for 48 samples...
Progress: 8% — Elapsed: 0.0 seconds
Progress: 17% — Elapsed: 0.0 seconds
Progress: 25% — Elapsed: 0.0 seconds
Progress: 33% — Elapsed: 0.0 seconds
Progress: 42% — Elapsed: 0.0 seconds
Progress: 50% — Elapsed: 0.0 seconds
Progress: 58% — Elapsed: 0.0 seconds
Progress: 67% — Elapsed: 0.1 seconds
Progress: 75% — Elapsed: 0.1 seconds
Progress: 83% — Elapsed: 0.1 seconds
Progress: 92% — Elapsed: 0.1 seconds
Progress: 100% — Elapsed: 0.1 seconds
Subgraph Pattern Encoding Begins for 42 samples...
Progress: 10% — Elapsed: 0.0 seconds
Progress: 19% — Elapsed: 0.0 seconds
Progress: 29% — Elapsed: 0.0 seconds
Progress: 38% — Elapsed: 0.0 seconds
Progress: 48% — Elapsed: 0.0 seconds
Progress: 57% — Elapsed: 0.0 seconds
Progress: 67% — Elapsed: 0.0 seconds
Progress: 76% — Elapsed: 0.0 seconds
Progress: 86% — Elapsed: 0.0 seconds
Progress: 95% — Elapsed: 0.0 seconds
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       72.92% |       0.6845 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0004 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0001 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0001 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |   9.3657e-05 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
    0.9779
    0.9779
    0.9213
    0.0000
    0.0000
    0.0000
    0.0004
    0.9848
    0.0000
    0.0000
    0.9553
    0.8537
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0004
    0.0000
    0.0000
    0.0000
    0.0000
    0.7579
    0.0000
    0.0000
    0.0001
    0.0000
    0.0000
    0.0000
    0.0000
    0.0360
    0.0000
    0.0000
    0.0001
    0.0005

    42     1

Best Threshold: 0.90, Precision: 0.6000, Recall: 1.0000, F1-Score: 0.7500
AUC: 0.9658
Processing dataset: SF1M2_tax_mass
Processing with K = 10
Experiment 1: Running WLNM...
Subgraph Pattern Encoding Begins for 36 samples...
Progress: 8% — Elapsed: 0.0 seconds
Progress: 17% — Elapsed: 0.0 seconds
Progress: 25% — Elapsed: 0.0 seconds
Progress: 33% — Elapsed: 0.0 seconds
Progress: 42% — Elapsed: 0.0 seconds
Progress: 50% — Elapsed: 0.0 seconds
Progress: 58% — Elapsed: 0.0 seconds
Progress: 67% — Elapsed: 0.0 seconds
Progress: 75% — Elapsed: 0.0 seconds
Progress: 83% — Elapsed: 0.0 seconds
Progress: 92% — Elapsed: 0.0 seconds
Progress: 100% — Elapsed: 0.0 seconds
Subgraph Pattern Encoding Begins for 54 samples...
Progress: 9% — Elapsed: 0.0 seconds
Progress: 19% — Elapsed: 0.0 seconds
Progress: 28% — Elapsed: 0.0 seconds
Progress: 37% — Elapsed: 0.0 seconds
Progress: 46% — Elapsed: 0.0 seconds
Progress: 56% — Elapsed: 0.0 seconds
Progress: 65% — Elapsed: 0.0 seconds
Progress: 74% — Elapsed: 0.0 seconds
Progress: 83% — Elapsed: 0.0 seconds
Progress: 93% — Elapsed: 0.1 seconds
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       66.67% |       0.6941 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0002 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |   6.1060e-05 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |   5.2439e-05 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |   4.8887e-05 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
    0.9869
    0.9869
    0.9766
    0.0000
    0.0000
    0.0000
    0.0000
    0.0002
    0.9943
    0.0000
    0.0000
    0.9999
    0.0000
    1.0000
    0.0000
    0.0000
    0.0000
    0.0000
    1.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0003
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.9001
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0000
    0.0053
    0.0000
    0.0000
    0.0020
    0.0001

    54     1

Best Threshold: 0.10, Precision: 0.3750, Recall: 1.0000, F1-Score: 0.5455
AUC: 0.9216
