Processing dataset: Fawn lake_tax_mass
    "Processing with K …"    "10"    " using strategy: "    "random"

    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 119)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',119,0)">line 119</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 85)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',85,0)">line 85</a>)] 
[sample_neg] Final link counts:
    Train Positive: 95
    Train Negative: 95
    Test  Positive: 24
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 190 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 19 of 190: (19,8)
Progress: 20% – Elapsed: 0.0s
Encoding link 38 of 190: (1,16)
Progress: 30% – Elapsed: 0.0s
Encoding link 57 of 190: (7,21)
Progress: 40% – Elapsed: 0.0s
Encoding link 76 of 190: (21,27)
Progress: 50% – Elapsed: 0.0s
Encoding link 95 of 190: (30,31)
Progress: 60% – Elapsed: 0.0s
Encoding link 114 of 190: (30,24)
Progress: 70% – Elapsed: 0.0s
Encoding link 133 of 190: (7,30)
Progress: 80% – Elapsed: 0.0s
Encoding link 152 of 190: (28,20)
Progress: 90% – Elapsed: 0.0s
Encoding link 171 of 190: (20,17)
Progress: 100% – Elapsed: 0.1s
Encoding link 190 of 190: (25,15)
Done. Total time: 0.1s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 4 of 48: (6,9)
Progress: 17% – Elapsed: 0.0s
Encoding link 8 of 48: (26,16)
Progress: 25% – Elapsed: 0.0s
Encoding link 12 of 48: (12,18)
Progress: 33% – Elapsed: 0.0s
Encoding link 16 of 48: (6,21)
Progress: 42% – Elapsed: 0.0s
Encoding link 20 of 48: (5,31)
Progress: 50% – Elapsed: 0.0s
Encoding link 24 of 48: (27,31)
Progress: 58% – Elapsed: 0.0s
Encoding link 28 of 48: (19,32)
Progress: 67% – Elapsed: 0.0s
Encoding link 32 of 48: (20,6)
Progress: 75% – Elapsed: 0.0s
Encoding link 36 of 48: (7,32)
Progress: 83% – Elapsed: 0.0s
Encoding link 40 of 48: (25,10)
Progress: 92% – Elapsed: 0.0s
Encoding link 44 of 48: (15,11)
Progress: 100% – Elapsed: 0.0s
Encoding link 48 of 48: (6,7)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       49.22% |       0.6931 |          0.1000 |
|      50 |          50 |       00:00:00 |       99.22% |       0.0382 |          0.0656 |
|     100 |         100 |       00:00:00 |       99.22% |       0.0346 |          0.0387 |
|     150 |         150 |       00:00:00 |       99.22% |       0.0345 |          0.0229 |
|     200 |         200 |       00:00:00 |       99.22% |       0.0344 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.9583, F1-Score: 0.9787
AUC: 1.0000
    "Experiment "    "2"    " (strategy: "    "random"    ") — Running WLNM..."

[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 119)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',119,0)">line 119</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 85)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',85,0)">line 85</a>)] 
[sample_neg] Final link counts:
    Train Positive: 95
    Train Negative: 95
    Test  Positive: 24
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 190 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 19 of 190: (19,8)
Progress: 20% – Elapsed: 0.0s
Encoding link 38 of 190: (1,16)
Progress: 30% – Elapsed: 0.0s
Encoding link 57 of 190: (7,21)
Progress: 40% – Elapsed: 0.1s
Encoding link 76 of 190: (21,27)
Progress: 50% – Elapsed: 0.1s
Encoding link 95 of 190: (30,31)
Progress: 60% – Elapsed: 0.1s
Encoding link 114 of 190: (10,25)
Progress: 70% – Elapsed: 0.1s
Encoding link 133 of 190: (15,11)
Progress: 80% – Elapsed: 0.1s
Encoding link 152 of 190: (25,17)
Progress: 90% – Elapsed: 0.1s
Encoding link 171 of 190: (7,30)
Progress: 100% – Elapsed: 0.1s
Encoding link 190 of 190: (15,30)
Done. Total time: 0.1s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 4 of 48: (6,9)
Progress: 17% – Elapsed: 0.0s
Encoding link 8 of 48: (26,16)
Progress: 25% – Elapsed: 0.0s
Encoding link 12 of 48: (12,18)
Progress: 33% – Elapsed: 0.0s
Encoding link 16 of 48: (6,21)
Progress: 42% – Elapsed: 0.0s
Encoding link 20 of 48: (5,31)
Progress: 50% – Elapsed: 0.0s
Encoding link 24 of 48: (27,31)
Progress: 58% – Elapsed: 0.0s
Encoding link 28 of 48: (32,11)
Progress: 67% – Elapsed: 0.0s
Encoding link 32 of 48: (24,10)
Progress: 75% – Elapsed: 0.0s
Encoding link 36 of 48: (20,32)
Progress: 83% – Elapsed: 0.0s
Encoding link 40 of 48: (24,15)
Progress: 92% – Elapsed: 0.0s
Encoding link 44 of 48: (17,30)
Progress: 100% – Elapsed: 0.0s
Encoding link 48 of 48: (3,25)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       51.56% |       0.7849 |          0.1000 |
|      50 |          50 |       00:00:00 |       98.44% |       0.0619 |          0.0656 |
|     100 |         100 |       00:00:00 |       98.44% |       0.0599 |          0.0387 |
|     150 |         150 |       00:00:00 |       98.44% |       0.0598 |          0.0229 |
|     200 |         200 |       00:00:00 |       98.44% |       0.0598 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.9167, F1-Score: 0.9565
AUC: 0.9844
    "Experiment "    "3"    " (strategy: "    "random"    ") — Running WLNM..."

[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 119)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',119,0)">line 119</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 85)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',85,0)">line 85</a>)] 
[sample_neg] Final link counts:
    Train Positive: 95
    Train Negative: 95
    Test  Positive: 24
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 190 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 19 of 190: (19,8)
Progress: 20% – Elapsed: 0.0s
Encoding link 38 of 190: (1,16)
Progress: 30% – Elapsed: 0.0s
Encoding link 57 of 190: (7,21)
Progress: 40% – Elapsed: 0.0s
Encoding link 76 of 190: (21,27)
Progress: 50% – Elapsed: 0.0s
Encoding link 95 of 190: (30,31)
Progress: 60% – Elapsed: 0.0s
Encoding link 114 of 190: (28,17)
Progress: 70% – Elapsed: 0.0s
Encoding link 133 of 190: (10,24)
Progress: 80% – Elapsed: 0.0s
Encoding link 152 of 190: (17,7)
Progress: 90% – Elapsed: 0.1s
Encoding link 171 of 190: (10,17)
Progress: 100% – Elapsed: 0.1s
Encoding link 190 of 190: (25,20)
Done. Total time: 0.1s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 4 of 48: (6,9)
Progress: 17% – Elapsed: 0.0s
Encoding link 8 of 48: (26,16)
Progress: 25% – Elapsed: 0.0s
Encoding link 12 of 48: (12,18)
Progress: 33% – Elapsed: 0.0s
Encoding link 16 of 48: (6,21)
Progress: 42% – Elapsed: 0.0s
Encoding link 20 of 48: (5,31)
Progress: 50% – Elapsed: 0.0s
Encoding link 24 of 48: (27,31)
Progress: 58% – Elapsed: 0.0s
Encoding link 28 of 48: (7,6)
Progress: 67% – Elapsed: 0.0s
Encoding link 32 of 48: (7,11)
Progress: 75% – Elapsed: 0.0s
Encoding link 36 of 48: (6,30)
Progress: 83% – Elapsed: 0.0s
Encoding link 40 of 48: (20,32)
Progress: 92% – Elapsed: 0.1s
Encoding link 44 of 48: (3,25)
Progress: 100% – Elapsed: 0.1s
Encoding link 48 of 48: (30,11)
Done. Total time: 0.1s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       42.97% |       0.7113 |          0.1000 |
|      50 |          50 |       00:00:00 |       99.22% |       0.0366 |          0.0656 |
|     100 |         100 |       00:00:00 |       99.22% |       0.0362 |          0.0387 |
|     150 |         150 |       00:00:00 |       99.22% |       0.0362 |          0.0229 |
|     200 |         200 |       00:00:00 |       99.22% |       0.0361 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.15, Precision: 0.9167, Recall: 0.9167, F1-Score: 0.9167
AUC: 0.9514
    "Experiment "    "4"    " (strategy: "    "random"    ") — Running WLNM..."

[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 119)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',119,0)">line 119</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 85)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',85,0)">line 85</a>)] 
[sample_neg] Final link counts:
    Train Positive: 95
    Train Negative: 95
    Test  Positive: 24
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 190 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 19 of 190: (19,8)
Progress: 20% – Elapsed: 0.0s
Encoding link 38 of 190: (1,16)
Progress: 30% – Elapsed: 0.0s
Encoding link 57 of 190: (7,21)
Progress: 40% – Elapsed: 0.0s
Encoding link 76 of 190: (21,27)
Progress: 50% – Elapsed: 0.0s
Encoding link 95 of 190: (30,31)
Progress: 60% – Elapsed: 0.0s
Encoding link 114 of 190: (20,7)
Progress: 70% – Elapsed: 0.0s
Encoding link 133 of 190: (19,7)
Progress: 80% – Elapsed: 0.1s
Encoding link 152 of 190: (32,25)
Progress: 90% – Elapsed: 0.1s
Encoding link 171 of 190: (3,28)
Progress: 100% – Elapsed: 0.1s
Encoding link 190 of 190: (15,17)
Done. Total time: 0.1s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 4 of 48: (6,9)
Progress: 17% – Elapsed: 0.0s
Encoding link 8 of 48: (26,16)
Progress: 25% – Elapsed: 0.0s
Encoding link 12 of 48: (12,18)
Progress: 33% – Elapsed: 0.0s
Encoding link 16 of 48: (6,21)
Progress: 42% – Elapsed: 0.0s
Encoding link 20 of 48: (5,31)
Progress: 50% – Elapsed: 0.0s
Encoding link 24 of 48: (27,31)
Progress: 58% – Elapsed: 0.0s
Encoding link 28 of 48: (32,15)
Progress: 67% – Elapsed: 0.0s
Encoding link 32 of 48: (17,6)
Progress: 75% – Elapsed: 0.0s
Encoding link 36 of 48: (10,19)
Progress: 83% – Elapsed: 0.0s
Encoding link 40 of 48: (19,15)
Progress: 92% – Elapsed: 0.0s
Encoding link 44 of 48: (11,24)
Progress: 100% – Elapsed: 0.0s
Encoding link 48 of 48: (19,17)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       54.69% |       0.6953 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0003 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0001 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0001 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |   9.4731e-05 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9583, Recall: 0.9583, F1-Score: 0.9583
AUC: 0.9965
    "Experiment "    "5"    " (strategy: "    "random"    ") — Running WLNM..."

[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 119)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',119,0)">line 119</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 85)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',85,0)">line 85</a>)] 
[sample_neg] Final link counts:
    Train Positive: 95
    Train Negative: 95
    Test  Positive: 24
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 190 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 19 of 190: (19,8)
Progress: 20% – Elapsed: 0.0s
Encoding link 38 of 190: (1,16)
Progress: 30% – Elapsed: 0.0s
Encoding link 57 of 190: (7,21)
Progress: 40% – Elapsed: 0.0s
Encoding link 76 of 190: (21,27)
Progress: 50% – Elapsed: 0.0s
Encoding link 95 of 190: (30,31)
Progress: 60% – Elapsed: 0.0s
Encoding link 114 of 190: (30,10)
Progress: 70% – Elapsed: 0.0s
Encoding link 133 of 190: (6,11)
Progress: 80% – Elapsed: 0.1s
Encoding link 152 of 190: (24,10)
Progress: 90% – Elapsed: 0.1s
Encoding link 171 of 190: (17,24)
Progress: 100% – Elapsed: 0.1s
Encoding link 190 of 190: (25,6)
Done. Total time: 0.1s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 4 of 48: (6,9)
Progress: 17% – Elapsed: 0.0s
Encoding link 8 of 48: (26,16)
Progress: 25% – Elapsed: 0.0s
Encoding link 12 of 48: (12,18)
Progress: 33% – Elapsed: 0.0s
Encoding link 16 of 48: (6,21)
Progress: 42% – Elapsed: 0.0s
Encoding link 20 of 48: (5,31)
Progress: 50% – Elapsed: 0.0s
Encoding link 24 of 48: (27,31)
Progress: 58% – Elapsed: 0.0s
Encoding link 28 of 48: (24,19)
Progress: 67% – Elapsed: 0.0s
Encoding link 32 of 48: (3,32)
Progress: 75% – Elapsed: 0.0s
Encoding link 36 of 48: (10,30)
Progress: 83% – Elapsed: 0.0s
Encoding link 40 of 48: (11,19)
Progress: 92% – Elapsed: 0.0s
Encoding link 44 of 48: (28,15)
Progress: 100% – Elapsed: 0.0s
Encoding link 48 of 48: (6,30)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       50.78% |       0.7154 |          0.1000 |
|      50 |          50 |       00:00:00 |       98.44% |       0.0627 |          0.0656 |
|     100 |         100 |       00:00:00 |       98.44% |       0.0605 |          0.0387 |
|     150 |         150 |       00:00:00 |       98.44% |       0.0603 |          0.0229 |
|     200 |         200 |       00:00:00 |       98.44% |       0.0603 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.20, Precision: 1.0000, Recall: 0.9167, F1-Score: 0.9565
AUC: 0.9913
    "Experiment "    "6"    " (strategy: "    "random"    ") — Running WLNM..."

[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 119)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',119,0)">line 119</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 85)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',85,0)">line 85</a>)] 
[sample_neg] Final link counts:
    Train Positive: 95
    Train Negative: 95
    Test  Positive: 24
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 190 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 19 of 190: (19,8)
Progress: 20% – Elapsed: 0.0s
Encoding link 38 of 190: (1,16)
Progress: 30% – Elapsed: 0.0s
Encoding link 57 of 190: (7,21)
Progress: 40% – Elapsed: 0.0s
Encoding link 76 of 190: (21,27)
Progress: 50% – Elapsed: 0.0s
Encoding link 95 of 190: (30,31)
Progress: 60% – Elapsed: 0.0s
Encoding link 114 of 190: (7,20)
Progress: 70% – Elapsed: 0.0s
Encoding link 133 of 190: (25,20)
Progress: 80% – Elapsed: 0.0s
Encoding link 152 of 190: (7,17)
Progress: 90% – Elapsed: 0.0s
Encoding link 171 of 190: (10,7)
Progress: 100% – Elapsed: 0.1s
Encoding link 190 of 190: (6,30)
Done. Total time: 0.1s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 4 of 48: (6,9)
Progress: 17% – Elapsed: 0.0s
Encoding link 8 of 48: (26,16)
Progress: 25% – Elapsed: 0.0s
Encoding link 12 of 48: (12,18)
Progress: 33% – Elapsed: 0.0s
Encoding link 16 of 48: (6,21)
Progress: 42% – Elapsed: 0.0s
Encoding link 20 of 48: (5,31)
Progress: 50% – Elapsed: 0.0s
Encoding link 24 of 48: (27,31)
Progress: 58% – Elapsed: 0.0s
Encoding link 28 of 48: (19,24)
Progress: 67% – Elapsed: 0.0s
Encoding link 32 of 48: (28,32)
Progress: 75% – Elapsed: 0.0s
Encoding link 36 of 48: (19,15)
Progress: 83% – Elapsed: 0.0s
Encoding link 40 of 48: (28,24)
Progress: 92% – Elapsed: 0.0s
Encoding link 44 of 48: (11,28)
Progress: 100% – Elapsed: 0.0s
Encoding link 48 of 48: (30,20)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       48.44% |       0.6912 |          0.1000 |
|      50 |          50 |       00:00:00 |       99.22% |       0.0457 |          0.0656 |
|     100 |         100 |       00:00:00 |       99.22% |       0.0366 |          0.0387 |
|     150 |         150 |       00:00:00 |       99.22% |       0.0363 |          0.0229 |
|     200 |         200 |       00:00:00 |       99.22% |       0.0362 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.9167, F1-Score: 0.9565
AUC: 0.9983
    "Experiment "    "7"    " (strategy: "    "random"    ") — Running WLNM..."

[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 119)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',119,0)">line 119</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 85)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',85,0)">line 85</a>)] 
[sample_neg] Final link counts:
    Train Positive: 95
    Train Negative: 95
    Test  Positive: 24
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 190 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 19 of 190: (19,8)
Progress: 20% – Elapsed: 0.0s
Encoding link 38 of 190: (1,16)
Progress: 30% – Elapsed: 0.0s
Encoding link 57 of 190: (7,21)
Progress: 40% – Elapsed: 0.0s
Encoding link 76 of 190: (21,27)
Progress: 50% – Elapsed: 0.0s
Encoding link 95 of 190: (30,31)
Progress: 60% – Elapsed: 0.0s
Encoding link 114 of 190: (15,17)
Progress: 70% – Elapsed: 0.0s
Encoding link 133 of 190: (10,15)
Progress: 80% – Elapsed: 0.0s
Encoding link 152 of 190: (32,24)
Progress: 90% – Elapsed: 0.1s
Encoding link 171 of 190: (30,11)
Progress: 100% – Elapsed: 0.1s
Encoding link 190 of 190: (20,28)
Done. Total time: 0.1s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 4 of 48: (6,9)
Progress: 17% – Elapsed: 0.0s
Encoding link 8 of 48: (26,16)
Progress: 25% – Elapsed: 0.0s
Encoding link 12 of 48: (12,18)
Progress: 33% – Elapsed: 0.0s
Encoding link 16 of 48: (6,21)
Progress: 42% – Elapsed: 0.0s
Encoding link 20 of 48: (5,31)
Progress: 50% – Elapsed: 0.0s
Encoding link 24 of 48: (27,31)
Progress: 58% – Elapsed: 0.0s
Encoding link 28 of 48: (7,17)
Progress: 67% – Elapsed: 0.0s
Encoding link 32 of 48: (17,25)
Progress: 75% – Elapsed: 0.0s
Encoding link 36 of 48: (11,25)
Progress: 83% – Elapsed: 0.0s
Encoding link 40 of 48: (17,20)
Progress: 92% – Elapsed: 0.0s
Encoding link 44 of 48: (3,10)
Progress: 100% – Elapsed: 0.0s
Encoding link 48 of 48: (3,15)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       55.47% |       0.6752 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0012 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0003 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0002 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0002 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9600, Recall: 1.0000, F1-Score: 0.9796
AUC: 0.9757
    "Experiment "    "8"    " (strategy: "    "random"    ") — Running WLNM..."

[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 119)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',119,0)">line 119</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 85)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',85,0)">line 85</a>)] 
[sample_neg] Final link counts:
    Train Positive: 95
    Train Negative: 95
    Test  Positive: 24
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 190 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 19 of 190: (19,8)
Progress: 20% – Elapsed: 0.0s
Encoding link 38 of 190: (1,16)
Progress: 30% – Elapsed: 0.0s
Encoding link 57 of 190: (7,21)
Progress: 40% – Elapsed: 0.0s
Encoding link 76 of 190: (21,27)
Progress: 50% – Elapsed: 0.0s
Encoding link 95 of 190: (30,31)
Progress: 60% – Elapsed: 0.0s
Encoding link 114 of 190: (3,10)
Progress: 70% – Elapsed: 0.0s
Encoding link 133 of 190: (7,10)
Progress: 80% – Elapsed: 0.0s
Encoding link 152 of 190: (24,10)
Progress: 90% – Elapsed: 0.1s
Encoding link 171 of 190: (11,10)
Progress: 100% – Elapsed: 0.1s
Encoding link 190 of 190: (32,20)
Done. Total time: 0.1s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 4 of 48: (6,9)
Progress: 17% – Elapsed: 0.0s
Encoding link 8 of 48: (26,16)
Progress: 25% – Elapsed: 0.0s
Encoding link 12 of 48: (12,18)
Progress: 33% – Elapsed: 0.0s
Encoding link 16 of 48: (6,21)
Progress: 42% – Elapsed: 0.0s
Encoding link 20 of 48: (5,31)
Progress: 50% – Elapsed: 0.0s
Encoding link 24 of 48: (27,31)
Progress: 58% – Elapsed: 0.0s
Encoding link 28 of 48: (24,6)
Progress: 67% – Elapsed: 0.0s
Encoding link 32 of 48: (6,15)
Progress: 75% – Elapsed: 0.0s
Encoding link 36 of 48: (19,3)
Progress: 83% – Elapsed: 0.0s
Encoding link 40 of 48: (20,19)
Progress: 92% – Elapsed: 0.0s
Encoding link 44 of 48: (10,11)
Progress: 100% – Elapsed: 0.0s
Encoding link 48 of 48: (3,32)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       71.88% |       0.6716 |          0.1000 |
|      50 |          50 |       00:00:00 |       99.22% |       0.0380 |          0.0656 |
|     100 |         100 |       00:00:00 |       99.22% |       0.0359 |          0.0387 |
|     150 |         150 |       00:00:00 |       99.22% |       0.0357 |          0.0229 |
|     200 |         200 |       00:00:00 |       99.22% |       0.0357 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.35, Precision: 1.0000, Recall: 0.9167, F1-Score: 0.9565
AUC: 0.9965
    "Experiment "    "9"    " (strategy: "    "random"    ") — Running WLNM..."

[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 119)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',119,0)">line 119</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 85)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',85,0)">line 85</a>)] 
[sample_neg] Final link counts:
    Train Positive: 95
    Train Negative: 95
    Test  Positive: 24
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 190 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 19 of 190: (19,8)
Progress: 20% – Elapsed: 0.0s
Encoding link 38 of 190: (1,16)
Progress: 30% – Elapsed: 0.0s
Encoding link 57 of 190: (7,21)
Progress: 40% – Elapsed: 0.0s
Encoding link 76 of 190: (21,27)
Progress: 50% – Elapsed: 0.0s
Encoding link 95 of 190: (30,31)
Progress: 60% – Elapsed: 0.0s
Encoding link 114 of 190: (15,6)
Progress: 70% – Elapsed: 0.0s
Encoding link 133 of 190: (32,17)
Progress: 80% – Elapsed: 0.0s
Encoding link 152 of 190: (6,11)
Progress: 90% – Elapsed: 0.0s
Encoding link 171 of 190: (3,25)
Progress: 100% – Elapsed: 0.1s
Encoding link 190 of 190: (10,20)
Done. Total time: 0.1s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 4 of 48: (6,9)
Progress: 17% – Elapsed: 0.0s
Encoding link 8 of 48: (26,16)
Progress: 25% – Elapsed: 0.0s
Encoding link 12 of 48: (12,18)
Progress: 33% – Elapsed: 0.0s
Encoding link 16 of 48: (6,21)
Progress: 42% – Elapsed: 0.0s
Encoding link 20 of 48: (5,31)
Progress: 50% – Elapsed: 0.0s
Encoding link 24 of 48: (27,31)
Progress: 58% – Elapsed: 0.0s
Encoding link 28 of 48: (32,6)
Progress: 67% – Elapsed: 0.0s
Encoding link 32 of 48: (17,15)
Progress: 75% – Elapsed: 0.0s
Encoding link 36 of 48: (3,24)
Progress: 83% – Elapsed: 0.0s
Encoding link 40 of 48: (25,3)
Progress: 92% – Elapsed: 0.0s
Encoding link 44 of 48: (7,28)
Progress: 100% – Elapsed: 0.0s
Encoding link 48 of 48: (3,20)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       45.31% |       0.6739 |          0.1000 |
|      50 |          50 |       00:00:00 |       99.22% |       0.0338 |          0.0656 |
|     100 |         100 |       00:00:00 |       99.22% |       0.0330 |          0.0387 |
|     150 |         150 |       00:00:00 |       99.22% |       0.0330 |          0.0229 |
|     200 |         200 |       00:00:00 |       99.22% |       0.0330 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.20, Precision: 0.9600, Recall: 1.0000, F1-Score: 0.9796
AUC: 0.9983
    "Experiment "    "10"    " (strategy: "    "random"    ") — Running WLNM..."

[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 119)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',119,0)">line 119</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 85)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',85,0)">line 85</a>)] 
[sample_neg] Final link counts:
    Train Positive: 95
    Train Negative: 95
    Test  Positive: 24
    Test  Negative: 24
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 190 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 19 of 190: (19,8)
Progress: 20% – Elapsed: 0.0s
Encoding link 38 of 190: (1,16)
Progress: 30% – Elapsed: 0.0s
Encoding link 57 of 190: (7,21)
Progress: 40% – Elapsed: 0.0s
Encoding link 76 of 190: (21,27)
Progress: 50% – Elapsed: 0.0s
Encoding link 95 of 190: (30,31)
Progress: 60% – Elapsed: 0.0s
Encoding link 114 of 190: (10,3)
Progress: 70% – Elapsed: 0.0s
Encoding link 133 of 190: (32,11)
Progress: 80% – Elapsed: 0.0s
Encoding link 152 of 190: (24,20)
Progress: 90% – Elapsed: 0.0s
Encoding link 171 of 190: (17,6)
Progress: 100% – Elapsed: 0.1s
Encoding link 190 of 190: (10,32)
Done. Total time: 0.1s
Encoding 48 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 4 of 48: (6,9)
Progress: 17% – Elapsed: 0.0s
Encoding link 8 of 48: (26,16)
Progress: 25% – Elapsed: 0.0s
Encoding link 12 of 48: (12,18)
Progress: 33% – Elapsed: 0.0s
Encoding link 16 of 48: (6,21)
Progress: 42% – Elapsed: 0.0s
Encoding link 20 of 48: (5,31)
Progress: 50% – Elapsed: 0.0s
Encoding link 24 of 48: (27,31)
Progress: 58% – Elapsed: 0.0s
Encoding link 28 of 48: (3,20)
Progress: 67% – Elapsed: 0.0s
Encoding link 32 of 48: (19,15)
Progress: 75% – Elapsed: 0.0s
Encoding link 36 of 48: (3,7)
Progress: 83% – Elapsed: 0.0s
Encoding link 40 of 48: (24,10)
Progress: 92% – Elapsed: 0.0s
Encoding link 44 of 48: (3,19)
Progress: 100% – Elapsed: 0.0s
Encoding link 48 of 48: (19,30)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       46.88% |       0.7011 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0013 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0004 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0003 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0003 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9565, Recall: 0.9167, F1-Score: 0.9362
AUC: 0.9635
