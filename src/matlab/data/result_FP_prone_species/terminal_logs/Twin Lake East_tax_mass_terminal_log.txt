Processing dataset: Twin Lake East_tax_mass
    "Processing with K …"    "10"    " using strategy: "    "random"

    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts:
    Train Positive: 12
    Train Negative: 24
    Test  Positive: 4
    Test  Negative: 8
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 36 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 3 of 36: (2,3)
Progress: 17% – Elapsed: 0.0s
Encoding link 6 of 36: (7,4)
Progress: 25% – Elapsed: 0.0s
Encoding link 9 of 36: (11,4)
Progress: 33% – Elapsed: 0.0s
Encoding link 12 of 36: (13,12)
Progress: 42% – Elapsed: 0.0s
Encoding link 15 of 36: (2,9)
Progress: 50% – Elapsed: 0.0s
Encoding link 18 of 36: (8,11)
Progress: 58% – Elapsed: 0.0s
Encoding link 21 of 36: (2,13)
Progress: 67% – Elapsed: 0.0s
Encoding link 24 of 36: (8,13)
Progress: 75% – Elapsed: 0.0s
Encoding link 27 of 36: (11,7)
Progress: 83% – Elapsed: 0.0s
Encoding link 30 of 36: (9,6)
Progress: 92% – Elapsed: 0.0s
Encoding link 33 of 36: (6,8)
Progress: 100% – Elapsed: 0.0s
Encoding link 36 of 36: (9,11)
Done. Total time: 0.0s
Encoding 12 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 1 of 12: (2,4)
Progress: 17% – Elapsed: 0.0s
Encoding link 2 of 12: (1,10)
Progress: 25% – Elapsed: 0.0s
Encoding link 3 of 12: (12,10)
Progress: 33% – Elapsed: 0.0s
Encoding link 4 of 12: (2,12)
Progress: 42% – Elapsed: 0.0s
Encoding link 5 of 12: (13,8)
Progress: 50% – Elapsed: 0.0s
Encoding link 6 of 12: (8,2)
Progress: 58% – Elapsed: 0.0s
Encoding link 7 of 12: (6,9)
Progress: 67% – Elapsed: 0.0s
Encoding link 8 of 12: (7,13)
Progress: 75% – Elapsed: 0.0s
Encoding link 9 of 12: (6,7)
Progress: 83% – Elapsed: 0.0s
Encoding link 10 of 12: (7,2)
Progress: 92% – Elapsed: 0.0s
Encoding link 11 of 12: (9,8)
Progress: 100% – Elapsed: 0.0s
Encoding link 12 of 12: (2,7)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       58.33% |       0.6839 |          0.1000 |
|      50 |          50 |       00:00:00 |       97.22% |       0.0534 |          0.0656 |
|     100 |         100 |       00:00:00 |       97.22% |       0.0531 |          0.0387 |
|     150 |         150 |       00:00:00 |       97.22% |       0.0531 |          0.0229 |
|     200 |         200 |       00:00:00 |       97.22% |       0.0531 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.35, Precision: 1.0000, Recall: 0.5000, F1-Score: 0.6667
AUC: 0.9375
    "Experiment "    "2"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts:
    Train Positive: 12
    Train Negative: 24
    Test  Positive: 4
    Test  Negative: 8
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 36 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 3 of 36: (2,3)
Progress: 17% – Elapsed: 0.0s
Encoding link 6 of 36: (7,4)
Progress: 25% – Elapsed: 0.0s
Encoding link 9 of 36: (11,4)
Progress: 33% – Elapsed: 0.0s
Encoding link 12 of 36: (13,12)
Progress: 42% – Elapsed: 0.0s
Encoding link 15 of 36: (11,7)
Progress: 50% – Elapsed: 0.0s
Encoding link 18 of 36: (3,4)
Progress: 58% – Elapsed: 0.0s
Encoding link 21 of 36: (6,2)
Progress: 67% – Elapsed: 0.0s
Encoding link 24 of 36: (11,6)
Progress: 75% – Elapsed: 0.0s
Encoding link 27 of 36: (2,8)
Progress: 83% – Elapsed: 0.0s
Encoding link 30 of 36: (13,9)
Progress: 92% – Elapsed: 0.0s
Encoding link 33 of 36: (8,7)
Progress: 100% – Elapsed: 0.0s
Encoding link 36 of 36: (11,13)
Done. Total time: 0.0s
Encoding 12 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 1 of 12: (2,4)
Progress: 17% – Elapsed: 0.0s
Encoding link 2 of 12: (1,10)
Progress: 25% – Elapsed: 0.0s
Encoding link 3 of 12: (12,10)
Progress: 33% – Elapsed: 0.0s
Encoding link 4 of 12: (2,12)
Progress: 42% – Elapsed: 0.0s
Encoding link 5 of 12: (13,6)
Progress: 50% – Elapsed: 0.0s
Encoding link 6 of 12: (9,7)
Progress: 58% – Elapsed: 0.0s
Encoding link 7 of 12: (13,7)
Progress: 67% – Elapsed: 0.0s
Encoding link 8 of 12: (7,6)
Progress: 75% – Elapsed: 0.0s
Encoding link 9 of 12: (13,8)
Progress: 83% – Elapsed: 0.0s
Encoding link 10 of 12: (9,11)
Progress: 92% – Elapsed: 0.0s
Encoding link 11 of 12: (9,2)
Progress: 100% – Elapsed: 0.0s
Encoding link 12 of 12: (13,11)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       66.67% |       0.6666 |          0.1000 |
|      50 |          50 |       00:00:00 |       97.22% |       0.0392 |          0.0656 |
|     100 |         100 |       00:00:00 |       97.22% |       0.0387 |          0.0387 |
|     150 |         150 |       00:00:00 |       97.22% |       0.0387 |          0.0229 |
|     200 |         200 |       00:00:00 |       97.22% |       0.0387 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.5000, F1-Score: 0.6667
AUC: 1.0000
    "Experiment "    "3"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts:
    Train Positive: 12
    Train Negative: 24
    Test  Positive: 4
    Test  Negative: 8
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 36 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 3 of 36: (2,3)
Progress: 17% – Elapsed: 0.0s
Encoding link 6 of 36: (7,4)
Progress: 25% – Elapsed: 0.0s
Encoding link 9 of 36: (11,4)
Progress: 33% – Elapsed: 0.0s
Encoding link 12 of 36: (13,12)
Progress: 42% – Elapsed: 0.0s
Encoding link 15 of 36: (13,2)
Progress: 50% – Elapsed: 0.0s
Encoding link 18 of 36: (8,11)
Progress: 58% – Elapsed: 0.0s
Encoding link 21 of 36: (2,9)
Progress: 67% – Elapsed: 0.0s
Encoding link 24 of 36: (7,2)
Progress: 75% – Elapsed: 0.0s
Encoding link 27 of 36: (8,9)
Progress: 83% – Elapsed: 0.0s
Encoding link 30 of 36: (7,13)
Progress: 92% – Elapsed: 0.0s
Encoding link 33 of 36: (9,2)
Progress: 100% – Elapsed: 0.0s
Encoding link 36 of 36: (13,7)
Done. Total time: 0.0s
Encoding 12 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 1 of 12: (2,4)
Progress: 17% – Elapsed: 0.0s
Encoding link 2 of 12: (1,10)
Progress: 25% – Elapsed: 0.0s
Encoding link 3 of 12: (12,10)
Progress: 33% – Elapsed: 0.0s
Encoding link 4 of 12: (2,12)
Progress: 42% – Elapsed: 0.0s
Encoding link 5 of 12: (2,13)
Progress: 50% – Elapsed: 0.0s
Encoding link 6 of 12: (13,9)
Progress: 58% – Elapsed: 0.0s
Encoding link 7 of 12: (4,3)
Progress: 67% – Elapsed: 0.0s
Encoding link 8 of 12: (2,6)
Progress: 75% – Elapsed: 0.0s
Encoding link 9 of 12: (7,6)
Progress: 83% – Elapsed: 0.0s
Encoding link 10 of 12: (11,6)
Progress: 92% – Elapsed: 0.0s
Encoding link 11 of 12: (9,6)
Progress: 100% – Elapsed: 0.0s
Encoding link 12 of 12: (11,7)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       33.33% |       0.7365 |          0.1000 |
|      50 |          50 |       00:00:00 |       97.22% |       0.0639 |          0.0656 |
|     100 |         100 |       00:00:00 |       97.22% |       0.0628 |          0.0387 |
|     150 |         150 |       00:00:00 |       97.22% |       0.0628 |          0.0229 |
|     200 |         200 |       00:00:00 |       97.22% |       0.0628 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.25, Precision: 1.0000, Recall: 0.5000, F1-Score: 0.6667
AUC: 0.9375
    "Experiment "    "4"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts:
    Train Positive: 12
    Train Negative: 24
    Test  Positive: 4
    Test  Negative: 8
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 36 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 3 of 36: (2,3)
Progress: 17% – Elapsed: 0.0s
Encoding link 6 of 36: (7,4)
Progress: 25% – Elapsed: 0.0s
Encoding link 9 of 36: (11,4)
Progress: 33% – Elapsed: 0.0s
Encoding link 12 of 36: (13,12)
Progress: 42% – Elapsed: 0.0s
Encoding link 15 of 36: (11,13)
Progress: 50% – Elapsed: 0.0s
Encoding link 18 of 36: (13,2)
Progress: 58% – Elapsed: 0.0s
Encoding link 21 of 36: (8,2)
Progress: 67% – Elapsed: 0.0s
Encoding link 24 of 36: (5,4)
Progress: 75% – Elapsed: 0.0s
Encoding link 27 of 36: (8,11)
Progress: 83% – Elapsed: 0.0s
Encoding link 30 of 36: (8,9)
Progress: 92% – Elapsed: 0.0s
Encoding link 33 of 36: (8,6)
Progress: 100% – Elapsed: 0.0s
Encoding link 36 of 36: (3,4)
Done. Total time: 0.0s
Encoding 12 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 1 of 12: (2,4)
Progress: 17% – Elapsed: 0.0s
Encoding link 2 of 12: (1,10)
Progress: 25% – Elapsed: 0.0s
Encoding link 3 of 12: (12,10)
Progress: 33% – Elapsed: 0.0s
Encoding link 4 of 12: (2,12)
Progress: 42% – Elapsed: 0.0s
Encoding link 5 of 12: (4,5)
Progress: 50% – Elapsed: 0.0s
Encoding link 6 of 12: (7,9)
Progress: 58% – Elapsed: 0.0s
Encoding link 7 of 12: (13,8)
Progress: 67% – Elapsed: 0.0s
Encoding link 8 of 12: (11,7)
Progress: 75% – Elapsed: 0.0s
Encoding link 9 of 12: (2,11)
Progress: 83% – Elapsed: 0.0s
Encoding link 10 of 12: (6,11)
Progress: 92% – Elapsed: 0.0s
Encoding link 11 of 12: (6,13)
Progress: 100% – Elapsed: 0.0s
Encoding link 12 of 12: (13,7)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       25.00% |       0.6976 |          0.1000 |
|      50 |          50 |       00:00:00 |       97.22% |       0.0539 |          0.0656 |
|     100 |         100 |       00:00:00 |       97.22% |       0.0532 |          0.0387 |
|     150 |         150 |       00:00:00 |       97.22% |       0.0532 |          0.0229 |
|     200 |         200 |       00:00:00 |       97.22% |       0.0532 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.35, Precision: 1.0000, Recall: 0.5000, F1-Score: 0.6667
AUC: 0.9375
    "Experiment "    "5"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts:
    Train Positive: 12
    Train Negative: 24
    Test  Positive: 4
    Test  Negative: 8
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 36 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 3 of 36: (2,3)
Progress: 17% – Elapsed: 0.0s
Encoding link 6 of 36: (7,4)
Progress: 25% – Elapsed: 0.0s
Encoding link 9 of 36: (11,4)
Progress: 33% – Elapsed: 0.0s
Encoding link 12 of 36: (13,12)
Progress: 42% – Elapsed: 0.0s
Encoding link 15 of 36: (13,8)
Progress: 50% – Elapsed: 0.0s
Encoding link 18 of 36: (11,2)
Progress: 58% – Elapsed: 0.0s
Encoding link 21 of 36: (3,5)
Progress: 67% – Elapsed: 0.0s
Encoding link 24 of 36: (5,4)
Progress: 75% – Elapsed: 0.0s
Encoding link 27 of 36: (11,6)
Progress: 83% – Elapsed: 0.0s
Encoding link 30 of 36: (6,7)
Progress: 92% – Elapsed: 0.0s
Encoding link 33 of 36: (11,7)
Progress: 100% – Elapsed: 0.0s
Encoding link 36 of 36: (7,2)
Done. Total time: 0.0s
Encoding 12 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 1 of 12: (2,4)
Progress: 17% – Elapsed: 0.0s
Encoding link 2 of 12: (1,10)
Progress: 25% – Elapsed: 0.0s
Encoding link 3 of 12: (12,10)
Progress: 33% – Elapsed: 0.0s
Encoding link 4 of 12: (2,12)
Progress: 42% – Elapsed: 0.0s
Encoding link 5 of 12: (2,9)
Progress: 50% – Elapsed: 0.0s
Encoding link 6 of 12: (6,13)
Progress: 58% – Elapsed: 0.0s
Encoding link 7 of 12: (8,9)
Progress: 67% – Elapsed: 0.0s
Encoding link 8 of 12: (13,11)
Progress: 75% – Elapsed: 0.0s
Encoding link 9 of 12: (6,8)
Progress: 83% – Elapsed: 0.0s
Encoding link 10 of 12: (7,8)
Progress: 92% – Elapsed: 0.0s
Encoding link 11 of 12: (9,13)
Progress: 100% – Elapsed: 0.0s
Encoding link 12 of 12: (3,4)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       66.67% |       0.6661 |          0.1000 |
|      50 |          50 |       00:00:00 |       97.22% |       0.0629 |          0.0656 |
|     100 |         100 |       00:00:00 |       97.22% |       0.0626 |          0.0387 |
|     150 |         150 |       00:00:00 |       97.22% |       0.0626 |          0.0229 |
|     200 |         200 |       00:00:00 |       97.22% |       0.0626 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.30, Precision: 1.0000, Recall: 0.5000, F1-Score: 0.6667
AUC: 0.9375
    "Experiment "    "6"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts:
    Train Positive: 12
    Train Negative: 24
    Test  Positive: 4
    Test  Negative: 8
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 36 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 3 of 36: (2,3)
Progress: 17% – Elapsed: 0.0s
Encoding link 6 of 36: (7,4)
Progress: 25% – Elapsed: 0.0s
Encoding link 9 of 36: (11,4)
Progress: 33% – Elapsed: 0.0s
Encoding link 12 of 36: (13,12)
Progress: 42% – Elapsed: 0.0s
Encoding link 15 of 36: (7,2)
Progress: 50% – Elapsed: 0.0s
Encoding link 18 of 36: (13,7)
Progress: 58% – Elapsed: 0.0s
Encoding link 21 of 36: (13,11)
Progress: 67% – Elapsed: 0.0s
Encoding link 24 of 36: (6,13)
Progress: 75% – Elapsed: 0.0s
Encoding link 27 of 36: (6,8)
Progress: 83% – Elapsed: 0.0s
Encoding link 30 of 36: (9,11)
Progress: 92% – Elapsed: 0.0s
Encoding link 33 of 36: (7,13)
Progress: 100% – Elapsed: 0.0s
Encoding link 36 of 36: (9,2)
Done. Total time: 0.0s
Encoding 12 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 1 of 12: (2,4)
Progress: 17% – Elapsed: 0.0s
Encoding link 2 of 12: (1,10)
Progress: 25% – Elapsed: 0.0s
Encoding link 3 of 12: (12,10)
Progress: 33% – Elapsed: 0.0s
Encoding link 4 of 12: (2,12)
Progress: 42% – Elapsed: 0.0s
Encoding link 5 of 12: (13,2)
Progress: 50% – Elapsed: 0.0s
Encoding link 6 of 12: (3,5)
Progress: 58% – Elapsed: 0.0s
Encoding link 7 of 12: (2,13)
Progress: 67% – Elapsed: 0.0s
Encoding link 8 of 12: (11,8)
Progress: 75% – Elapsed: 0.0s
Encoding link 9 of 12: (2,11)
Progress: 83% – Elapsed: 0.0s
Encoding link 10 of 12: (11,7)
Progress: 92% – Elapsed: 0.0s
Encoding link 11 of 12: (13,9)
Progress: 100% – Elapsed: 0.0s
Encoding link 12 of 12: (13,8)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       41.67% |       0.6948 |          0.1000 |
|      50 |          50 |       00:00:00 |       97.22% |       0.0541 |          0.0656 |
|     100 |         100 |       00:00:00 |       97.22% |       0.0532 |          0.0387 |
|     150 |         150 |       00:00:00 |       97.22% |       0.0532 |          0.0229 |
|     200 |         200 |       00:00:00 |       97.22% |       0.0532 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.35, Precision: 0.5000, Recall: 0.5000, F1-Score: 0.5000
AUC: 0.7500
    "Experiment "    "7"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts:
    Train Positive: 12
    Train Negative: 24
    Test  Positive: 4
    Test  Negative: 8
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 36 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 3 of 36: (2,3)
Progress: 17% – Elapsed: 0.0s
Encoding link 6 of 36: (7,4)
Progress: 25% – Elapsed: 0.0s
Encoding link 9 of 36: (11,4)
Progress: 33% – Elapsed: 0.0s
Encoding link 12 of 36: (13,12)
Progress: 42% – Elapsed: 0.0s
Encoding link 15 of 36: (6,13)
Progress: 50% – Elapsed: 0.0s
Encoding link 18 of 36: (13,11)
Progress: 58% – Elapsed: 0.0s
Encoding link 21 of 36: (8,11)
Progress: 67% – Elapsed: 0.0s
Encoding link 24 of 36: (11,7)
Progress: 75% – Elapsed: 0.0s
Encoding link 27 of 36: (8,13)
Progress: 83% – Elapsed: 0.0s
Encoding link 30 of 36: (6,9)
Progress: 92% – Elapsed: 0.0s
Encoding link 33 of 36: (13,6)
Progress: 100% – Elapsed: 0.0s
Encoding link 36 of 36: (7,6)
Done. Total time: 0.0s
Encoding 12 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 1 of 12: (2,4)
Progress: 17% – Elapsed: 0.0s
Encoding link 2 of 12: (1,10)
Progress: 25% – Elapsed: 0.0s
Encoding link 3 of 12: (12,10)
Progress: 33% – Elapsed: 0.0s
Encoding link 4 of 12: (2,12)
Progress: 42% – Elapsed: 0.0s
Encoding link 5 of 12: (8,7)
Progress: 50% – Elapsed: 0.0s
Encoding link 6 of 12: (11,9)
Progress: 58% – Elapsed: 0.0s
Encoding link 7 of 12: (5,3)
Progress: 67% – Elapsed: 0.0s
Encoding link 8 of 12: (2,13)
Progress: 75% – Elapsed: 0.0s
Encoding link 9 of 12: (7,8)
Progress: 83% – Elapsed: 0.0s
Encoding link 10 of 12: (11,8)
Progress: 92% – Elapsed: 0.0s
Encoding link 11 of 12: (9,7)
Progress: 100% – Elapsed: 0.0s
Encoding link 12 of 12: (8,9)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       75.00% |       0.6851 |          0.1000 |
|      50 |          50 |       00:00:00 |       97.22% |       0.0701 |          0.0656 |
|     100 |         100 |       00:00:00 |       97.22% |       0.0696 |          0.0387 |
|     150 |         150 |       00:00:00 |       97.22% |       0.0696 |          0.0229 |
|     200 |         200 |       00:00:00 |       97.22% |       0.0696 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.55, Precision: 0.6667, Recall: 0.5000, F1-Score: 0.5714
AUC: 0.8438
    "Experiment "    "8"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts:
    Train Positive: 12
    Train Negative: 24
    Test  Positive: 4
    Test  Negative: 8
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 36 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 3 of 36: (2,3)
Progress: 17% – Elapsed: 0.0s
Encoding link 6 of 36: (7,4)
Progress: 25% – Elapsed: 0.0s
Encoding link 9 of 36: (11,4)
Progress: 33% – Elapsed: 0.0s
Encoding link 12 of 36: (13,12)
Progress: 42% – Elapsed: 0.0s
Encoding link 15 of 36: (8,13)
Progress: 50% – Elapsed: 0.0s
Encoding link 18 of 36: (11,7)
Progress: 58% – Elapsed: 0.0s
Encoding link 21 of 36: (2,6)
Progress: 67% – Elapsed: 0.0s
Encoding link 24 of 36: (6,7)
Progress: 75% – Elapsed: 0.0s
Encoding link 27 of 36: (7,8)
Progress: 83% – Elapsed: 0.0s
Encoding link 30 of 36: (6,11)
Progress: 92% – Elapsed: 0.0s
Encoding link 33 of 36: (11,2)
Progress: 100% – Elapsed: 0.0s
Encoding link 36 of 36: (2,13)
Done. Total time: 0.0s
Encoding 12 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 1 of 12: (2,4)
Progress: 17% – Elapsed: 0.0s
Encoding link 2 of 12: (1,10)
Progress: 25% – Elapsed: 0.0s
Encoding link 3 of 12: (12,10)
Progress: 33% – Elapsed: 0.0s
Encoding link 4 of 12: (2,12)
Progress: 42% – Elapsed: 0.0s
Encoding link 5 of 12: (6,2)
Progress: 50% – Elapsed: 0.0s
Encoding link 6 of 12: (7,2)
Progress: 58% – Elapsed: 0.0s
Encoding link 7 of 12: (9,8)
Progress: 67% – Elapsed: 0.0s
Encoding link 8 of 12: (7,6)
Progress: 75% – Elapsed: 0.0s
Encoding link 9 of 12: (5,4)
Progress: 83% – Elapsed: 0.0s
Encoding link 10 of 12: (8,7)
Progress: 92% – Elapsed: 0.0s
Encoding link 11 of 12: (3,5)
Progress: 100% – Elapsed: 0.0s
Encoding link 12 of 12: (11,8)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       66.67% |       0.6460 |          0.1000 |
|      50 |          50 |       00:00:00 |       97.22% |       0.0697 |          0.0656 |
|     100 |         100 |       00:00:00 |       97.22% |       0.0695 |          0.0387 |
|     150 |         150 |       00:00:00 |       97.22% |       0.0695 |          0.0229 |
|     200 |         200 |       00:00:00 |       97.22% |       0.0695 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.8000, Recall: 1.0000, F1-Score: 0.8889
AUC: 0.9062
    "Experiment "    "9"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts:
    Train Positive: 12
    Train Negative: 24
    Test  Positive: 4
    Test  Negative: 8
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 36 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 3 of 36: (2,3)
Progress: 17% – Elapsed: 0.0s
Encoding link 6 of 36: (7,4)
Progress: 25% – Elapsed: 0.0s
Encoding link 9 of 36: (11,4)
Progress: 33% – Elapsed: 0.0s
Encoding link 12 of 36: (13,12)
Progress: 42% – Elapsed: 0.0s
Encoding link 15 of 36: (2,9)
Progress: 50% – Elapsed: 0.0s
Encoding link 18 of 36: (11,9)
Progress: 58% – Elapsed: 0.0s
Encoding link 21 of 36: (11,8)
Progress: 67% – Elapsed: 0.0s
Encoding link 24 of 36: (11,7)
Progress: 75% – Elapsed: 0.0s
Encoding link 27 of 36: (8,2)
Progress: 83% – Elapsed: 0.0s
Encoding link 30 of 36: (13,11)
Progress: 92% – Elapsed: 0.0s
Encoding link 33 of 36: (13,2)
Progress: 100% – Elapsed: 0.0s
Encoding link 36 of 36: (8,13)
Done. Total time: 0.0s
Encoding 12 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 1 of 12: (2,4)
Progress: 17% – Elapsed: 0.0s
Encoding link 2 of 12: (1,10)
Progress: 25% – Elapsed: 0.0s
Encoding link 3 of 12: (12,10)
Progress: 33% – Elapsed: 0.0s
Encoding link 4 of 12: (2,12)
Progress: 42% – Elapsed: 0.0s
Encoding link 5 of 12: (5,3)
Progress: 50% – Elapsed: 0.0s
Encoding link 6 of 12: (13,6)
Progress: 58% – Elapsed: 0.0s
Encoding link 7 of 12: (8,7)
Progress: 67% – Elapsed: 0.0s
Encoding link 8 of 12: (2,13)
Progress: 75% – Elapsed: 0.0s
Encoding link 9 of 12: (9,7)
Progress: 83% – Elapsed: 0.0s
Encoding link 10 of 12: (7,13)
Progress: 92% – Elapsed: 0.0s
Encoding link 11 of 12: (6,13)
Progress: 100% – Elapsed: 0.0s
Encoding link 12 of 12: (3,5)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       63.89% |       0.6786 |          0.1000 |
|      50 |          50 |       00:00:00 |       97.22% |       0.0540 |          0.0656 |
|     100 |         100 |       00:00:00 |       97.22% |       0.0532 |          0.0387 |
|     150 |         150 |       00:00:00 |       97.22% |       0.0532 |          0.0229 |
|     200 |         200 |       00:00:00 |       97.22% |       0.0532 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.60, Precision: 1.0000, Recall: 0.5000, F1-Score: 0.6667
AUC: 0.8750
    "Experiment "    "10"    " (strategy: "    "random"    ") — Running WLNM..."

[sample_neg] Final link counts:
    Train Positive: 12
    Train Negative: 24
    Test  Positive: 4
    Test  Negative: 8
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 36 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 3 of 36: (2,3)
Progress: 17% – Elapsed: 0.0s
Encoding link 6 of 36: (7,4)
Progress: 25% – Elapsed: 0.0s
Encoding link 9 of 36: (11,4)
Progress: 33% – Elapsed: 0.0s
Encoding link 12 of 36: (13,12)
Progress: 42% – Elapsed: 0.0s
Encoding link 15 of 36: (13,9)
Progress: 50% – Elapsed: 0.0s
Encoding link 18 of 36: (13,7)
Progress: 58% – Elapsed: 0.0s
Encoding link 21 of 36: (6,8)
Progress: 67% – Elapsed: 0.0s
Encoding link 24 of 36: (8,7)
Progress: 75% – Elapsed: 0.0s
Encoding link 27 of 36: (9,13)
Progress: 83% – Elapsed: 0.0s
Encoding link 30 of 36: (11,9)
Progress: 92% – Elapsed: 0.0s
Encoding link 33 of 36: (13,2)
Progress: 100% – Elapsed: 0.0s
Encoding link 36 of 36: (2,11)
Done. Total time: 0.0s
Encoding 12 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 1 of 12: (2,4)
Progress: 17% – Elapsed: 0.0s
Encoding link 2 of 12: (1,10)
Progress: 25% – Elapsed: 0.0s
Encoding link 3 of 12: (12,10)
Progress: 33% – Elapsed: 0.0s
Encoding link 4 of 12: (2,12)
Progress: 42% – Elapsed: 0.0s
Encoding link 5 of 12: (7,2)
Progress: 50% – Elapsed: 0.0s
Encoding link 6 of 12: (8,2)
Progress: 58% – Elapsed: 0.0s
Encoding link 7 of 12: (8,13)
Progress: 67% – Elapsed: 0.0s
Encoding link 8 of 12: (4,5)
Progress: 75% – Elapsed: 0.0s
Encoding link 9 of 12: (6,13)
Progress: 83% – Elapsed: 0.0s
Encoding link 10 of 12: (6,9)
Progress: 92% – Elapsed: 0.0s
Encoding link 11 of 12: (6,11)
Progress: 100% – Elapsed: 0.0s
Encoding link 12 of 12: (3,4)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       30.56% |       0.7015 |          0.1000 |
|      50 |          50 |       00:00:00 |       97.22% |       0.0696 |          0.0656 |
|     100 |         100 |       00:00:00 |       97.22% |       0.0695 |          0.0387 |
|     150 |         150 |       00:00:00 |       97.22% |       0.0695 |          0.0229 |
|     200 |         200 |       00:00:00 |       97.22% |       0.0695 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.6667, Recall: 0.5000, F1-Score: 0.5714
AUC: 0.9062
