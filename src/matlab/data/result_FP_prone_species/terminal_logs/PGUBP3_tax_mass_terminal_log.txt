Processing dataset: PGUBP3_tax_mass
    "Processing with K …"    "10"    " using strategy: "    "random"

    "Experiment "    "1"    " (strategy: "    "random"    ") — Running WLNM..."

[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 119)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',119,0)">line 119</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 85)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',85,0)">line 85</a>)] 
[sample_neg] Final link counts:
    Train Positive: 52
    Train Negative: 52
    Test  Positive: 13
    Test  Negative: 13
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 104 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 10 of 104: (20,4)
Progress: 19% – Elapsed: 0.0s
Encoding link 20 of 104: (2,9)
Progress: 29% – Elapsed: 0.0s
Encoding link 30 of 104: (15,10)
Progress: 38% – Elapsed: 0.0s
Encoding link 40 of 104: (1,17)
Progress: 48% – Elapsed: 0.0s
Encoding link 50 of 104: (15,19)
Progress: 58% – Elapsed: 0.0s
Encoding link 60 of 104: (20,13)
Progress: 67% – Elapsed: 0.0s
Encoding link 70 of 104: (13,6)
Progress: 77% – Elapsed: 0.0s
Encoding link 80 of 104: (2,11)
Progress: 87% – Elapsed: 0.0s
Encoding link 90 of 104: (20,7)
Progress: 96% – Elapsed: 0.0s
Encoding link 100 of 104: (1,2)
Done. Total time: 0.0s
Encoding 26 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 2 of 26: (11,4)
Progress: 15% – Elapsed: 0.0s
Encoding link 4 of 26: (15,9)
Progress: 23% – Elapsed: 0.0s
Encoding link 6 of 26: (6,16)
Progress: 31% – Elapsed: 0.0s
Encoding link 8 of 26: (20,16)
Progress: 38% – Elapsed: 0.0s
Encoding link 10 of 26: (15,17)
Progress: 46% – Elapsed: 0.0s
Encoding link 12 of 26: (6,19)
Progress: 54% – Elapsed: 0.0s
Encoding link 14 of 26: (1,13)
Progress: 62% – Elapsed: 0.0s
Encoding link 16 of 26: (4,8)
Progress: 69% – Elapsed: 0.0s
Encoding link 18 of 26: (7,1)
Progress: 77% – Elapsed: 0.0s
Encoding link 20 of 26: (11,7)
Progress: 85% – Elapsed: 0.0s
Encoding link 22 of 26: (11,15)
Progress: 92% – Elapsed: 0.0s
Encoding link 24 of 26: (13,1)
Progress: 100% – Elapsed: 0.0s
Encoding link 26 of 26: (11,13)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       53.85% |       0.6926 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0023 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0005 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0004 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0004 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9286, Recall: 1.0000, F1-Score: 0.9630
AUC: 0.9882
    "Experiment "    "2"    " (strategy: "    "random"    ") — Running WLNM..."

[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 119)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',119,0)">line 119</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 85)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',85,0)">line 85</a>)] 
[sample_neg] Final link counts:
    Train Positive: 52
    Train Negative: 52
    Test  Positive: 13
    Test  Negative: 13
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 104 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 10 of 104: (20,4)
Progress: 19% – Elapsed: 0.0s
Encoding link 20 of 104: (2,9)
Progress: 29% – Elapsed: 0.0s
Encoding link 30 of 104: (15,10)
Progress: 38% – Elapsed: 0.0s
Encoding link 40 of 104: (1,17)
Progress: 48% – Elapsed: 0.0s
Encoding link 50 of 104: (15,19)
Progress: 58% – Elapsed: 0.0s
Encoding link 60 of 104: (15,6)
Progress: 67% – Elapsed: 0.0s
Encoding link 70 of 104: (2,11)
Progress: 77% – Elapsed: 0.0s
Encoding link 80 of 104: (1,13)
Progress: 87% – Elapsed: 0.0s
Encoding link 90 of 104: (4,9)
Progress: 96% – Elapsed: 0.0s
Encoding link 100 of 104: (9,17)
Done. Total time: 0.0s
Encoding 26 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 2 of 26: (11,4)
Progress: 15% – Elapsed: 0.0s
Encoding link 4 of 26: (15,9)
Progress: 23% – Elapsed: 0.0s
Encoding link 6 of 26: (6,16)
Progress: 31% – Elapsed: 0.0s
Encoding link 8 of 26: (20,16)
Progress: 38% – Elapsed: 0.0s
Encoding link 10 of 26: (15,17)
Progress: 46% – Elapsed: 0.0s
Encoding link 12 of 26: (6,19)
Progress: 54% – Elapsed: 0.0s
Encoding link 14 of 26: (20,11)
Progress: 62% – Elapsed: 0.0s
Encoding link 16 of 26: (6,15)
Progress: 69% – Elapsed: 0.0s
Encoding link 18 of 26: (19,17)
Progress: 77% – Elapsed: 0.0s
Encoding link 20 of 26: (20,2)
Progress: 85% – Elapsed: 0.0s
Encoding link 22 of 26: (11,2)
Progress: 92% – Elapsed: 0.0s
Encoding link 24 of 26: (1,15)
Progress: 100% – Elapsed: 0.0s
Encoding link 26 of 26: (13,1)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       50.00% |       0.6893 |          0.1000 |
|      50 |          50 |       00:00:00 |       89.42% |       0.1674 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0225 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0052 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0033 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000
AUC: 1.0000
    "Experiment "    "3"    " (strategy: "    "random"    ") — Running WLNM..."

[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 119)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',119,0)">line 119</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 85)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',85,0)">line 85</a>)] 
[sample_neg] Final link counts:
    Train Positive: 52
    Train Negative: 52
    Test  Positive: 13
    Test  Negative: 13
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 104 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 10 of 104: (20,4)
Progress: 19% – Elapsed: 0.0s
Encoding link 20 of 104: (2,9)
Progress: 29% – Elapsed: 0.0s
Encoding link 30 of 104: (15,10)
Progress: 38% – Elapsed: 0.0s
Encoding link 40 of 104: (1,17)
Progress: 48% – Elapsed: 0.0s
Encoding link 50 of 104: (15,19)
Progress: 58% – Elapsed: 0.0s
Encoding link 60 of 104: (2,20)
Progress: 67% – Elapsed: 0.0s
Encoding link 70 of 104: (2,1)
Progress: 77% – Elapsed: 0.0s
Encoding link 80 of 104: (11,13)
Progress: 87% – Elapsed: 0.0s
Encoding link 90 of 104: (9,4)
Progress: 96% – Elapsed: 0.0s
Encoding link 100 of 104: (13,7)
Done. Total time: 0.0s
Encoding 26 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 2 of 26: (11,4)
Progress: 15% – Elapsed: 0.0s
Encoding link 4 of 26: (15,9)
Progress: 23% – Elapsed: 0.0s
Encoding link 6 of 26: (6,16)
Progress: 31% – Elapsed: 0.0s
Encoding link 8 of 26: (20,16)
Progress: 38% – Elapsed: 0.0s
Encoding link 10 of 26: (15,17)
Progress: 46% – Elapsed: 0.0s
Encoding link 12 of 26: (6,19)
Progress: 54% – Elapsed: 0.0s
Encoding link 14 of 26: (7,11)
Progress: 62% – Elapsed: 0.0s
Encoding link 16 of 26: (1,20)
Progress: 69% – Elapsed: 0.0s
Encoding link 18 of 26: (4,17)
Progress: 77% – Elapsed: 0.0s
Encoding link 20 of 26: (1,11)
Progress: 85% – Elapsed: 0.0s
Encoding link 22 of 26: (13,20)
Progress: 92% – Elapsed: 0.0s
Encoding link 24 of 26: (7,13)
Progress: 100% – Elapsed: 0.0s
Encoding link 26 of 26: (19,9)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       49.04% |       0.7674 |          0.1000 |
|      50 |          50 |       00:00:00 |       96.15% |       0.0670 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0093 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0034 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0025 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9091, Recall: 0.7692, F1-Score: 0.8333
AUC: 0.8698
    "Experiment "    "4"    " (strategy: "    "random"    ") — Running WLNM..."

[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 119)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',119,0)">line 119</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 85)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',85,0)">line 85</a>)] 
[sample_neg] Final link counts:
    Train Positive: 52
    Train Negative: 52
    Test  Positive: 13
    Test  Negative: 13
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 104 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 10 of 104: (20,4)
Progress: 19% – Elapsed: 0.0s
Encoding link 20 of 104: (2,9)
Progress: 29% – Elapsed: 0.0s
Encoding link 30 of 104: (15,10)
Progress: 38% – Elapsed: 0.0s
Encoding link 40 of 104: (1,17)
Progress: 48% – Elapsed: 0.0s
Encoding link 50 of 104: (15,19)
Progress: 58% – Elapsed: 0.0s
Encoding link 60 of 104: (2,20)
Progress: 67% – Elapsed: 0.0s
Encoding link 70 of 104: (17,4)
Progress: 77% – Elapsed: 0.0s
Encoding link 80 of 104: (2,11)
Progress: 87% – Elapsed: 0.0s
Encoding link 90 of 104: (13,2)
Progress: 96% – Elapsed: 0.0s
Encoding link 100 of 104: (19,4)
Done. Total time: 0.0s
Encoding 26 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 2 of 26: (11,4)
Progress: 15% – Elapsed: 0.0s
Encoding link 4 of 26: (15,9)
Progress: 23% – Elapsed: 0.0s
Encoding link 6 of 26: (6,16)
Progress: 31% – Elapsed: 0.0s
Encoding link 8 of 26: (20,16)
Progress: 38% – Elapsed: 0.0s
Encoding link 10 of 26: (15,17)
Progress: 46% – Elapsed: 0.0s
Encoding link 12 of 26: (6,19)
Progress: 54% – Elapsed: 0.0s
Encoding link 14 of 26: (8,4)
Progress: 62% – Elapsed: 0.0s
Encoding link 16 of 26: (7,15)
Progress: 69% – Elapsed: 0.0s
Encoding link 18 of 26: (20,7)
Progress: 77% – Elapsed: 0.0s
Encoding link 20 of 26: (20,6)
Progress: 85% – Elapsed: 0.0s
Encoding link 22 of 26: (2,13)
Progress: 92% – Elapsed: 0.0s
Encoding link 24 of 26: (20,15)
Progress: 100% – Elapsed: 0.0s
Encoding link 26 of 26: (6,1)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       46.15% |       0.7057 |          0.1000 |
|      50 |          50 |       00:00:00 |       99.04% |       0.0465 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0027 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0014 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0011 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.9231, F1-Score: 0.9600
AUC: 1.0000
    "Experiment "    "5"    " (strategy: "    "random"    ") — Running WLNM..."

[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 119)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',119,0)">line 119</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 85)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',85,0)">line 85</a>)] 
[sample_neg] Final link counts:
    Train Positive: 52
    Train Negative: 52
    Test  Positive: 13
    Test  Negative: 13
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 104 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 10 of 104: (20,4)
Progress: 19% – Elapsed: 0.0s
Encoding link 20 of 104: (2,9)
Progress: 29% – Elapsed: 0.0s
Encoding link 30 of 104: (15,10)
Progress: 38% – Elapsed: 0.0s
Encoding link 40 of 104: (1,17)
Progress: 48% – Elapsed: 0.0s
Encoding link 50 of 104: (15,19)
Progress: 58% – Elapsed: 0.0s
Encoding link 60 of 104: (13,1)
Progress: 67% – Elapsed: 0.0s
Encoding link 70 of 104: (7,6)
Progress: 77% – Elapsed: 0.0s
Encoding link 80 of 104: (15,1)
Progress: 87% – Elapsed: 0.0s
Encoding link 90 of 104: (4,8)
Progress: 96% – Elapsed: 0.0s
Encoding link 100 of 104: (7,15)
Done. Total time: 0.0s
Encoding 26 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 2 of 26: (11,4)
Progress: 15% – Elapsed: 0.0s
Encoding link 4 of 26: (15,9)
Progress: 23% – Elapsed: 0.0s
Encoding link 6 of 26: (6,16)
Progress: 31% – Elapsed: 0.0s
Encoding link 8 of 26: (20,16)
Progress: 38% – Elapsed: 0.0s
Encoding link 10 of 26: (15,17)
Progress: 46% – Elapsed: 0.0s
Encoding link 12 of 26: (6,19)
Progress: 54% – Elapsed: 0.0s
Encoding link 14 of 26: (20,13)
Progress: 62% – Elapsed: 0.0s
Encoding link 16 of 26: (1,2)
Progress: 69% – Elapsed: 0.0s
Encoding link 18 of 26: (6,1)
Progress: 77% – Elapsed: 0.0s
Encoding link 20 of 26: (11,15)
Progress: 85% – Elapsed: 0.0s
Encoding link 22 of 26: (13,20)
Progress: 92% – Elapsed: 0.0s
Encoding link 24 of 26: (19,8)
Progress: 100% – Elapsed: 0.0s
Encoding link 26 of 26: (1,15)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       50.00% |       0.7241 |          0.1000 |
|      50 |          50 |       00:00:00 |       98.08% |       0.0407 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0033 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0018 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0014 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 0.9231, F1-Score: 0.9600
AUC: 0.9822
    "Experiment "    "6"    " (strategy: "    "random"    ") — Running WLNM..."

[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 119)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',119,0)">line 119</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 85)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',85,0)">line 85</a>)] 
[sample_neg] Final link counts:
    Train Positive: 52
    Train Negative: 52
    Test  Positive: 13
    Test  Negative: 13
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 104 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 10 of 104: (20,4)
Progress: 19% – Elapsed: 0.0s
Encoding link 20 of 104: (2,9)
Progress: 29% – Elapsed: 0.0s
Encoding link 30 of 104: (15,10)
Progress: 38% – Elapsed: 0.0s
Encoding link 40 of 104: (1,17)
Progress: 48% – Elapsed: 0.0s
Encoding link 50 of 104: (15,19)
Progress: 58% – Elapsed: 0.0s
Encoding link 60 of 104: (15,20)
Progress: 67% – Elapsed: 0.0s
Encoding link 70 of 104: (4,8)
Progress: 77% – Elapsed: 0.0s
Encoding link 80 of 104: (13,7)
Progress: 87% – Elapsed: 0.0s
Encoding link 90 of 104: (6,2)
Progress: 96% – Elapsed: 0.1s
Encoding link 100 of 104: (4,17)
Done. Total time: 0.1s
Encoding 26 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 2 of 26: (11,4)
Progress: 15% – Elapsed: 0.0s
Encoding link 4 of 26: (15,9)
Progress: 23% – Elapsed: 0.0s
Encoding link 6 of 26: (6,16)
Progress: 31% – Elapsed: 0.0s
Encoding link 8 of 26: (20,16)
Progress: 38% – Elapsed: 0.0s
Encoding link 10 of 26: (15,17)
Progress: 46% – Elapsed: 0.0s
Encoding link 12 of 26: (6,19)
Progress: 54% – Elapsed: 0.0s
Encoding link 14 of 26: (2,20)
Progress: 62% – Elapsed: 0.0s
Encoding link 16 of 26: (7,15)
Progress: 69% – Elapsed: 0.0s
Encoding link 18 of 26: (1,20)
Progress: 77% – Elapsed: 0.0s
Encoding link 20 of 26: (7,1)
Progress: 85% – Elapsed: 0.0s
Encoding link 22 of 26: (13,6)
Progress: 92% – Elapsed: 0.0s
Encoding link 24 of 26: (17,9)
Progress: 100% – Elapsed: 0.0s
Encoding link 26 of 26: (7,13)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       54.81% |       0.7093 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0132 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0013 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0009 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0007 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000
AUC: 1.0000
    "Experiment "    "7"    " (strategy: "    "random"    ") — Running WLNM..."

[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 119)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',119,0)">line 119</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 85)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',85,0)">line 85</a>)] 
[sample_neg] Final link counts:
    Train Positive: 52
    Train Negative: 52
    Test  Positive: 13
    Test  Negative: 13
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 104 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 10 of 104: (20,4)
Progress: 19% – Elapsed: 0.0s
Encoding link 20 of 104: (2,9)
Progress: 29% – Elapsed: 0.0s
Encoding link 30 of 104: (15,10)
Progress: 38% – Elapsed: 0.0s
Encoding link 40 of 104: (1,17)
Progress: 48% – Elapsed: 0.0s
Encoding link 50 of 104: (15,19)
Progress: 58% – Elapsed: 0.0s
Encoding link 60 of 104: (20,6)
Progress: 67% – Elapsed: 0.0s
Encoding link 70 of 104: (17,9)
Progress: 77% – Elapsed: 0.0s
Encoding link 80 of 104: (1,20)
Progress: 87% – Elapsed: 0.0s
Encoding link 90 of 104: (20,1)
Progress: 96% – Elapsed: 0.0s
Encoding link 100 of 104: (8,4)
Done. Total time: 0.0s
Encoding 26 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 2 of 26: (11,4)
Progress: 15% – Elapsed: 0.0s
Encoding link 4 of 26: (15,9)
Progress: 23% – Elapsed: 0.0s
Encoding link 6 of 26: (6,16)
Progress: 31% – Elapsed: 0.0s
Encoding link 8 of 26: (20,16)
Progress: 38% – Elapsed: 0.0s
Encoding link 10 of 26: (15,17)
Progress: 46% – Elapsed: 0.0s
Encoding link 12 of 26: (6,19)
Progress: 54% – Elapsed: 0.0s
Encoding link 14 of 26: (7,20)
Progress: 62% – Elapsed: 0.0s
Encoding link 16 of 26: (4,19)
Progress: 69% – Elapsed: 0.0s
Encoding link 18 of 26: (20,13)
Progress: 77% – Elapsed: 0.0s
Encoding link 20 of 26: (15,11)
Progress: 85% – Elapsed: 0.0s
Encoding link 22 of 26: (6,13)
Progress: 92% – Elapsed: 0.0s
Encoding link 24 of 26: (6,1)
Progress: 100% – Elapsed: 0.0s
Encoding link 26 of 26: (7,13)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       40.38% |       0.6800 |          0.1000 |
|      50 |          50 |       00:00:00 |       98.08% |       0.0488 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0026 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0013 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0010 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9286, Recall: 1.0000, F1-Score: 0.9630
AUC: 0.9941
    "Experiment "    "8"    " (strategy: "    "random"    ") — Running WLNM..."

[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 119)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',119,0)">line 119</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 85)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',85,0)">line 85</a>)] 
[sample_neg] Final link counts:
    Train Positive: 52
    Train Negative: 52
    Test  Positive: 13
    Test  Negative: 13
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 104 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 10 of 104: (20,4)
Progress: 19% – Elapsed: 0.0s
Encoding link 20 of 104: (2,9)
Progress: 29% – Elapsed: 0.0s
Encoding link 30 of 104: (15,10)
Progress: 38% – Elapsed: 0.0s
Encoding link 40 of 104: (1,17)
Progress: 48% – Elapsed: 0.0s
Encoding link 50 of 104: (15,19)
Progress: 58% – Elapsed: 0.0s
Encoding link 60 of 104: (19,9)
Progress: 67% – Elapsed: 0.0s
Encoding link 70 of 104: (6,1)
Progress: 77% – Elapsed: 0.0s
Encoding link 80 of 104: (6,2)
Progress: 87% – Elapsed: 0.0s
Encoding link 90 of 104: (15,11)
Progress: 96% – Elapsed: 0.0s
Encoding link 100 of 104: (11,7)
Done. Total time: 0.0s
Encoding 26 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 2 of 26: (11,4)
Progress: 15% – Elapsed: 0.0s
Encoding link 4 of 26: (15,9)
Progress: 23% – Elapsed: 0.0s
Encoding link 6 of 26: (6,16)
Progress: 31% – Elapsed: 0.0s
Encoding link 8 of 26: (20,16)
Progress: 38% – Elapsed: 0.0s
Encoding link 10 of 26: (15,17)
Progress: 46% – Elapsed: 0.0s
Encoding link 12 of 26: (6,19)
Progress: 54% – Elapsed: 0.0s
Encoding link 14 of 26: (1,15)
Progress: 62% – Elapsed: 0.0s
Encoding link 16 of 26: (15,1)
Progress: 69% – Elapsed: 0.0s
Encoding link 18 of 26: (19,4)
Progress: 77% – Elapsed: 0.0s
Encoding link 20 of 26: (6,15)
Progress: 85% – Elapsed: 0.0s
Encoding link 22 of 26: (1,6)
Progress: 92% – Elapsed: 0.0s
Encoding link 24 of 26: (6,7)
Progress: 100% – Elapsed: 0.0s
Encoding link 26 of 26: (4,8)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       45.19% |       0.6932 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0058 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0008 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0006 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0005 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.9286, Recall: 1.0000, F1-Score: 0.9630
AUC: 0.9763
    "Experiment "    "9"    " (strategy: "    "random"    ") — Running WLNM..."

[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 119)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',119,0)">line 119</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 85)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',85,0)">line 85</a>)] 
[sample_neg] Final link counts:
    Train Positive: 52
    Train Negative: 52
    Test  Positive: 13
    Test  Negative: 13
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 104 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 10 of 104: (20,4)
Progress: 19% – Elapsed: 0.0s
Encoding link 20 of 104: (2,9)
Progress: 29% – Elapsed: 0.0s
Encoding link 30 of 104: (15,10)
Progress: 38% – Elapsed: 0.0s
Encoding link 40 of 104: (1,17)
Progress: 48% – Elapsed: 0.0s
Encoding link 50 of 104: (15,19)
Progress: 58% – Elapsed: 0.0s
Encoding link 60 of 104: (20,13)
Progress: 67% – Elapsed: 0.0s
Encoding link 70 of 104: (15,2)
Progress: 77% – Elapsed: 0.0s
Encoding link 80 of 104: (2,20)
Progress: 87% – Elapsed: 0.0s
Encoding link 90 of 104: (6,15)
Progress: 96% – Elapsed: 0.0s
Encoding link 100 of 104: (8,17)
Done. Total time: 0.0s
Encoding 26 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 2 of 26: (11,4)
Progress: 15% – Elapsed: 0.0s
Encoding link 4 of 26: (15,9)
Progress: 23% – Elapsed: 0.0s
Encoding link 6 of 26: (6,16)
Progress: 31% – Elapsed: 0.0s
Encoding link 8 of 26: (20,16)
Progress: 38% – Elapsed: 0.0s
Encoding link 10 of 26: (15,17)
Progress: 46% – Elapsed: 0.0s
Encoding link 12 of 26: (6,19)
Progress: 54% – Elapsed: 0.0s
Encoding link 14 of 26: (15,1)
Progress: 62% – Elapsed: 0.0s
Encoding link 16 of 26: (8,9)
Progress: 69% – Elapsed: 0.0s
Encoding link 18 of 26: (19,17)
Progress: 77% – Elapsed: 0.0s
Encoding link 20 of 26: (7,1)
Progress: 85% – Elapsed: 0.0s
Encoding link 22 of 26: (15,7)
Progress: 92% – Elapsed: 0.0s
Encoding link 24 of 26: (9,4)
Progress: 100% – Elapsed: 0.0s
Encoding link 26 of 26: (4,8)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       50.00% |       0.6573 |          0.1000 |
|      50 |          50 |       00:00:00 |      100.00% |       0.0119 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0013 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0009 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0007 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.10, Precision: 0.8125, Recall: 1.0000, F1-Score: 0.8966
AUC: 0.9882
    "Experiment "    "10"    " (strategy: "    "random"    ") — Running WLNM..."

[Warning: Not enough negative links. Reducing k...] 
[> In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('sample_neg', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m', 78)" style="font-weight:bold">sample_neg</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/sample_neg.m',78,0)">line 78</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('WLNM', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m', 28)" style="font-weight:bold">WLNM</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/WLNM.m',28,0)">line 28</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main>processExperiment', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 119)" style="font-weight:bold">Main>processExperiment</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',119,0)">line 119</a>)
In <a href="matlab:matlab.lang.internal.introspective.errorDocCallback('Main', '/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m', 85)" style="font-weight:bold">Main</a> (<a href="matlab: opentoline('/Users/jorge/Documents/qmul-phd-framework/src/matlab/Main.m',85,0)">line 85</a>)] 
[sample_neg] Final link counts:
    Train Positive: 52
    Train Negative: 52
    Test  Positive: 13
    Test  Negative: 13
[WLNM] Skipping DegreeCompute: non-degree-based strategy selected.
Encoding 104 subgraphs (K = 10)...
Progress: 10% – Elapsed: 0.0s
Encoding link 10 of 104: (20,4)
Progress: 19% – Elapsed: 0.0s
Encoding link 20 of 104: (2,9)
Progress: 29% – Elapsed: 0.0s
Encoding link 30 of 104: (15,10)
Progress: 38% – Elapsed: 0.0s
Encoding link 40 of 104: (1,17)
Progress: 48% – Elapsed: 0.0s
Encoding link 50 of 104: (15,19)
Progress: 58% – Elapsed: 0.0s
Encoding link 60 of 104: (7,6)
Progress: 67% – Elapsed: 0.0s
Encoding link 70 of 104: (4,8)
Progress: 77% – Elapsed: 0.0s
Encoding link 80 of 104: (8,4)
Progress: 87% – Elapsed: 0.0s
Encoding link 90 of 104: (20,13)
Progress: 96% – Elapsed: 0.0s
Encoding link 100 of 104: (19,4)
Done. Total time: 0.0s
Encoding 26 subgraphs (K = 10)...
Progress: 8% – Elapsed: 0.0s
Encoding link 2 of 26: (11,4)
Progress: 15% – Elapsed: 0.0s
Encoding link 4 of 26: (15,9)
Progress: 23% – Elapsed: 0.0s
Encoding link 6 of 26: (6,16)
Progress: 31% – Elapsed: 0.0s
Encoding link 8 of 26: (20,16)
Progress: 38% – Elapsed: 0.0s
Encoding link 10 of 26: (15,17)
Progress: 46% – Elapsed: 0.0s
Encoding link 12 of 26: (6,19)
Progress: 54% – Elapsed: 0.0s
Encoding link 14 of 26: (19,9)
Progress: 62% – Elapsed: 0.0s
Encoding link 16 of 26: (1,7)
Progress: 69% – Elapsed: 0.0s
Encoding link 18 of 26: (15,7)
Progress: 77% – Elapsed: 0.0s
Encoding link 20 of 26: (13,1)
Progress: 85% – Elapsed: 0.0s
Encoding link 22 of 26: (6,15)
Progress: 92% – Elapsed: 0.0s
Encoding link 24 of 26: (6,7)
Progress: 100% – Elapsed: 0.0s
Encoding link 26 of 26: (2,7)
Done. Total time: 0.0s
|========================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |
|========================================================================================|
|       1 |           1 |       00:00:00 |       47.12% |       0.7946 |          0.1000 |
|      50 |          50 |       00:00:00 |       96.15% |       0.0844 |          0.0656 |
|     100 |         100 |       00:00:00 |      100.00% |       0.0029 |          0.0387 |
|     150 |         150 |       00:00:00 |      100.00% |       0.0014 |          0.0229 |
|     200 |         200 |       00:00:00 |      100.00% |       0.0011 |          0.0135 |
|========================================================================================|
Training finished: Max epochs completed.
Best Threshold: 0.60, Precision: 0.9286, Recall: 1.0000, F1-Score: 0.9630
AUC: 0.9941
